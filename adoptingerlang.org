#+TITLE:     Adopting Erlang
#+AUTHOR:    Fred Hebert, Tristan Sloughter
#+DRAWERS: HIDDEN HINT SOLUTION
#+EMAIL:     t@crashfast.com
#+DESCRIPTION: Adopting Erlang.
#+KEYWORDS: erlang

# \setcounter{secnumdepth}{-1}

#+LATEX_CLASS: book
#+LATEX_CLASS_OPTIONS: [oneside,11pt]
#+ATTR_LATEX: :width 4in
#+OPTIONS: H:6
#+LATEX_HEADER: \usepackage[Bjornstrup]{fncychap}
#+LATEX_HEADER: \usepackage[svgnames]{xcolor}
#+LATEX_HEADER: \usepackage[tikz]{bclogo}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{minted}
#+latex_header: \usepackage{xcolor}
#+latex_header: \usemintedstyle{monokai}    %% sets default for all source-code blocks
#+latex_header: \definecolor{friendlybg}{HTML}{f0f0f0}
#+latex_header: \definecolor{dark}{HTML}{272822}   %% custom colour for background
#+latex_header: \setminted{style=friendly, bgcolor=friendlybg, frame=lines, breaklines, breakanywhere}
#+LATEX_HEADER: \newenvironment{alert}{\begin{bclogo}}{\end{bclogo}}
#+LATEX_HEADER: \newenvironment{notice}{\begin{bclogo}}{\end{bclogo}}
#+OPTIONS: ^:{}
#+HUGO_BASE_DIR: .
#+HUGO_SECTION: docs
#+HUGO_PAIRED_SHORTCODES: %alert
#+HUGO_PAIRED_SHORTCODES: %notice
#+hugo_auto_set_lastmod: t

* Introduction
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/introduction
:END:

** DONE Index
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_FRONT_MATTER_KEY_REPLACE: title>label
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :title "Introduction"
:EXPORT_HUGO_MENU: :menu main :weight 1001
:END:

#+BEGIN_EXPORT html
<header>
  <h1>Introduction</h1>
  <h5>
    <strong>August 3, 2019</strong>
  </h5>
</header>
#+END_EXPORT

So you've been checking Erlang out, and you've read a few tutorials and a bunch of books, but you're finding that nothing really tells you how you should set up a modern project for you and your team, and you have then found this text.  The Erlang community has collectively spent years writing introductory content, and a lot of it is still really good. So what's the hope for yet another book?

Frankly, most of the material out there is really solid to teach you the Erlang basics, and we have no pretension of replacing them, nor a desire to re-explain the same content they contain once more. Instead, we the authors felt like while they are rock solid in a lot of areas, we could help cover some blind spots.

For example, here are a bunch of interesting books:

- [[https://www.goodreads.com/book/show/808814.Programming_Erlang][Programming Erlang]], by Joe Armstrong is great to get into the philosophy behind Erlang
- [[https://www.goodreads.com/book/show/4826120-erlang-programming][Erlang Programming]], by Cesarini & Thompson is a very well-rounded practical approach to learning the language and bits of OTP
- [[https://www.goodreads.com/book/show/7438968-erlang-and-otp-in-action][Erlang and OTP in Action]], by Logan, Merritt & Carlsson is the first Erlang book that really tries to teach you OTP-first and hints at broader system design
- [[https://learnyousomeerlang.com/][Learn You Some Erlang]], by Fred Hebert, is possibly the friendliest introduction to both Erlang and OTP that tries to cover everything from basic Erlang to the design principles underpinning OTP, releases, and the whole ordeal
- [[https://www.goodreads.com/book/show/17984681-tudes-for-erlang][Études for Erlang]] by J. David Eisenberg is a fantastic companion exercise book that works with a bunch of other Erlang books, as a kind of practical complement
- [[https://www.goodreads.com/book/show/808815.Concurrent_Programming_ERLANG][Concurrent Programming ERLANG]] by Williams & Armstrong is a great piece of history from the 90s, showing earlier iterations of Erlang and how it could be applied to real world problems
- [[https://www.goodreads.com/book/show/15811999-introducing-erlang][Introducing Erlang]] by Simon St. Laurent is the most concise taste of Erlang you can get in book form
- [[https://www.erlang-in-anger.com/][Erlang in Anger]] by Fred Hebert is the only book that really contains a complete guide to debugging your Erlang systems in production
- [[https://www.goodreads.com/book/show/18324312-designing-for-scalability-with-erlang-otp][Designing for Scalability with Erlang/OTP]] by Cesarini & Vinoski is likely the most modern approach to Erlang/OTP systems with a real-world slant to it.
- [[https://blog.stenmans.org/theBeamBook/][The BEAM Book]] by Erik Stenman (and a lot of community contributors) is the most advanced resource on the virtual machine internals
- [[https://propertesting.com/][Property-Based Testing with PropEr, Erlang, and Elixir]] by Fred Hebert is the one book that teaches Property-based testing for Erlang

And there are some more too.

We intend to replace none of these. One huge omission in most (if not all) of these books, is that they tend to focus on Erlang/OTP on its own. In fact, many of these were written before massive shifts in how the community works. For example, _Learn You Some Erlang_, while very complete, was being written before _any_ community-driven build tool would see massive adoption, and before concepts such as OTP Releases would see widespread use. None of them have really been written under the new age of containerized platforms currently in place. And pretty much none of them mention how you should structure your projects to fit well within the open source Erlang ecosystem.

So this is what _Adopting Erlang_ is all about. This book (and website!) is all about filling in the niche that other books and manuals have not yet managed to properly cover. What you will learn in these pages will contain actually super useful stuff like:

- How to set yourself up to use multiple Erlang versions, because in the real world, you end up having to run multiple Erlang versions for the multiple projects your workplace or group of friends will end up using.
- We also cover how to set up editors and other tools, because chances are you may not have a good Erlang setup going even if you've already seen the basics
- How to approach OTP systems from the top. Most resources out there take a bottom-up approach, but we want you to be able to have the right project structure from day one, and then fill in the gaps with other resources as you need them
- What's needed for a good project, including dependency handling, some testing practices, handling configuration and documentation, and so on
- How to set up a good _Continuous Integration_ (CI) pipeline on common open platforms so that code reviews and automated testing can get the best support they can
- How to handle a bunch of difficult stuff nobody really teaches properly, like dealing with strings, specifically Unicode, time and proper SSL/TLS configuration
- How to deploy your Erlang systems as a self-executable bundle of files
- How to properly package your Erlang systems as Docker images, and showing how to manage their lifecycle with Kubernetes
- How to plan on setting up operations and get metrics going _outside_ of what the VM provides; think of things like logging and distributed tracing, platforms to get metrics dashboards going, and so on
- How to build a team that will start using Erlang in commercial projects
- How to interview your first Erlang experts or developers
- How to structure your practices for things such as code reviews, experience sharing, and so on.

By opposition, we will _not_ cover things like basic Erlang, core OTP behaviours, and so on. They have been covered multiple times in other resources in the past, many of which are freely available. We still have put together an appendix of cheat sheets you can refer to if you need a refresher.

Essentially, we hope for _Adopting Erlang_ to be the missing link between all the various starter books  and the more advanced material like _Erlang in Anger_ that lets you debug stuff in production. We want this book to teach you how to go from "Okay, I think I got the basics" to "let's get this project going, and let's do it right." After reading this book, you should be able to know exactly what the best practices are to fit right in with the rest of the Erlang community.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/">← Prev</a></div>
  <div><a href="/docs/introduction/about_the_authors">Next →</a></div>
</div>
#+END_EXPORT

** DONE About the Authors
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: about_the_authors
:EXPORT_HUGO_MENU: :menu main :parent introduction
:END:

*** Tristan Sloughter

Tristan is a long time Erlang programmer, having picked it up for fun while in college and then professionally for various companies, Orbitz Worldwide, eCDMarket, Heroku, SpaceTime Insight, and currently as a senior software engineer at Postmates, Inc.

While at Heroku, Tristan, along with Fred, started the build tool Rebar3 after seeing the struggles involved in onboarding new developers to Erlang projects. He is also a maintainer of the release tool Relx.

Tristan also created the website [[https://howistart.org/][How I Start]] which collects articles for various languages from experienced developers on how they setup a new project and take it to completion, while also giving a peek at the tools and packages these top developers prefer.

- [[https://twitter.com/t_sloughter][@t_sloughter]]
- [[http://blog.erlware.org/][blog]]

*** Fred Hebert

Fred is the author of [[https://learnyousomeerlang.com][_Learn You Some Erlang_]], [[https://erlang-in-anger.com][_Erlang in Anger_]], and more recently, [[https://propertesting.com][_Property-Based Testing with PropEr, Erlang, and Elixir_]]. He is a maintainer of Rebar3, and of libraries such as recon, pobox, vmstats, and backoff.

He is a senior infrastructure developer at Postmates. Previously, he was a Systems Architect at Genetec, a company offering video systems, access control, case management, and IoT integration systems, and was also a principal member of technical staff on the Heroku platform, worked in real-time bidding, and provided Erlang training.

- [[https://twitter.com/mononcqc][@mononcqc]]
- [[https://ferd.ca][blog]]

*** Evan Vigil-McClanahan

Evan has been writing Erlang professionally since 2012 and in various other languages since 2001.  He's worked with Erlang at Basho Technologies, Heroku, SpaceTime Insight, and most recently Helium, where his broad focus has been on distributed systems along with high- and low-level performance.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/introduction">← Prev</a></div>
  <div><a href="/docs/development">Next →</a></div>
</div>
#+END_EXPORT

* Development
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/development
:END:
#+latex_header: \usepackage[utf8]{inputenc}
#+latex_header: \usepackage{pmboxdraw} % for directory listings
#+latex_header: \usepackage{textalpha} % for greek a
#+latex_header: \usepackage[T2A]{fontenc} % cyrilic a
#+latex_header: \DeclareUnicodeCharacter{0430}{\cyra} % cyrilic a
#+latex_header: \DeclareUnicodeCharacter{03A9}{Ω} % omega vs. ohm
#+latex_header: \DeclareUnicodeCharacter{267B}{\includegraphics[height=\fontcharht\font`\B]{./static/img/recycling.png}}
#+latex_header: \DeclareUnicodeCharacter{FDFD}{\includegraphics[height=\fontcharht\font`\B]{./static/img/bismillah.png}}
#+latex_header: \DeclareUnicodeCharacter{1F469}{\includegraphics[height=\fontcharht\font`\B]{./static/img/woman.png}}
#+latex_header: \DeclareUnicodeCharacter{1F466}{\includegraphics[height=\fontcharht\font`\B]{./static/img/boy.png}}
#+latex_header: \DeclareUnicodeCharacter{1F914}{\includegraphics[height=\fontcharht\font`\B]{./static/img/thinking.png}}
#+latex_header: \DeclareUnicodeCharacter{200D}{\hspace{0pt}}


** DONE Index
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_FRONT_MATTER_KEY_REPLACE: title>label
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :title "Development"
:EXPORT_HUGO_MENU: :menu main :weight 2001
:END:

#+BEGIN_EXPORT html
<header>
  <h1>Development</h1>
  <h5>
    <strong>August 3, 2019</strong>
  </h5>
</header>
#+END_EXPORT

The first section of this book is dedicated to getting a working installation, and understanding the actual structure of a project. This section will also cover how to import dependencies in your project, how to build projects that contain multiple OTP applications, write tests for your projects, and also a few other interesting topics.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/introduction/about_the_authors">← Prev</a></div>
  <div><a href="/docs/development/setup">Next →</a></div>
</div>
#+END_EXPORT

** DONE Setup
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: setup
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

You can't write Erlang without having Erlang installed, so the unsurprising first steps covered in this chapter will be to go through the basic steps required to install Erlang/OTP on most major platforms. The instructions will aim for a basic set-up on most platforms, but you'll find out that real world Erlang development is rarely done with just the basic instructions.

In fact, as teams grow and they accumulate various projects, chances are that not all services, libraries, or bits of code will all support the same exact version of Erlang, and won't be upgraded all at once. If you talk to developers who use Erlang professionally, most (aside from Windows users) will tell you that they just compile their own copies with the options they need, and with a tool that lets them switch between multiple versions. So we'll go through that.

You will also see how to install Rebar3, the official build tool for the Erlang community, and base configurations for various text editors. In later chapters, we'll additionally talk about other tools that aren't specific to Erlang such as Kubernetes or Prometheus, but let's get started with Just Erlang for now.

*** Installing Erlang/OTP

The first step is to get a proper install of Erlang/OTP in place. This is not going to be a uniform experience on all platforms, but we'll at least make sure everyone following these steps has a fully functioning setup for any work environment.

**** Choosing a Version

Erlang/OTP is released on a fairly stable and predictable schedule, with well-defined criteria for backwards-incompatible changes.

Erlang versions are numbered according to a =<Major>.<Minor>.<Patch>= scheme, as described in the [[http://erlang.org/doc/system_principles/versions.html#version_scheme][Erlang/OTP system principles]]. In some rare circumstances, other digits are bolted on as "branched" versions, which you likely won't have to care about.

Here are some example possible versions:

- 22.0
- 22.0-rc3
- 21.3
- 21.2.3
- 21.1
- 19.3
- 17.0
- R16B03 (this is a legacy version format that hasn't been used since 2014)

As you can see, the =Patch= version is not mentioned when no patch is required. The release schedule for Erlang goes a bit like this:

1. Once per year, around February or March, a release candidate for the next major version is announced (with a suffix such as =-rc1=, or =-rc2=). This release candidate is made available for users who want to build from source, in order to test that their applications and system will work well with it
2. A few months later (April to June), the major release is cut and made public. Major releases contain large new features that require bigger virtual machine changes, and are also allowed to introduce backwards-incompatible changes
3. At a frequency of every three or four months, a minor release is made public, which usually includes stability fixes and minor feature additions in individual libraries
4. If a critical bug has been found in some circumstances, either for security or stability reasons, a patch release may be announced.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_alert
Backwards incompatible changes are usually going through a cycle of deprecation before being removed, which tends to leave ample time to adapt. The policy is described in the [[http://erlang.org/doc/system_principles/misc.html][Support, Compatibility, Deprecations, and Removal]] document published by the OTP team at Ericsson.
#+end_alert

In some rare scenarios, hard-and-fast deprecations do happen (mostly by accident), and it may take a few weeks for the community to come up with workarounds.

A team that adopts Erlang will therefore likely want to adopt a maintenance schedule that fits the main releases if they want to avoid falling too far behind. While it is possible to only upgrade occasionally, you will find that it is often easier to do a bit of maintenance here and there than a lot of maintenance all at once.

Do note that patch-level releases are often only announced on the [[http://erlang.org/mailman/listinfo/erlang-questions][mailing lists]] and tagged on [[https://github.com/erlang/otp][the main git repository on GitHub]], but are otherwise not packaged on the main website.

**** Windows

If you are a Windows user, it is recommended that you use Windows 10 for any Erlang development. Prior versions can work, but community tools such as Rebar3 are only tested on Windows 10, for example.

Building on Windows from source has been notoriously difficult, and it is therefore recommended that you stick to the pre-built copies.

If you are a user of [[https://chocolatey.org][Chocolatey]], you can grab the [[https://chocolatey.org/packages/erlang][Erlang]] packages, and install them as you wish, with commands such as:

#+NAME: choco
#+BEGIN_SRC sh
choco install erlang                   # for the latest
choco install erlang --version 21.2 -m # allow many versions
choco install erlang --version 20.1 -m # and one more versions
#+END_SRC

This will add all the versions you want to your =PATH= variable, which you will then need to maintain in the right order.

Without Chocolatey, use binaries distributed on [[https://www.erlang.org/downloads][www.erlang.org/downloads]], or alternatively those built by [[https://www.erlang-solutions.com/resources/download.html][Erlang Solutions Ltd.]].

The installer for these versions comes with a wizard that will take you through all the required steps.

Do not forget to add Erlang/OTP to your =PATH= variable to contain your Erlang/OTP installation, since this will let you call it from the command-line:

1. In the start menu, search for "system environment variables" and select the "Edit the System and Environment Variables (Control Panel)" option
2. At the bottom of the "System Properties" window that has just open, press the "Environment Variables..." button
3. Select the =Path= variable (or create it if it does not exist) and click the "Edit" button
4. Add an entry for Erlang/OTP that matches the installation path, usually something like =C:\Program Files\erl10.2\bin=. The entries put earlier in the list will be loaded first.
5. Save the options
6. Close and restart any terminal you were running.

If you do development in the long term, you will be able to install multiple versions that way. You can control which one is used by changing and modifying the =PATH= variable's priorities in paths.

If you are a purist when it comes to Windows development, you may be quite comfortable in an environment such as Visual Studio, where pretty much everything can be done from within the IDE. Erlang comes from a different environment, and a lot of the instructions we'll use in this book are focused on using the command line to build everything.

If you are looking for a terminal to run the command line on Windows, various options are available:

- Use PowerShell as a terminal. Most commands in this book should work fine with it, but some edge cases may exist.
- Download and install [[https://git-scm.com/download/win][git for Windows]], which will come with a =git-bash= shell that will work well with all tooling and most commands in this book
- Try [[https://www.fosshub.com/ConEmu.htm][ConEmu]] as a nicer terminal emulator to work with
- Use [[https://cmder.net/][Cmder]] which is a Windows console emulator that packages most of the above options rather well
- Use [[https://www.cygwin.com][Cygwin]] at your own risk; you will need to rebuild your software from source to work well with it, and tools like Rebar3 dynamically figure out they're on Windows, which historically has caused a few path problems when interacting with Cygwin

You can then use the editor or IDE of your choosing to work with Erlang components.

**** OSX

While OSX makes it possible to use [[https://brew.sh/][Homebrew]] or [[https://www.erlang-solutions.com/resources/download.html][Erlang Solutions Ltd. packages]] to install pre-built versions of Erlang/OTP, you should only do so if you're trying things out the first time around. If you're planning on doing actual development for the longer haul, you'll instead want to be able to handle multiple versions at once.

The most commonly supported tool for this is [[https://github.com/kerl/kerl][kerl]]. Kerl is a wrapper around downloading, compiling, and loading various Erlang/OTP versions on a single system, and will abstract away most annoying operations.

You can install Kerl from homebrew by calling =$ brew install kerl=, or by following the instructions in its [[https://github.com/kerl/kerl#downloading][README file]].

Before installing Erlang, we will need to install and update a few dependencies, the main ones being to make sure you have [[https://developer.apple.com/xcode/][XCode]] installed and to then install OpenSSL (since OSX has terribly outdated copies of SSL by default):

#+NAME: openssl_osx
#+BEGIN_SRC sh
$ brew install openssl
...
$ ls /usr/local/Cellar/openssl/
1.0.2q
#+END_SRC

Note the full path this gives you for the local openssl install, here being =/usr/local/Cellar/openssl/1.0.2q/=

You can set the following options in your environment:

#+NAME: kerlcfg_osx
#+BEGIN_SRC sh
SSL_PATH=/usr/local/Cellar/openssl/1.0.2q/
export KERL_BUILD_BACKEND="git"
export KERL_CONFIGURE_OPTIONS="--without-javac \
                               --with-dynamic-trace=dtrace \
                               --with-ssl=${SSL_PATH}"
#+END_SRC

And ensure it's active (for example, call =source ~/.bashrc=). These options specify what is accepted or expected from the build tool. The one here disables Java bindings, and uses the new SSL install we've made. You can look at the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#configuring-1][Build Instructions]] for more configuration options.

If you want to add more content, such as =Wx= (which lets you use and build GUIs), the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#os-x-darwin][Build instructions for OSX]] contain further details to guide you.

From that point on, you can download and install your own Erlang/OTP versions:

#+NAME: kerl_osx
#+BEGIN_SRC sh
$ kerl update releases
...
# kerl build <release> <build name>
$ kerl build 21.3 21.3
...
# kerl install <build name> <target path>
$ kerl install 21.3 ~/bin/erls/21.3/
...
# make that version active
$ . ~/bin/erls/21.3/activate
# or alternatively
$ source ~/bin/erls/21.3/activate
#+END_SRC

Any installed version can then be activated on-demand. If you want to set a default version, you can put the activation command in your =.bashrc= configuration file (or any shell profile you might have).

If you are planning on using both Erlang and Elixir on your development machine, you might want to take a look at [[https://asdf-vm.com/#/core-manage-asdf-vm][=asdf=]]. It is a plugin-based installer for multiple programming languages, and can handle both Elixir and Erlang at once. You may need to install the =autoconf= package to make it work.

To use it with Erlang, install the [[https://github.com/asdf-vm/asdf-erlang][Erlang plugin]] by calling =asdf plugin-add erlang https://github.com/asdf-vm/asdf-erlang.git=. This plugin wraps =kerl= and reuses all of its options, but transfers the builds under =asdf='s control. As such, the previous configuration instructions remain the same. You just have to change the sequence of calls for:

#+NAME: asdf_linux
#+BEGIN_SRC sh
# asdf install erlang <version>
$ asdf install erlang 21.3
...
# asdf global <name> <version> [<version>...]
# asdf local <name> <version> [<version>...]
# export ASDF_ERLANG_VERSION=<version>
#+END_SRC

The main difference between =kerl= and =asdf= from there on is that =kerl= will use environment variables to know which version to run, and =asdf= will optionally use a =.tool-versions= file to trigger the change on a per-directory basis.


**** Linux

Linux distributions pretty much all have package managers that let you install pre-built copies of Erlang, or you can still use [[https://www.erlang-solutions.com/resources/download.html][Erlang Solutions Ltd. packages]]. Much like with OSX though, you should only do so if you're trying things out the first time around. If you're planning on doing actual development for the longer haul, you'll instead want to be able to handle multiple versions at once.

The most commonly supported tool for this is [[https://github.com/kerl/kerl][kerl]]. Kerl is a wrapper around downloading, compiling, and loading various Erlang/OTP versions on a single system, and will abstract away most annoying operations.

You can install kerl by calling:

#+NAME: linux_kerl
#+BEGIN_SRC sh
$ curl -O https://raw.githubusercontent.com/kerl/kerl/master/kerl
$ chmod a+x kerl
#+END_SRC

And then moving kerl to your path. Kerl will automatically check and warn you about missing dependencies you might be needing when building libraries, so you can just go ahead and run the following commands, and listen to its directions as you go.

First, you can set options as follows in your environment:

#+NAME: kerlcfg_linux
#+BEGIN_SRC sh
export KERL_BUILD_BACKEND="git"
export KERL_CONFIGURE_OPTIONS="--without-javac \
                               --with-dynamic-trace=systemtap"
#+END_SRC

And ensure it's active (for example, call =source ~/.bashrc=). These options specify what is accepted or expected from the build tool. The one here disables Java bindings, but they would be skipped automatically anyway. You can look at the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#configuring-1][Build Instructions]] for more configuration options.

If you want to add more content, such as =Wx= (which lets you use and build GUIs), the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#building-with-wxerlang][Build instructions for Wx]] contain further details to guide you.

From that point on, you can download and install your own Erlang/OTP versions:

#+NAME: kerl_linux
#+BEGIN_SRC sh
$ kerl update releases
...
# kerl build <release> <build name>
$ kerl build 21.3 21.3
...
# kerl install <build name> <target path>
$ kerl install 21.3 ~/bin/erls/21.3/
...
# make that version active
$ . ~/bin/erls/21.3/activate
# or alternatively
$ source ~/bin/erls/21.3/activate
#+END_SRC

Any installed version can then be activated on-demand. If you want to set a default version, you can put the activation command in your =.bashrc= configuration file (or any shell profile you might have).

If you are planning on using both Erlang and Elixir on your development machine, you might want to take a look at [[https://asdf-vm.com/#/core-manage-asdf-vm][=asdf=]]. It is a plugin-based installer for multiple programming languages, and can handle both Elixir and Erlang at once. You may need to install the =autoconf= package to make it work.

To use it with Erlang, install the [[https://github.com/asdf-vm/asdf-erlang][Erlang plugin]] by calling =asdf plugin-add erlang https://github.com/asdf-vm/asdf-erlang.git=. This plugin wraps =kerl= and reuses all of its options, but transfers the builds under =asdf='s control. As such, the previous configuration instructions remain the same. You just have to change the sequence of calls for:

#+NAME: asdf_osx
#+BEGIN_SRC sh
# asdf install erlang <version>
$ asdf install erlang 21.3
...
# asdf global <name> <version> [<version>...]
# asdf local <name> <version> [<version>...]
# export ASDF_ERLANG_VERSION=<version>
#+END_SRC

The main difference between =kerl= and =asdf= from there on is that =kerl= will use environment variables to know which version to run, and =asdf= will optionally use a =.tool-versions= file to trigger the change on a per-directory basis.

**** FreeBSD

On FreeBSD, the experience with =kerl= (as reported in other sections) has been hit and miss. Sometimes, some patches are required to make things work as smoothly as on other platforms. The good news is that if you use either the BSD [[https://www.freebsd.org/doc/en/books/handbook/ports-using.html][ports]] or [[https://www.freebsd.org/doc/en/books/handbook/pkgng-intro.html][packages]], it will all work fine out of the box.

This is the easiest way forwards, but makes switching across versions a bit trickier since you don't get an Erlang version manager for free. However, BSD ports and packages do let you build any version supported at your liking.

For example you can call any of the following:

#+NAME: bsd_install
#+BEGIN_SRC sh
# pkg install erlang # default copy
# pkg install erlang-runtime20  # OTP-20.x
# ls /usr/ports/lang/erlang* # source install: pick the version directory
erlang/
...
erlang-runtime20/
erlang-runtime21/
erlang-wx/
# cd /usr/ports/lang/erlang-runtime21/
# make config-recursive     # configure all the deps
# make install
#+END_SRC

FreeBSD maintainers are generally good about ensuring things keep working fine on the main supported architectures, so if you're sticking to x86 and avoid ARM, you should have no major issues.

**** Making things Nice

Before you're done, you should go to your shell or terminal profile, and add a few environment variables. Specifically, you can use =ERL_AFLAGS= or =ERL_ZFLAGS= to add configuration switches to the =erl= executable at all times.

We'll use =ERL_AFLAGS= to turn on two neat features: outputting strings with Unicode support by default, and enabling shell history so that the Erlang shell remembers your commands between invocations. Add the following to your environment:

#+NAME: erl_aflags
#+BEGIN_SRC sh
export ERL_AFLAGS="+pc unicode -kernel shell_history enabled"
#+END_SRC

Things will feel a bit more modern that way.

*** Installing Rebar3

Rebar3 is the standard build tool within the Erlang community. It essentially bundles all of the other tools shipping with Erlang along with a few open-source ones, and makes them all work under a unified project structure.

There are a few ways to install Rebar3: from a pre-built binary, or from source, and then a last variant for a faster-running local install. Do note that in all cases, you need Erlang to have been installed already.

**** Pre-Built Binaries

Pre-built binaries can be found at [[https://www.rebar3.org/][www.rebar3.org]]. There's a big "Download" button with the latest stable version, but if you like to live more dangerously, you can grab [[https://s3.amazonaws.com/rebar3-nightly/rebar3][the latest _nightly_ build]] as well.

It is common to create a directory =~/bin/= to place commands line utilities like =rebar3=, which is where you might want to put the version you just downloaded. Call =chmod +x rebar3= on it to make sure it can run, and add it to your path with =export PATH=~/bin/:$PATH= in your =~/.bashrc=, =~/.zshrc= or equivalent.

Windows users who want to use the code from PowerShell or cmd.exe (rather than a terminal emulator) must ensure that a =rebar3.cmd= file is added:

#+NAME: rebar.cmd
#+BEGIN_SRC sh
@echo off
setlocal
set rebarscript=%~f0
escript.exe "%rebarscript:.cmd=%" %*
#+END_SRC

**** Building From Source

First make sure that you have git installed, and checkout the repository to build it:

#+NAME: rebar_bootstrap
#+BEGIN_SRC sh
$ git clone https://github.com/erlang/rebar3.git
$ cd rebar3
$ ./bootstrap
#+END_SRC

This will create a =rebar3= script file (along with a =rebar3.cmd= file on Windows).

**** Local Install

The local install form will let you take any of the previously built rebar3 versions, and unpack them to a local directory from which the tool will be able to self-update at a later time:

#+NAME: rebar_local
#+BEGIN_SRC sh
$ ./rebar3 local install  # starting from a rebar3 not in PATH
===> Extracting rebar3 libs to ~/.cache/rebar3/lib...
===> Writing rebar3 run script ~/.cache/rebar3/bin/rebar3...
===> Add to $PATH for use: export PATH=$PATH:~/.cache/rebar3/bin
$ export PATH=$PATH:~/.cache/rebar3/bin
$ rebar3 local upgrade # this can be used to update to the latest stable copy
...
#+END_SRC


*** Configuring Editors

**** Visual Studio Code

Although there exists a [[https://github.com/erlang/sourcer][language server]] with its own [[https://github.com/vladdu/vscode-erlang-lsp][extension]], they are at the time of this writing only at an experimental stage. Instead, the [[https://marketplace.visualstudio.com/items?itemName=pgourlain.erlang][Erlang extension]] by Pierrick Gourlain is recommended.

To configure the extension, go to the =Preferences= and then =Settings= menu. Within the VS Code window, unroll the =Extensions= menu until the =erlang configuration= section. Make sure that all the values are right, particularly the Erlang path and the Rebar3 path. With this in place, you can mix and match all the other extensions you'd like and things should be ready to go.

The code formatter may feel a bit janky; it respects the official Erlang repository's old rules of mixing tabs and spaces, and expects each tab is 8 spaces wide. This is not really use anywhere else, and if your Visual Studio Code is not configured that way (using 4 spaces for example), it will just look off.

Otherwise, that extension covers all the major features: jumping around code definitions, build tool support (although only =compile=, =eunit=, and =dialyzer= are supported in the command palette, you can still call =rebar3= directly from the terminal), intellisense, warnings as you type, and CodeLens features. If you look at the extension's documentation, you'll also find debugger support instructions.

All you've got to do then is configure themes and more general extensions to your liking.

**** Emacs

Erlang/OTP comes with an Emacs mode in the =tools= application, =lib/tools/emacs/=. The authors of this book who use Emacs stick to using this mode by having Emacs load directly from the latest Erlang version installed. There are a number of options for alternative modes and addons to use for fancier support in =erlang-mode=, here we will only discuss [[https://oremacs.com/swiper/][Ivy]] completions and [[https://www.flycheck.org/en/latest/][Flycheck]] syntax checking. But first we need [[https://jwiegley.github.io/use-package/][use-package]] which is a tool for isolating package configuration. Code for automatically installing =use-package= can be [[https://github.com/CachesToCaches/getting_started_with_use_package/blob/7d260ddf7b15160c027915340ff0c70ce05ea315/init-use-package.el][found here]]. Include that code in your =~/.emacs.d/init.el= so that on startup =use-package= is installed. Or use the [[https://jwiegley.github.io/use-package/installation/][installation instructions]] found on the =use-package= website.

This following bit of =elisp= code can be used to setup just =erlang-mode=, no Ivy or Flycheck involved, and have it load for =rebar3=, =relx= and other Erlang configuration files:

#+BEGIN_SRC elisp
(use-package erlang
  :load-path ("<PATH TO OTP>/lib/erlang/lib/tools-3.0/emacs/")
  :mode (("\\.erl?$" . erlang-mode)
         ("rebar\\.config$" . erlang-mode)
         ("relx\\.config$" . erlang-mode)
         ("sys\\.config\\.src$" . erlang-mode)
         ("sys\\.config$" . erlang-mode)
         ("\\.config\\.src?$" . erlang-mode)
         ("\\.config\\.script?$" . erlang-mode)
         ("\\.hrl?$" . erlang-mode)
         ("\\.app?$" . erlang-mode)
         ("\\.app.src?$" . erlang-mode)
         ("\\Emakefile" . erlang-mode)))
#+END_SRC

For using Ivy to get completion support add the =ivy-erlang-complete= package, set a custom Erlang root for it to use and run its =init= when the Erlang mode is configured:

#+BEGIN_SRC elisp
(use-package ivy-erlang-complete
  :ensure t)

(use-package erlang
  :load-path ("<PATH TO OTP>/lib/erlang/lib/tools-3.0/emacs/")
  :hook (after-save . ivy-erlang-complete-reparse)
  :custom (ivy-erlang-complete-erlang-root "<PATH TO OTP>/lib/erlang/")
  :config (ivy-erlang-complete-init)
  :mode (("\\.erl?$" . erlang-mode)
         ("rebar\\.config$" . erlang-mode)
         ("relx\\.config$" . erlang-mode)
         ("sys\\.config\\.src$" . erlang-mode)
         ("sys\\.config$" . erlang-mode)
         ("\\.config\\.src?$" . erlang-mode)
         ("\\.config\\.script?$" . erlang-mode)
         ("\\.hrl?$" . erlang-mode)
         ("\\.app?$" . erlang-mode)
         ("\\.app.src?$" . erlang-mode)
         ("\\Emakefile" . erlang-mode)))
#+END_SRC

Flycheck comes with =rebar3= support and can automatically detect a rebar3 project, so all that is needed is the =flycheck= package:

#+BEGIN_SRC elisp
(use-package delight
  :ensure t)

(use-package flycheck
  :ensure t
  :delight
  :config (global-flycheck-mode))
#+END_SRC

The =:config (global-flycheck-mode)= argument to =use-package= will enable Flycheck for all code you edit in Emacs, the expressions given with =:config= are run after the package has been loaded. The =:delight= argument tells =use-package= to use the =delight= utility to disable showing Flycheck in the mode line. Keeping it out of the mode line saves space and especially since it is enabled globally we don't need it being called out as currently enabled in the mode line.

If you like using Flycheck then [[https://github.com/abo-abo/hydra][hydra]] is worth checking out for stepping through and viewing the full list of errors. The Hydra macro sets up short keybindings that work only when the initial Hydra binding has been run. The following code will setup basic bindings for viewing Flycheck errors when =C-c f= is called:

#+BEGIN_SRC elisp
(use-package hydra
  :defer 2
  :bind ("C-c f" . hydra-flycheck/body))

(defhydra hydra-flycheck (:color blue)
  "
  ^
  ^Errors^
  ^──────^
  _<_ previous
  _>_ next
  _l_ list
  _q_ quit
  ^^
  "
  ("q" nil)
  ("<" flycheck-previous-error :color pink)
  (">" flycheck-next-error :color pink)
  ("l" flycheck-list-errors))
#+END_SRC

Lastly, a couple packages that are not Erlang specific but are worth calling out as very useful when developing on a project:

- [[https://magit.vc/][magit]]: An Emacs interface for [[https://git-scm.com/][Git]]. Magit does not just allow for calling Git from Emacs but provides a streamlined interface for everything from staging changes to interactive rebases.
- =counsel-rg=: [[https://github.com/abo-abo/swiper/][counsel]] is a collection of commands that utilize Ivy, the package we used earlier for Erlang completions. =counsel-rg= uses  [[https://github.com/BurntSushi/ripgrep][ripgrep]] to search for strings across the files in a project -- when in a git project they act like =git grep=, only searching in files in the git repo and honoring =.gitignore=. Since ripgrep is an external commands it must be installed separately, for example on Ubuntu or Debian run =sudo apt-get install ripgrep=. When =ripgrep= is installed it will also be used by =ivy-erlang-complete= for faster searches.
- [[https://github.com/abo-abo/swiper/][swiper]]: An alternative to =isearch= for searching in a buffer that uses Ivy.
- [[https://company-mode.github.io/][company-mode]]: When combined with =ivy-erlang-complete= through [[https://github.com/s-kostyaev/company-erlang][company-erlang]] this mode will provide a popup of completions automatically, rather than requiring =C-:= to bring up completions in the minibuffer.
- [[https://github.com/flycheck/flycheck-inline][flycheck-inline]], [[https://github.com/flycheck/flycheck-pos-tip][flycheck-pos-tip]] or [[https://github.com/flycheck/flycheck-popup-tip][flycheck-popup-tip]]: These packages offer different options for displaying Flycheck errors at the position of the error instead of in the minibuffer.

**** Vim

Although absolutely fancy support for Erlang is possible in Vim—as the [[https://github.com/vim-erlang][vim-erlang group on Github]] allows—the authors of this book who use it tends to stick with the most minimal configuration possible.

Simply stick with the default syntax highlighting in your =.vimrc= file, and make sure it's used in all the right file types:

#+BEGIN_SRC vim
"also erlang
autocmd BufRead,BufNewFile *.erl,*.es.*.hrl,*.xrl,*.config setlocal expandtab noautoindent
au BufNewFile,BufRead *.erl,*.es,*.hrl,*.xrl,*.config setf erlang
#+END_SRC

This is the very basic stuff, obviously. Fancier integration is possible, but the one author who uses vim mostly uses only this, and relies on Rebar3 in a terminal to deal with the rest of the language.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/development">← Prev</a></div>
  <div><a href="/docs/development/otp_high_level">Next →</a></div>
</div>
#+END_EXPORT

** DONE OTP at a High Level
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: otp_high_level
:EXPORT_HUGO_MENU: :menu main :parent development
:END:


Erlang/OTP is different from most programming environments out there, even those that also use a virtual machine. Erlang has a strong opinion about how your applications should be structured, the level of isolation they should have, and a separation between what Erlang's VM can do, and what your software can do. It's not just a programming language, it's a whole framework for building systems. Understanding its core principles is the key to getting started fast without having to rewrite everything later: it ensures that all applications can fit well together, that updates can be done live, and that your code is easy to instrument and make observable.

In this chapter, we'll cover the Erlang virtual machine and the core concepts of OTP at the highest level.

*** The Erlang Run-Time System

The foundational block for everything is the Erlang virtual machine itself, called BEAM. BEAM is technically a single implementation of the Erlang virtual machine, as there could be others. For example, Erllvm is an implementation over LLVM (using some custom patches to make everything possible), and an older implementation in the 90s was called JAM. The Erlang VM is implemented in C, and contains a lot of fancy stuff: schedulers to run processes, garbage collection, memory allocators, a timer wheel for events, a bunch of smart switches to abstract over operating system features and provide unified interfaces (such as over time management, file-handling drivers, and so on), a few built-in functions that go faster than what Erlang can do on its own (BIFs) and an interface for functions implemented natively in other languages (NIFs) along with special schedulers for them. There's obviously a lot more, but you can think of all that stuff the way you would with the kernel in BSD or Linux: low level stuff that you need in order to build fancier stuff.

If all you have is the virtual machine with nothing else, you can't run Erlang code. You don't have a standard library, you don't have libraries to even load code. To get it all going, there's some tricky bootstrapping going on that we don't need to understand. Just know that there's a limited set of pre-loaded Erlang modules that ship with the virtual machine, and those can be used to set up networking and file-handling stuff that allows to further load and run modules. If you're interested in knowing more though, please consult [[https://happi.github.io/theBeamBook/][The BEAM Book]] or [[http://beam-wisdoms.clau.se/en/latest/][BEAM Wisdoms]].

If you take the virtual machine and the pre-loaded stuff, along with all the little utilities that make code-loading possible, you have what is essentially called the _Erlang Run-Time System_ (ERTS). The Run-Time System, when starting, follows the instructions of a thing called a _boot script_ (which nobody writes by hand) that specifies what to start.

Erlang, by default, provides boot scripts that load a minimal amount of code required to start a shell and write your own applications. Once this is done, we can start thinking about Erlang, and not just the virtual machine.

*** Erlang/OTP

What we have described so far is equivalent to an operating system's kernel. We now need the foundational blocks for the userspace components. In Erlang, this is essentially what OTP is about. OTP specifies how "components" that run on the virtual machine should be structured. There's more to the language than just "processes and messages": there's one well-defined way to structure your code.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_alert
OTP stands for _Open Telecom Platform_, which is literally a meaningless name that was used to get the stuff open-sourced back in the old days of Erlang at Ericsson.
#+end_alert

Erlang/OTP systems are structured through components named _OTP Applications_. Every Erlang version you have installed or system built with it that you use ships with a few OTP Applications. There are basically two variants of OTP applications: _Library Applications_, which are just collections of modules, and _Runnable Applications_, which contain a collection of modules, but also specify a stateful process structure stored under a supervision tree. For the sake of clarity, we're going to use the following terminology for OTP Applications for this entire book:

- _Library Applications_: stateless collections of modules
- _Runnable Applications_: OTP applications that start stateful supervision tree structures with processes running in them
- _OTP Applications_: either _Library_ or _Runnable Applications_, interchangeably

By default, the two OTP applications everyone includes are called =stdlib=, which is a library application that contains the core standard library modules such as =list= or =maps=, and =kernel=, which is a runnable application and sets up the core structure for an Erlang system that relies on OTP applications to work.

When a node boots, the modules from all required OTP applications are loaded in memory. Then =kernel= is started. =kernel= manages the lifecycle of the system from this point on. All other OTP applications and their configuration are handled through it, and so are unique features like distribution and hot code updates. If we go back to the operating system comparison, you can think of the =kernel= OTP application a bit like you could think of =systemd= for the Linux kernel (or =init= if you hate =systemd= or use a BSD -- Windows users can think of it as the service that runs other services)

In fact, =kernel= and =stdlib= are the only two applications you need for a basic working Erlang shell. When you type in =erl= (or start =werl= on Windows), this boots up the VM, along with kernel, with =stdlib= pre-loaded. Everything else is optional and can be loaded at a later time.

The standard Erlang distribution contains applications such as:

- kernel
- stdlib
- crypto (cryptographic primitives)
- ssl (TLS termination library)
- inets (network services such as FTP or HTTP clients)
- ct (Common Test framework)
- wx (graphic toolkit)
- observer (a control panel to manage your Erlang node, building on =wx=)
- compiler (the Erlang compiler to build your own project)
- and so on

All of these are put together into what is called an Erlang _release_. A release is a collection of OTP applications, possibly bundled together with a full copy of the virtual machine. As such, when you download and install Erlang, you just get a release whose name is something like _Erlang/OTP-21.3.4_. You're free to build your own releases, which will take some of the OTP applications in the standard distribution, and then bundle them with some of your own apps.

So if we were to write an app named =proxy= that relies on =ssh= and =ssl= (which themselves depend on =public_key=, =crypto=, =stdlib=, and =kernel=), we would make a release with all of these components in it:

- ERTS
- kernel
- stdlib
- crypto
- public_key
- ssl
- ssh
- proxy

A visual representation of this can be seen in Figure [[fig:proxy_release]].

#+CAPTION: Visual representation of building the =proxy= release
#+NAME:   fig:proxy_release
[[./static/img/proxy_release_draft.png]]

Essentially, building an Erlang system is re-bundling the VM, along with some standard applications provided with the default distribution, together with your own apps and libraries.

*** Living in Erlang/OTP

Standard tools developed and used by the community such as rebar3 operate on the idea that what you write and publish are OTP applications, and as such contain all the functionality required to deal with them. That's a big shift from a lot of programming languages that only ask of you to have a function named =main()= somewhere in one of your files. This is why the programming language is often called =Erlang/OTP= rather than just 'Erlang': it's not just a programming language, it's a general development framework that mandates some basic structure for everything you do.

And everyone follows it, whether they are writing embedded software, blockchain systems, or distributed databases. It's OTP or nothing. Whereas other languages usually mandate nothing specific to get started, but then add some requirements later on (such as when integrating with a package manager), Erlang--and its entire community--expects you to just write OTP applications, which the rest of the tools can handle.

So the key to getting started fast in Erlang is to know the framework, which is often kept as more advanced material. Here we're going to do things upside down and start from a fully functional release, and then dig down into its structure. The next chapters will be dedicated to understanding how to work within these requirements.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/development/setup">← Prev</a></div>
  <div><a href="/docs/development/otp_applications">Next →</a></div>
</div>
#+END_EXPORT

** DONE OTP Applications
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: otp_applications
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

Since every component to be shipped in an Erlang/OTP release needs to be an OTP Application, it will do you a great good to understand what they are and how they work. In this chapter, we'll go over the basic structure of an OTP application, and what that means for your project.

*** Project Structure

We'll start by using the rebar3 templates, since they will allow us to create brand new projects that properly respect the directory structures expected by Erlang/OTP. Let's see which templates are available:

#+NAME: rebar3_new
#+BEGIN_SRC sh
$ rebar3 new
app (built-in): Complete OTP Application structure.
cmake (built-in): Standalone Makefile for building C/C++ in c_src
escript (built-in): Complete escriptized application structure
lib (built-in): Complete OTP Library application (no processes) structure
plugin (built-in): Rebar3 plugin project structure
release (built-in): OTP Release structure for executable programs
umbrella (built-in): OTP structure for executable programs
                     (alias of 'release' template)
#+END_SRC

Here's a table showing when they might be used:

| Type of Project                    | Template to use | Comments                                                            |
|------------------------------------+-----------------+---------------------------------------------------------------------|
| script or command line tool        | escript         | Requires Erlang to be installed by the user                         |
| a library (collection of modules)  | lib             | Can be used as a dependency                                         |
| a library (stateful processes)     | app             | Can be used as a dependency                                         |
| full executable program            | umbrella or app | Can be turned into a full release, the recommended deploy mechanism |
| a collection of multiple libraries | umbrella        | Cannot be used as a git dependency but each individual app could be published to hex |
| rebar3 extension                   | plugin          |                                                                     |
| compiling C code                   | cmake           | Also see the "pc" plugin for a portable way to compile C/C++        |

You can see the details of a given template by calling =rebar3 new help <template>=. See for example:

#+NAME: rebar3_new_lib
#+BEGIN_SRC sh
$ rebar3 new help lib
lib:
  built-in template
  Description: Complete OTP Library application (no processes) structure
  Variables:
    name="mylib" (Name of the OTP library application)
    desc="An OTP library" (Short description of the app)
    date="2019-03-15"
    datetime="2019-03-15T19:52:31+00:00"
    author_name="Fred Hebert"
    author_email="mononcqc@ferd.ca"
    copyright_year="2019"
    apps_dir="apps" (Directory where applications will be created if needed)
#+END_SRC

The values can be modified as desired on the command line, but those are the default variables. Let's see what we get by writing our own:

#+NAME: rebar3_new_mylib
#+BEGIN_SRC sh
$ rebar3 new lib mylib desc="Checking out OTP libs"
===> Writing mylib/src/mylib.erl
===> Writing mylib/src/mylib.app.src
===> Writing mylib/rebar.config
===> Writing mylib/.gitignore
===> Writing mylib/LICENSE
===> Writing mylib/README.md
#+END_SRC

Go to the =mylib= directory, and call =rebar3 compile= right away:

#+NAME: rebar3_mylib_compile
#+BEGIN_SRC sh
$ rebar3 compile
===> Verifying dependencies...
===> Compiling mylib
#+END_SRC

If you look at your directory structure, you should now have something like this in your project:


#+NAME: lib_structure
#+BEGIN_SRC sh
mylib/
├─ _build/
│  └─ default/
│     └─ lib/
│        └─ mylib/
│           ├─ ebin/
│           │  ├─ mylib.app
│           │  └─ mylib.beam
│           ├─ include/
│           ├─ priv/
│           └─ src/
│              └─ ...
├─ .gitignore
├─ LICENSE
├─ README.md
├─ rebar.config
├─ rebar.lock
└─ src/
   ├─ mylib.app.src
   └─ mylib.erl
#+END_SRC

The =_build/= directory is the build tool's playground, where it can stash all the artifacts it needs. You should never have to touch what is in there by hand, but should feel free to blow it away when you want. This directory is nonetheless interesting because it shows how rebar3 structures things.

Everything in =_build/= is split by [[https://www.rebar3.org/docs/profiles][profile]], which lets rebar3 build things differently (with different sets of dependencies and compiler options) whether they are built in the =default=, =test=, or =prod= profile—in fact, you can define as many profiles as you want, and compose them together. The rebar3 documentation explains how this works.

Within each profile, the =lib/= directory contains all the OTP applications that your project may use, outside of the standard distribution's libraries. You can see our =mylib= library replicated right there, but its directory structure is a bit different from what's directly at the project root:

- compiled =.erl= files are moved to the =ebin/= directory and now have the =.beam= extension
- there is a =mylib.app= file created, whereas the source application had =mylib.app.src=
- two symlinks have been added to =include/= and =priv/=. These will refer to matching directories at the root of the project, if they exist. The =include/= directory is meant for [[http://erlang.org/doc/reference_manual/macros.html#file-inclusion][header files]] (=.hrl=), and the =priv/= directory for any file that must be copied over and made available in production
- All other files at the root of the project have been discarded

If we had any dependencies (see [[/docs/development/dependencies][The Dependencies chapter]]), they would also be placed in the =_build/<profile>/lib/= directory.

In general, you will want to ignore the =_build/= directory entirely and avoid tracking it in your source control: if you look at the =.gitignore= file, you will see that it automatically ignores =_build/= for you.

Rebar3 chooses a license for you by default (because you should always choose a license if you plan on doing open source work), going for the [[https://en.wikipedia.org/wiki/Apache_License#Version_2.0][Apache 2.0]] license that Erlang ships with. Feel free to replace it as required. Rebar3 also sets up a =README= file that you might want to fix up and update with all the relevant contents. Don't be a jerk, write documentation!

Then we get to two interesting files, =rebar.config= and =rebar.lock=. The lock file is used by rebar3 to track which versions you were using for any dependency in the project, and should therefore be checked into source control. The [[/docs/development/dependencies][Dependencies chapter]] contains more details.

The =rebar.config= file is a complete declarative configuration file that exposes options for all the Erlang tools that rebar3 integrates with. [[https://www.rebar3.org/docs/configuration][The official documentation]] explains all the values possible, but by default it is quite empty. In fact, if you only want default values with no dependencies, you can just delete the file. As long as your project is structured like an OTP application, rebar3 will figure out what needs to be done.

Let's see what the standards are for that to happen.

*** What Makes a Lib an App

As with any other framework, there are some things you have to do to conform to its expectations. You've possibly guessed it, but the directory structure is one of the basic requirements of a framework like OTP. As long as your library has an =ebin/= directory once compiled with an =<appname>.app= file in it, the Erlang runtime system will be able to load your modules and run your code.

This basic requirement guides the project structure of the entire Erlang ecosystem. Let's look at what a built =.app= file looks like:

#+NAME: mylib.app
#+BEGIN_SRC erlang
$ cat _build/default/lib/mylib/ebin/mylib.app
{application, mylib, [
  {description, "Checking out OTP libs"},
  {vsn, "0.1.0"},     % version number (string)
  {registered, []},   % name of registered processes, if any
  {applications, [    % List of OTP application names on which
    kernel, stdlib    % yours depends at run-time. kernel and
  ]},                 % stdlib are ALWAYS needed
  {env, []},          % default configuration values ({Key, Val} pairs)
  {modules, [mylib]}, % list of all the modules in the application
  %% content below is optional, and for package publication only
  {licenses, ["Apache 2.0"]},
  {links, []}         % relevant URLs
]}.
#+END_SRC

This is essentially a metadata file that describes everything about the application. We've taken the time to annotate it for you, so check it out. A lot of the content in there is annoying to write by hand so if you look at the source file (=src/mylib.app.src=), you'll see that the fields are mostly pre-populated when you apply the rebar3 template. You may also notice that =modules= is empty. That's on purpose: rebar3 will populate the list for you when compiling your code.

By far, the most critical field to keep up to date in there is the =applications= tuple. It lets Erlang libraries know the order in which OTP applications must be started to work, and also allows build tools to build a dependency graph between all available OTP applications to know which to keep and which to remove from the distribution when building a release.

A more subtle thing to notice is that even if what we have here is a _library_, and it therefore has no processes to run, we still have the ability to define some configuration values (see the [[/docs/development/configuration][Configuration chapter]]), and dependencies must be respected. It is possible, for example, that our library is stateless, but uses a stateful HTTP client: the Erlang VM will then need to know when your code may or may not be safe to call.

For now, let's focus on what exactly is the difference between a stateless and a stateful application.

*** What Makes a Runnable App an App

To make a runnable application, we're going to use the "app" template in rebar3, and see what are the differences with a stateless application.

So let's grab your command line tool and run the following:

#+NAME: rebar3_new_myapp
#+BEGIN_SRC sh
$ rebar3 new app myapp
===> Writing myapp/src/myapp_app.erl
===> Writing myapp/src/myapp_sup.erl
===> Writing myapp/src/myapp.app.src
===> Writing myapp/rebar.config
===> Writing myapp/.gitignore
===> Writing myapp/LICENSE
===> Writing myapp/README.md
$ cd myapp
#+END_SRC

If you're careful, you'll see that we now have two modules instead of =<appname>.erl=: we have =<appname>_app.erl= and =<appname>_sup.erl=. We'll study them real soon, but first, let's focus on the top-level metadata file for the application, the =myapp.app.src= file:

#+NAME: myapp.app.src
#+BEGIN_SRC erlang
$ cat src/myapp.app.src
{application, myapp,
 [{description, "An OTP application"},
  {vsn, "0.1.0"},
  {registered, []},
  {mod, {myapp_app, []}},               % this is new!
  {applications, [kernel, stdlib]},
  {env,[]},
  {modules, []},

  {licenses, ["Apache 2.0"]},
  {links, []}
 ]}.
#+END_SRC

The only new line here is the ={mod, {<appname>_app, []}}= tuple. This tuple specifies a special module that can be called (=<appname>_app=) with some specific arguments (=[]=). When called, it is expected that this module will return the _process identifier_ (the _pid_) of a [[/docs/development/supervision_trees][supervision tree]].

If you go visit the =myapp_app= module, you will see what these callbacks are:

#+NAME: myapp_app.erl
#+BEGIN_SRC erlang
%%%-------------------------------------------------------------------
%% @doc myapp public API
%% @end
%%%-------------------------------------------------------------------

-module(myapp_app).
-behaviour(application).
%% Application callbacks
-export([start/2, stop/1]).

%%====================================================================
%% API
%%====================================================================

start(_StartType, _StartArgs) ->
    myapp_sup:start_link().

stop(_State) ->
    ok.
#+END_SRC

The =start/2= callback is called when the application is booted by the Erlang runtime system, at which point all of its dependencies—as defined in the =applications= tuple in the .app file—have already been started. This is where you can do one-time bits of initialization. In the template application, the only thing done is starting the root supervisor for the application.

The =stop/1= callback is called _after_ the whole supervision tree has been taken down once someone, somewhere, has decided to shut down the OTP application.

But all in all, this little additional =mod= line in the app file and the presence of a supervision structure are what differentiates a runnable application from a library application.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
If you do not want to care for a supervision tree and are only interested in getting a =main()= function to get going like you would in most other programming languages, =escript= might be a good option for you.

escript is a special C program that wraps the Erlang virtual machine. In wrapping it, it also introduces a small shim that retrofits the idea of a main() function to the release structure, by calling your code into the root Erlang process of the virtual machine.

The net result is that you can run interpreted code without having to bother about releases, OTP Applications, or supervision tree. You can read more about escripts in <a href="http://erlang.org/doc/man/escript.html">the official Erlang documentation</a>. Rebar3 also <a href="https://www.rebar3.org/docs/commands#escriptize">has a command to create complex escript bundles</a>.
#+end_notice

You now understand most of the weird stuff about Erlang/OTP's project structure and everything that has to do with these mysterious "OTP Applications". Starting with next chapter, we'll start digging a bit in supervision trees, so that you know how to set things up in a stateful runnable application.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/development/otp_high_level">← Prev</a></div>
  <div><a href="/docs/production">Next →</a></div>
</div>
#+END_EXPORT

** TODO Supervision Trees
:PROPERTIES:
:EXPORT_FILE_NAME: supervision_trees
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

The biggest difference between Erlang and every other programming language out there is not in its concurrency, but rather in its fault tolerance. Almost everything in the language [[https://ferd.ca/the-zen-of-erlang.html][was designed for fault tolerance]], and supervisors are one of the core parts of this design. In this chapter, we'll cover the basics of supervision trees, what is in a supervisor, and how to structure supervision trees in your own system. When we're done, you'll be able to set up and manage most of the state your system will need.

*** Basics

Erlang is a kind of two-tiered language. At the lowest level, you have a functional subset. All you get is a bunch of data structures, functions, and pattern matching to modify and transform them. The data is immutable, local, and side-effects are rather limited if not unnecessary. At the higher level, you have the concurrent subset, where long-lived state is managed, and where it gets communicated from process to process.

The functional subset is rather straightforward and easy to learn with any of the resources mentioned in the book's [[/docs/introduction][Introduction]]: you get a data structure, you change it, and return a new one. All program transformations are handled as pipelines of functions applied to a piece of data to get a new one. It's a solid foundation on which to build.

The challenge of functional languages comes when you have to handle side-effects. How will you take something like a program's configuration and pass it through the entire stack? Where is it going to be stored and modified? How do you take something inherently mutable and stateful, like a network stream, and embed it in an immutable and stateless application?

In most programming languages, this is all done in a rather informal and ad-hoc matter. In object-oriented languages, for example, we would tend to pick where side-effects live according to the [[https://en.wikipedia.org/wiki/Domain-driven_design][boundaries of their domain]], possibly while trying to respect principles such as [[https://deviq.com/persistence-ignorance/][persistence ignorance]] or [[https://fideloper.com/hexagonal-architecture][hexagonal architecture]].

In the end what you may end up with is a kind of layered system where you hopefully have a bunch of pure domain-specific entities in the core, a bunch of interaction mechanisms on the outer edge, and a few layers in-between whose role is to coordinate and wrap all activities between entities:

#+CAPTION: Hexagonal architecture as frequently recommended in OO design
#+NAME: fig:hexagonal
[[./static/img/hexagonal.png]]

The kind of structure this gives is usually very explicit regarding the domain modelling, but rather ambiguous with regards to how interactions and side-effects should be structured. How should failures contacting an external service bubble up? How would the inability to save a transformation on a core domain entity impact the outer-edge interactions when it comes from some event-driven mechanism?

The domain modelling you'd do in object-oriented systems can still be done in Erlang. We'd stick all of that in the functional subset of the language, usually in a library application that regroups all the relevant modules that do the changes and transformation you need, or in some cases within specific modules of a runnable application.

The richness of failure and fault handling, however, will be explicitly encoded within a supervision structure. Because the stateful parts of the system are encoded using processes, the structure of dependencies and their respective instantialization is all laid out for everyone to see:

#+CAPTION: Sample supervision tree
#+NAME: fig:suptree
[[./static/img/suptree.png]]

In such a tree, all the processes are started depth-first, from left to right. This means that before the cache process and [[http://erlang.org/doc/man/ets.html][ETS table]] can be started, the database's supervision structure (and all its workers), must first be started. Similarly, before the HTTP server and its handler can be started, the whole business domain subtree will have been to be created, and since it depends on the cache table, we will similarly ensure that this one (and the database workers) will be ready to go.

This supervision structure defines how the release starts, but it will also define how it shuts down: depth-first, from right to left. And even more than this, each supervisor can set its own policy and tolerance for child failures. This means that they also define which kind of _partial failures_ are allowed or not in the system. Should the node still run if it can't talk to the database? Maybe it should, but it can't stay up if the cache becomes unavailable.

In a nutshell, where functional stuff can be used for the domain-specific handling, the flow of state, events, and interactions with the outside world is codified and explicit in stateful components, giving us a whole new way to handle errors and initialization.

We'll see how to do this in a moment, but first, let's review how supervisors work.

*** What's in a Supervisor

Supervisors are one of the simplest behaviours in all of Erlang/OTP on the surface. They take a single =init/1= callback, and that's about it. The callback allows to define the children of each supervisor, and some basic policies in how they react to failures of many kind.

There are 3 types of policies to handle:

- The supervisor type
- The restart policy of a child
- The frequency of failures to be accepted

Each of them is simple enough in isolation, but choosing good ones can become a bit tricky. Let's start with the supervisor type:

#+CAPTION: The three supervisor types
#+NAME: fig:suptypes
[[./static/img/suptypes.png]]

There are three types of strategies:

1. =one_for_one=, which states that each child is independent from the other children. If one dies, the others don't need any replacing or modification.
  - =simple_one_for_one= is a specialization of =one_for_one= in the case where all the children are of the same type (say a worker pool), which is faster and lighter weight
2. =rest_for_one= encodes a linear dependency between the supervisor's children. If one of them dies, all those started _after_ it must be restarted, but not those started before. In a scenario where process =C= depends on process =B=, and =B= depends on process =A=, the =rest_for_one= strategy allows efficient encoding of their dependency structure.
3. =one_for_all= is a strategy by which if any child dies, then all of them must also be restarted. This is the type of supervisor you'd want to use when there is a strong interdependency between all children; if any one of them restarts, there's no easy way for the other ones to recuperate, and so they should also be restarted.

These strategies are effectively all about how errors should propagate between children of the supervisor. The next bit to consider is how each of the processes that fail should, on their own, be handled by the supervisor after the signals have been propagated.

| Restart Policy | On Normal Exit | On Abnormal Exit |
|----------------+----------------+------------------|
| permanent      | restart        | restart          |
| transient      | stay dead      | restart          |
| temporary      | stay dead      | stay dead        |

This lets you say that some processes are expected to never stop (permanent), some are expected to stop (transient), and some are expected to fail (temporary).

The final bit of configuration we can set is the frequency at which restarts are allowed. This is done through two parameters, =intensity= and =period=, which respectively stand for how many crashes have been spotted and during how many seconds they took place. We can then specify that a supervisor should tolerate only one crash per hour, or a dozen per second if we want it so.

This is how you declare a supervisor:

#+NAME: myapp_sup
#+BEGIN_SRC erlang
-module(myapp_sup).
-behaviour(supervisor).

%% API
-export([start_link/0]).

%% Supervisor callbacks
-export([init/1]).

-define(SERVER, ?MODULE).

start_link() ->
    supervisor:start_link({local, ?SERVER}, ?MODULE, []).

init([]) ->
    {ok, {{one_for_all, 1, 10}, [ % one failure per 10 seconds
        #{id => internal_name,                % mandatory
          start => {mymod, function, [args]}. % mandatory
          restart => permanent,               % optional
          shutdown => 5000,                   % optional
          type => worker,                     % optional
          modules => [mymod]}                 % optional
    ]}}.
#+END_SRC

You can define as many children as you want at once in there (except for =simple_one_for_one=, which [[http://erlang.org/doc/man/supervisor.html#Module:init-1][expects a description template]]). Other arguments you can specify for a child include =shutdown=, which gives a number of milliseconds to wait for the proper termination of the child (or =brutal_kill= to kill it right away), and a definition on whether a process is a =worker= or a =supervisor=. This =type= field, along with =modules=, are only used when doing live code upgrades with releases, and the latter can generally be ignored and be left to its default value.

That's all that's needed. Let's see how we can put that in practice.

*** Trying Your Own Supervisor

Let's try to add a supervisor with a worker to an application, running what is essentially the heaviest _Hello World_ on the planet. We'll build a whole release for that:

#+NAME: hello_world
#+BEGIN_SRC sh
$ rebar3 new release hello_world
===> Writing hello_world/apps/hello_world/src/hello_world_app.erl
===> Writing hello_world/apps/hello_world/src/hello_world_sup.erl
===> Writing hello_world/apps/hello_world/src/hello_world.app.src
===> Writing hello_world/rebar.config
===> Writing hello_world/config/sys.config
===> Writing hello_world/config/vm.args
===> Writing hello_world/.gitignore
===> Writing hello_world/LICENSE
===> Writing hello_world/README.md
$ cd hello_world
#+END_SRC

You should recognize the release structure, where all OTP applications are in the =apps/= subdirectory.

Open up =hello_world_sup= module, and make sure it looks like this:


#+NAME: hello_world_sup.erl
#+BEGIN_SRC erlang
%%%----------------------------------------------------------
%% @doc hello_world top level supervisor.
%% @end
%%%----------------------------------------------------------

-module(hello_world_sup).
-behaviour(supervisor).

-export([start_link/0]).
-export([init/1]).

-define(SERVER, ?MODULE).

start_link() ->
    supervisor:start_link({local, ?SERVER}, ?MODULE, []).

init([]) ->
    SupFlags = #{strategy => one_for_all,
                 intensity => 0,
                 period => 1},
    ChildSpecs = [
        #{id => main,
          start => {hello_world_serv, start_link, []}}
    ],
    {ok, {SupFlags, ChildSpecs}}.
#+END_SRC

This establishes a single child, which will be in the module =hello_world_serv=. This will be a straightforward =gen_server= that does nothing, using only its =init= function:

#+NAME: hello_world_serv
#+BEGIN_SRC erlang
-module(hello_world_serv).
-export([start_link/0, init/1]).

start_link() ->
    gen_server:start_link(?MODULE, [], []).

init([]) ->
    %% Here we ignore what OTP asks of us and just do
    %% however we please.
    io:format("Hello, heavy world!~n"),
    halt(0). % shut down the VM without error
#+END_SRC

This file just starts an OTP process, outputs =Hello, heavy world!=, and then shuts the whole virtual machine down.

Let's build a release and see what happens:

#+BEGIN_SRC sh
$ rebar3 release
===> Verifying dependencies...
===> Compiling hello_world
===> Starting relx build process ...
===> Resolving OTP Applications from directories:
          /Users/ferd/code/self/adoptingerlang/hello_world/_build/default/lib
          /Users/ferd/code/self/adoptingerlang/hello_world/apps
          /Users/ferd/bin/erls/21.1.3/lib
===> Resolved hello_world-0.1.0
===> Dev mode enabled, release will be symlinked
===> release successfully created!
#+END_SRC

And now we can start it. We'll use the =foreground= argument, which means we'll boot the release to see all of its output, but do so in a non-interactive mode (without a shell):

#+BEGIN_SRC sh
$ ./_build/default/rel/hello_world/bin/hello_world foreground
<debug output provided by wrappers bundled with rebar3>
Hello, heavy world!
#+END_SRC

What happens here is that the tools generate a script at =/_build/default/rel/hello_world/bin/hello_world=. This script puts a bunch of stuff together to make sure your release boots with all the right configuration and environment values.

Everything starts with the virtual machine starting, and eventually spawning the root process in Erlang itself. The =kernel= OTP application boots, and then sees in the config data that it has to start the =hello_world= application.

This is done by calling =hello_world_app:start/2=, which in turn calls =hello_world_sup=, which starts the =hello_world_serv= process, which outputs text and then makes a hard call to the VM telling it to shut down.

And that's what we just did. Supervisors only start and restart processes; they're simple, but their power comes from how they can be composed and used to structure a system.

*** Structuring Supervision Trees

The most complex part of supervisors isn't their declaration, it's their composition. They're a simple tool up to a complex task. In this section, we'll cover why supervision trees can work, and how to best structure them to gain the most out of them.

**** What Makes Supervisors Work

Everyone has heard "have you tried turning it off and on again?" as a general bug-fixing approach. It works surprisingly often, and Erlang supervision trees operate under that principle. Of course, restarting can't solve all bugs, but it can cover a lot.

The reason restarting works is due to the nature of bugs encountered in production systems. To discuss this, we have to refer to the terms _Bohrbug_ and _Heisenbug_ coined by [[https://www.hpl.hp.com/techreports/tandem/TR-85.7.pdf][Jim Gray in 1985]]. Basically, a bohrbug is a bug that is solid, observable, and easily repeatable. They tend to be fairly simple to reason about. Heisenbugs by contrast, have unreliable behaviour that manifests itself under certain conditions, and which may possibly be hidden by the simple act of trying to observe them. For example, concurrency bugs are notorious for disappearing when using a debugger that may force every operation in the system to be serialised.

Heisenbugs are these nasty bugs that happen once in a thousand, million, billion, or trillion times. You know someone's been working on figuring one out for a while once you see them print out pages of code and go to town on them with a bunch of markers.

With these terms defined, let's look at how easy it should be to find bugs in production:

| Type of Feature | Repeatable              | Transient |
|-----------------+-------------------------+-----------|
| Core            | Easy                    | Hard      |
| Secondary       | Easy (often overlooked) | Hard      |

If you have bohrbugs in your system's core features, they should usually be very easy to find before reaching production. By virtue of being repeatable, and often on a critical path, you should encounter them sooner or later, and fix them before shipping.

Those that happen in secondary, less used features, are far more of a hit and miss affair. Everyone admits that fixing all bugs in a piece of software is an uphill battle with diminishing returns; weeding out all the little imperfections takes proportionally more time as you go on. Usually, these secondary features will tend to gather less attention because either fewer customers will use them, or their impact on their satisfaction will be less important. Or maybe they're just scheduled later and slipping timelines end up deprioritising their work.

Heisenbugs are pretty much impossible to find in development. Fancy techniques like formal proofs, model checking, exhaustive testing or property-based testing may increase the likelihood of uncovering some or all of them (depending on the means used), but frankly, few of us use any of these unless the task at hand is extremely critical. A once in a billion issue requires quite a lot of tests and validation to uncover, and chances are that if you've seen it, you won't be able to generate it again just by luck.

So let's take a look at the previous table of bug types, but let's focus on how often they _will_ happen in production:

| Type of Feature | Repeatable | Transient |
|--------+------------+-----------|
| Core | Should Never | All the time |
| Secondary | Pretty often | All the time |


First of all, easy repeatable bugs in core features should just not make it to production. If they do, you have essentially shipped a broken product and no amount of restarting or support will help your users. Those require modifying the code, and may be the result of some deeply entrenched issues within the organisation that produced them.

Repeatable bugs in side-features will pretty often make it to production. This is often a result of not taking or having the time to test them properly, but there's also a strong possibility that secondary features often get left behind when it comes to partial refactorings, or that the people behind their design do not fully consider whether the feature will coherently fit with the rest of the system.

On the other hand, transient bugs will show up all the damn time. Jim Gray, who coined these terms, reported that on 132 bugs noted at a given set of customer sites, only one was a Bohrbug. 131/132 of errors encountered in production tended to be heisenbugs. They're hard to catch, and if they're truly statistical bugs that may show once in a million times, it just takes some load on your system to trigger them all the time; a once in a billion bug will show up every 3 hours in a system doing 100,000 requests a second, and a once in a million bug could similarly show up once every 10 seconds on such a system, but their occurrence would still be rare in tests.

That's a lot of bugs, and a lot of failures if they are not handled properly. Let's rework the table, but now we're considering whether restarts can handle these faults:

| Type of Feature | Repeatable | Transient |
|--------+------------+-----------|
| Core | No | Yes |
| Secondary | It depends | Yes |

For repeatable bugs on core features, restarting is useless. For repeatable bugs in less frequently used code paths, it depends; if the feature is a thing very important to a very small amount of users, restarting won't do much. If it's a side-feature used by everyone, but to a degree they don't care much about, then restarting or ignoring the failure altogether can work well.

For transient bugs though, restarting is extremely effective, and they tend to be the majority of bugs you'll meet live. Because they are hard to reproduce, that their showing up is often dependent on very specific circumstances or interleavings of bits of state in the system, and that their appearance tends to be in a very small fraction of all operations, restarting tends to make them disappear altogether.

Supervisors allows a part of your system hit by such a bug to roll back to a known stable state. Once you've rolled back to that state, trying again is unlikely to hit the same weird context that caused the first bug. And just like that, what could have been a catastrophe has become little more than a hiccup for the system, something users quickly learn to live with.

**** It's About the Guarantees

One very important part of Erlang supervisors and their supervision trees is that their start phase is synchronous. Each OTP Process started has a period during which it can do its own thing, preventing the entire boot sequence of its siblings and cousins to come. If the process dies there, it's retried again, and again, until it works, or fails too often.

That's where people make a very common mistake. There isn't a backoff or cooldown period before a supervisor restarts a crashed child. When people write a network-based application and try to set up a connection in this initialization phase, and that the remote service is down, the application fails to boot after too many fruitless restarts. Then the system may shut down.

Many Erlang developers end up arguing in favor of a supervisor that has a cooldown period. This sentiment is wrong for one simple reason: it's all about the guarantees.

Restarting a process is about bringing it back to a stable, known state. From there, things can be retried. When the initialization isn't stable, supervision is worth very little. An initialized process should be stable no matter what happens. That way, when its siblings and cousins get started later on, they can be booted fully knowing that the rest of the system that came up before them is healthy.

If you don't provide that stable state, or if you were to start the entire system asynchronously, you get very little benefit from this structure that a =try ... catch= in a loop wouldn't provide.

Supervised processes provide guarantees in their initialization phase, not a best effort. This means that when you're writing a client for a database or service, you shouldn't need a connection to be established as part of the initialization phase unless you're ready to say it will always be available no matter what happens.

You could force a connection during initialization if you know the database is on the same host and should be booted before your Erlang system, for example. Then a restart should work. In case of something incomprehensible and unexpected that breaks these guarantees, the node will end up crashing, which is desirable: a pre-condition to starting your system hasn't been met. It's a system-wide assertion that failed.

If, on the other hand, your database is on a remote host, you should expect the connection to fail. In this case, the only guarantee you can make in the client process is that your client will be able to handle requests, but not that it will communicate to the database. It could return ={error, not_connected}= on all calls during a net split, for example.

The reconnection to the database can then be done using whatever cooldown or backoff strategy you believe is optimal, without impacting the stability of the system. It can be attempted in the initialization phase as an optimization, but the process should be able to reconnect later on if anything ever disconnects.

If you expect failure to happen on an external service, do not make its presence a guarantee of your system. We're dealing with the real world here, and failure of external dependencies is always an option. 

Of course, the libraries and processes that call the client will then error out if they didn't expect to work without a database. That's an entirely different issue in a different problem space, but not one that is always impossible to work around. For example, let's pretend the client is to a statistics service for Ops people—then the code that calls that client could very well ignore the errors without adverse effects to the system as a whole. In other cases, an event queue could be added in front of the client to avoid losing state when things go sour.

The difference in both initialization and supervision approaches is that the client's callers make the decision about how much failure they can tolerate, not the client itself. That's a very important distinction when it comes to designing fault-tolerant systems. Yes, supervisors are about restarts, but they should be about restarts to a stable known state.

**** Growing Trees

When you structure Erlang programs, everything you feel is fragile and should be allowed to fail has to move deeper into the hierarchy, and what is stable and critical needs to be reliable is higher up. Supervision structures allow the encoding of partial failures and fault propagation, so we must think properly about all of these things. Let's take a look at our sample supervision tree again:

#+NAME: fig:suptree_repeat
[[./static/img/suptree.png]]

If a worker in the =DB= subtree dies, and =DB= is a supervisor with a =one_for_one= strategy, then we are encoding that each worker is allowed to fail independently from each other. On the other hand, if =event_sup= has a =rest_for_one= strategy, we are encoding in our system that the worker handling subscriptions _must_ restart if the event listener dies; we say that there is a direct dependency.

Implicitly, there is also a statement that the event handling subtree is not directly impacted by the database, as long as it has managed to successfully boot at some point.

This supervision tree can be read like a schedule and a map to the system faults. The HTTP server won't start unless the domain-specific workers are available, and the HTTP handler failing will not do anything that might compromise the database cache. Of course, if the HTTP handler relies on the domain worker, which relies on the cache's ETS table and that table vanishes, then all these processes will may together.

What's truly interesting here is that we can at a glance know how even unknown failures may impact our system. I don't need to know _why_ a database worker may fail, whether it's due to a disconnection, a dying database, or a bug in the protocol implementation; I know that no matter what, this should leave the cache in place, and possibly let me do stale reads until the database sub-tree becomes available again.

This is where a child's restart policy, combined with the supervisor's accepted failure frequency comes in play. If all the workers and their supervisor are marked =permanent=, then there is a possibility that frequent crashes will take down the whole node. However, you can do a  special little trick:

#+CAPTION: The manager worker pattern
#+NAME: fig:manager
[[./static/img/manager.png]]

1. mark the workers as =permanent= or =transient=, so that if they fail they get restarted
2. mark the workers' direct supervisor (in the square) as =temporary=, so that if it fails, it gives up and does not get restarted
3. add a new supervisor above it (this one can use any policy you want), but make it =one_for_one=.
4. add a new process under the new supervisor (a sibling of the =temporary= supervisor). Have this process _linked_ to the old supervisor. This is the _manager_.

The temporary supervisor can be used to tolerate an acceptable restart frequency. It could say that it's normal for a worker to die every two minutes, for example. However, if we exceed this threshold, something bad is happening, and we want to stop retrying without risking to destabilize the node. The supervisor shuts down, and since it's temporary, the super-supervisor (above the square) will just stay there doing nothing.

The manager can then look at whether the =sup= supervisor is alive or dead, and apply any policy it want when it comes to restarting it: use an exponential backoff, wait until a [[https://en.wikipedia.org/wiki/Circuit_breaker_design_pattern][circuit breaker]] untrips, wait for an external service registry to say the dependent service is healthy again, or ask for user input on what to do. The manager can then ask its own parent supervisor to restart the temporary supervisor, which will then restart its own workers. 

This is one of the few _design patterns_ in Erlang. Because smart systems make stupid mistakes, we want to keep the supervisors as simple and predictable as they can be. The manager is us grafting a brain onto the supervisor, and making fancier decisions. This lets us separate policies for transient errors from policies for more major or persistent faults that can't just be dealt with through restarting.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
This pattern can be adapted however you want. The authors have, for example, used these two other variants for restart management:

- multiple supervision trees are nested into each other, each representing a worker pool for a physical device. Each physical device is allowed to fail, go offline, or lose power. The managing process would routinely compare the running subtrees to a configuration service that was off-site. It would then start all the subtrees that were missing, and shut down all those that no longer existed. This let the manager handle run-time configuration synchonisation while also handling restarts for tricky hardware failure scenarios.
- The manager does nothing. However, the Erlang release shipped with a script that could be called by an operator. The script sent a message to the manager, asking it to restart the missing subtree. This variant was used because the subtree died only in the rarest of occasions (a whole region's storage going down) without wanting to kill the rest of the system, but upon recovery, operators could re-enable traffic that way.

While it would be difficult to bake that kind of functionality in a generic supervisor, a manager can easily provide the flexibility required for tailor-made solutions of this kind.
#+end_notice

One exercise we would recommend you do is to take your system, and then draw its supervision tree on a white board. Go through all the workers and supervisors, and ask the following questions:

- Is it okay if this dies?
- Should other processes be taken down with this one?
- Does this process depend on anything else that will be weird once it restarts?
- How many crashes are too many for this supervisor?
- If this part of the system is flat out broken, should the rest of it keep working or should we give up?

Discuss these with your team. Shuffle supervisors around, adjust the strategies and policies. Add or remove supervision layers, and in some cases, add managers. 

Repeat this exercise from time to time, and eventually do some [[https://principlesofchaos.org/][chaos engineering]] by killing Erlang processes on a running node to see if it behaves and recovers the way you think it should (you can of course do chaos engineering on entire nodes, as is more common). What you'll end up with is a fault tolerant piece of code. You will also build a team with a strong understanding of the failure semantics that are baked in their system, with a good mental model of how things should break down when they inevitably do. This is worth its weight in gold.

** TODO Dependencies
:PROPERTIES:
:EXPORT_FILE_NAME: dependencies
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

** TODO Multi-App Projects
:PROPERTIES:
:EXPORT_FILE_NAME: umbrella_projects
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

** TODO Rebar3 Shell
:PROPERTIES:
:EXPORT_FILE_NAME: rebar3_shell
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

** TODO Configuration
:PROPERTIES:
:EXPORT_FILE_NAME: configuration
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

** TODO Documentation
:PROPERTIES:
:EXPORT_FILE_NAME: documentation
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

** TODO Testing
:PROPERTIES:
:EXPORT_FILE_NAME: testing
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

*** Common Test
*** Coverage
*** Dialyzer

Example from =service_discovery=: adding =port_name= to the endpoints:

#+BEGIN_SRC erlang
-spec endpoint_from_json(unicode:unicode_binary(), map()) -> {ok, service_discovery:endpoint()} |
                                                             {error, term()}.
endpoint_from_json(ServiceName, #{<<"ip">> := IPString,
                                  <<"port">> := Port,
                                  <<"tags">> := Tags}) ->
    case inet:parse_address(binary_to_list(IPString)) of
        {ok, IP} ->
            {ok, #{service_name => ServiceName,
                   ip => IP,
                   port => Port,
                   tags => Tags}};
        {error, einval}=Error ->
            Error
    end;
endpoint_from_json(_, _) ->
    {error, bad_endpoint_json}.
#+END_SRC

Missing =port_name= in return results in map that does not match the `service_discovery:endpoint()` spec:

#+BEGIN_SRC erlang
apps/service_discovery_http/src/sdh_handler.erl
  42: The pattern 'ok' can never match the type {'error','bad_endpoint_json' | 'einval'}
 130: The pattern {'ok', Endpoint} can never match the type {'error','bad_endpoint_json' | 'einval'}
#+END_SRC

*** XRef
*** Continuous Integration
**** Docker Compose
**** CircleCI

CircleCI has a very flexible CI offering that integrates well with services like Github. One of this author's favorite features of CircleCI when working with Erlang is the built in support for serving up test artifacts after a test run. This is especially useful because Common Test will output details about test runs as HTML. Plus CircleCI supports displaying information about a test run based on JUnit structured XML which CT can output using the =surefire= hook.

The =surefire= hook can be enabled in =rebar.config= with the following =ct_opts=:

#+BEGIN_SRC erlang
%% generate junit xml report from test results
{ct_opts, [{ct_hooks, [cth_surefire]}]}.
#+END_SRC

CircleCI has no official support for rebar3 projects, but they do host Erlang docker images which contain rebar3 and tools necessary for interacting with CircleCI's cache and artifact store. But thanks to [[https://circleci.com/orbs/][CircleCI Orbs]] it is easy to get started with rebar3 on CircleCI and take advantage of its unique features. CircleCI Orbs are reusable commands, executors and jobs that make writing workflows simpler. The [[https://circleci.com/orbs/registry/orb/tsloughter/rebar3][rebar3 Orb]] takes care of caching built dependencies and moving artifacts, like CT's HTML output, with CircleCI's artifacts commands.

#+BEGIN_SRC yaml
version: 2.1

orbs:
  rebar3: tsloughter/rebar3@0.7.0

workflows:
  version: 2.1
  build_and_test:
    jobs:
    - rebar3/compile

    - rebar3/xref:
        requires:
        - rebar3/compile
    - rebar3/dialyzer:
        requires:
        - rebar3/compile
    - rebar3/ct:
        requires:
        - rebar3/compile
#+END_SRC

The following screenshot show's CircleCI's workflow page for a project that runs Common Test, Dialyzer and xref in parallel followed by cover which is reported to [[https://codecov.io][codecov.io]]:

[[./static/img/circleci_ct_success_workflow.png]]

Clicking on the =rebar3/ct= job in the workflow graph goes to the job page which has the output from the steps in the job, a test summary based on the JUnit XML and a tab with artifacts kept after the job completed:

[[./static/img/circleci_ct_junit_success.png]]

Going to the artifacts tab we see the contents from =_build/test/logs=:

[[./static/img/circleci_ct_artifacts.png]]

Following the link for =index.html= will open a new browser tab for a url like https://498-59958463-gh.circle-artifacts.com/0/common_test/index.html where you can browse all Common Test test result pages:

[[./static/img/circleci_ct_html.png]]

Lastly, this image shows an example of the test summary, from the =cth_surefire= output, for a failed test case in a suite:

[[./static/img/circleci_ct_junit_failure.png]]


**** Microsoft's visual studio output
 https://github.com/ferd/trx

**** CirrusCI
**** Google Cloud Build

#+BEGIN_SRC yaml
steps:
- name: 'docker/compose:1.24.0'
  args: ['-f', 'docker-compose.yml', 'up', '-d']

- name: 'gcr.io/kaniko-project/executor:latest'
  args:
  - --target=releaser
  - --dockerfile=./Dockerfile.cb
  - --build-arg=BASE_IMAGE=$_BASE_IMAGE
  - --build-arg=RUNNER_IMAGE=$_RUNNER_IMAGE
  - --destination=gcr.io/$PROJECT_ID/service_discovery:tester-$BUILD_ID
  - --cache=true
  - --cache-ttl=48h

- name: 'gcr.io/cloud-builders/docker'
  args: ['run', '--network', 'workspace_sd_net', '-e', 'BUILD_ID=$BUILD_ID', '--entrypoint', 'rebar3', 'gcr.io/$PROJECT_ID/service_discovery:tester-$BUILD_ID', 'ct']
#+END_SRC

** TODO Hard Things to Get Right
:PROPERTIES:
:EXPORT_FILE_NAME: hard_to_get_right
:EXPORT_HUGO_MENU: :menu main :parent development
:END:

You probably have a fairly decent understanding of how an Erlang project should be structured by now. Along with any guide about the language basics, you should be mostly good to get started. However, there are a few complex topics that are currently not covered well in any of the Erlang documentation out there. In this chapter, we'll go through the task of providing guidance around handling Unicode, time, and SSL/TLS configurations.

Do note that those are three complex topics on their own. While we're going to provide some background information on each of them, you are not going to be an expert at handling them right away—it just helps to know how much complexity exists to avoid huge mistakes.

*** Handling Unicode

Erlang's got quite a bad reputation for string handling. A lot of this comes from not having a dedicated string type, and for years, not having decent unicode support outside of community libraries. While the former has not changed, there are some strengths to that approach, and the latter has finally been addressed in recent Erlang releases.

**** Background Information on Unicode

Unicode, in a nutshell, is a set of standards about how text should be handled in computers, regardless of the user's language (real languages, not programming languages). It has become a huge specification with a lot of exceedingly complex considerations about all kinds of details, and developers are often reasonably getting lost in it.

Even without knowing all about Unicode, you can know _enough_ to be effective and avoiding all of the most glaring mistakes. To get started, we'll introduce a bit of terminology:

- _character_: the word "character" is defined kind of vaguely in Unicode. Everytime you see the word "character", imagine that the person talking to you is using a very abstract term that can mean anything from a letter in a given alphabet, some drawings (like emojis), accents or letter modifiers (like =¸= and =c=, which becomes =ç=), control sequences (like "backspace"), and so on. It's mostly a common but inaccurate way to refer to bits of text, and you must not attach too much meaning to it. Unicode has better and exact definitions of its own.
- _code point_: the Unicode standard defines all the possible basic fundamental "characters" you can have in a big list (and then some), each of which has a unique identifier. That identifier is the _code point_, often denoted =U+<hexadecimal number>=. For example, "M" has the code point =U+004D=, and ♻ has the code point =U+267B=. You can see [[https://unicode-table.com][the Unicode Table]] for the full list.
- _encoding_: While code points are just integers that represent an index by which you can look up, this is not sufficient to represent text in programming languages. Historically, a lot of systems and programming languages used bytes (=0..255=) to represent all valid characters in a language. If you needed more characters, you had to switch languages. To be compatible with all kinds of systems, Unicode defines _encodings_, which allows people to represent sequences of code points under various schemes. _UTF-8_ is the most common one, using bytes for everything. Its representation shares the same basic structure as [[https://en.wikipedia.org/wiki/ASCII][ASCII]] or [[https://en.wikipedia.org/wiki/ISO/IEC_8859-1][Latin-1]] did, and so it became extremely popular in Latin and Germanic languages. _UTF-16_ and _UTF-32_ are two alternatives that represent on wider sequences (16 or 32 bits).
- _code unit_: A code unit specifies the way a given code point is encoded in a given encoding. Each code point takes from 1 to 4 code units for UTF-8. For example, =F= takes only =46= as a code unit in UTF-8, =0046= in UTF-16, and =00000046= in UTF-32. By comparison, =©= has the code point =U+00A9=, but is representable as _two_ code units in UTF-8 (=C2= and =A9=), and one code unit in UTF-16 and UTF-32 (=00A9= and =000000A9= respectively).
- _glyph_: the graphic representation of a character. For example, =U+2126= is "Ohm sign", represented as =Ω=, and =U+03A9= is "Greek Capital Letter Omega", also represented by a similar-looking =Ω=. In some [[https://en.wikipedia.org/wiki/Typeface][Typefaces]] they will be the same, in some not. Similarly, the letter "a" is possibly representable by glyphs looking like "а" or "α".  Some code points have no associated glyphs ("backspace", for example), and some glyphs can be used for _ligatures_ representing multiple codepoints at once (such as =æ= for =ae=).
- _grapheme cluster_: all of the terms mentioned so far have to do with very abstract concepts. Unicode has funky stuff like _combining marks_ and ways to join multiple code points into one "character". This can become super confusing because what a user considers a character and what a programmer considers a character are not the same thing. A _grapheme cluster_ is a term meaning "a unit of text the user perceives as being a single character". For example, the letter "ï" is composed of two code-points: the latin small letter =i= (=U+0069=), and a =combining= [[https://en.wikipedia.org/wiki/Diaeresis_(diacritic)][diaeresis]] (=¨= as =U+0308=). So for a programmer, this will look like two  code points, encoded with 3 code units in UTF-8. For a user though, they will expect that pressing "backspace" will remove both the diaeresis _and_ the letter "i".

That's a lot of stuff, but those are important to know about. There is no direct relationship between how a programmer writes a character and how it ends up displayed to a user.

One particularly fun example is the _ARABIC LIGATURE BISMILLAH AR-RAHMAN AR-RAHEEM_, which is a single code point (=U+FDFD=), but represented graphically as "﷽". This is currently the widest "character" in the Unicode standard. This represents an entire arabic sentence, and was added to the standard because it turns out to be a legal requirement in multiple Urdu documents, without their keyboard layouts having the ability to type arabic. It's a great bit of unicode to mess with UI folks.

Most languages have problems with the fact that graphical (and logical) representations are not equal to the underlying codes creating the final character. Those exist for all kinds of possible ligatures and assemblies of "character parts" in various languages, but for Emojis, you can also make a family by combining individual people: 👩‍👩‍👦‍👦 is a family composed of 4 components with combining marks: 👩 + 👩 + 👦 + 👦, where =+= is a special combining mark (a [[https://www.fileformat.info/info/unicode/char/200d/index.htm][zero width joiner]]) between two women and two boys (if you are viewing this document on an older browser, with an older font, or are checking out the PDF version of this book, then you might just see four people instead of a family.) If you were to go and consume that sequence byte by byte or codepoint by codepoint, you would break the family apart and change the semantic meaning of the text.

If you edit the text in a text editor that traditionally has good support for locales and all kinds of per-language rules, such as Microsoft Word (one of the few we know to do a great job of automatically handling half-width spaces and non-breakable spaces when languages ask for it), pressing backspace on 👩‍👩‍👦‍👦 will remove the whole family as one unit. If you do it in FireFox or Chrome, deleting that one 'character' will take you 7 backstrokes: one for each 'person' and one for each zero-width joining character. Slack will consider them to be a single character and visual studio code behaves like the browsers (even if both are electron apps), and notepad.exe or many terminal emulators will instead expand them as 4 people and implicitly drop the zero-width joining marks.

This means that no matter which programming language you are using, if strings look like arrays where you can grab "characters" by position or through some index, you are likely to have serious problems.

Worse than this, some "characters" have more than one acceptable encoding in Unicode. The character =é= can be created by encoding a single code point (=U+00E9=), or as the letter =e= (=U+0065=) followed by =´= (=U+0301=). This will logically be the same letter =é= in French, but two strings using the two different forms will not compare equal. Unicode therefore introduces concepts such as [[http://unicode.org/reports/tr15/][Normalization]], which allows to standardize the representation of strings according to four possible standards: NFC, NFD, NFKC, and NFKD (if you don't know which one to use, stick to NFC).

Sorting strings also introduces concepts such as [[http://unicode.org/reports/tr10/][Collations]], which require knowing the current language being used when sorting.

In short, to support Unicode well in your programs, no matter in which programming language you work, you must treat strings as a kind of opaque data type that you manipulate exclusively through Unicode-aware libraries. Anything else and you are manipulating _byte sequences_ or _code point sequences_ and may end up breaking things unexpectedly at the human-readable level.


**** Handling Strings in Erlang

Erlang's support for strings initially looks a bit funky: there is no dedicated string type. When considering all the complexity of Unicode though, it's not actually all that bad. It's usually as tricky to work with just _one_ string type as it would be to work with _no_ string types at all, because of all the possible alternative representations.

Folks using programming languages with variable string types that reflect multiple encodings may feel good about themselves right now, but you'll see that Erlang has pretty decent Unicode support all things considered—only collations appear to be missing.

***** Data Types

In Erlang, you have to be aware of the following possible encodings for strings:

- ="abcdef"=: a string, which is directly made up of Unicode code points in a list. This means that if you write =[16#1f914]= in your Erlang shell, you'll quite literally get ="🤔"= as a string, with no regards to encoding. This is a singly linked-list.
- =<<"abcdef">>= as a binary string, which is shorthand for =<<$a, $b, $c, $d, $e, $f>>=. This is an old standard list of Latin1 integers transformed as a binary. By default this literal format does _not_ support Unicode encodings, and if you put a value that is too large in there (such as =16#1f914=) by declaring a binary like =<<"🤔">>= in your source file, you will instead find yourself with an overflow, and the final binary =<<20>>=. This is implemented with an Erlang binary (what is essentially an immutable byte array), and is meant to handle any kind of binary data content, even if it's not text.
- =<<"abcdef"/utf8>>= as a binary Unicode string that is encoded as UTF-8. This one would work to support emojis. It is still implemented as an Erlang binary, but the =/utf8= constructor ensures proper Unicode encoding. =<<"🤔"/utf8>>= returns =<<240,159,164,148>>=, which is the proper sequence to represent the thinking emoji in UTF-8.
- =<<"abcdef"/utf16>>= as a binary string that is Unicode encoded as UTF-16. =<<"🤔"/utf16>>= returns =<<216,62,221,20>>=
- =<<"abcdef"/utf32>>= as a binary string that is Unicode encoded as UTF-32. =<<"🤔"/utf32>>= returns =<<0,1,249,20>>=
- =["abcdef", <<"abcdef"/utf8>>]=: This is a special list dubbed "IoData" that can support multiple string formats. Your list can be codepoints as usual, but you'll want all the binaries to all be the same encoding (ideally UTF-8) to prevent issues where encodings get mixed.

If you want to work with Unicode content, you will want to use the various string-related modules in Erlang.

The first one is [[http://erlang.org/doc/man/string.html][string]], which contains functions such as =equal/2-4= to handle string comparison while dealing with case sensitivity and normalization, =find/2-3= to look for substrings, =length/1= to get the number of grapheme clusters, =lexemes/2= to split a string on some pattern, =next_codepoint/1= and =next_grapheme/1= to consume bits of a string, =replace/3-4= for substitutions, =to_graphemes/1= to turn a string into lists of grapheme clusters, and finally functions like =lowercase/1=, =uppercase/1=, and =titlecase/1= to play with casing. The module contains more content still, but that should be representative.

You will also want to use the [[http://erlang.org/doc/man/unicode.html][unicode]] module to handle all kinds of conversions across string formats, encodings, and normalization forms. The regular expression module [[http://erlang.org/doc/man/re.html][re]] handles unicode fine (just pass in the =unicode= atom to its options lists), and lets you use [[http://erlang.org/doc/man/re.html#generic_character_types][Generic Character Types]] if you pass in the =ucp= option. Finally, the =file= and =io= modules all support specific options to make unicode work fine.

All of these modules work on any form of string: binaries, lists of integers, or mixed representations. As long as you stick with these modules for string handling, you'll be in a good position.

The one tricky thing you have to remember is that the encoding of a string is implicit. You have to know what it is when a string enters your system: an HTTP request often specifies it in headers, and so does XML. JSON and YAML mandate using UTF-8, for example. When dealing with SQL databases, each table may specify its own encoding, but so does the connection to the database itself! If any one of them disagrees, you're going to corrupt data.

So you will want to know and identify your encoding very early on, and track it well. It's not just a question of which data type in your language exists, it's a question of how you design your entire system and handle exchanging data over the network.

There's one more thing we can cover about strings: how to transform them effectively.

***** IoData

So which string type should you use? There are plenty of options, but picking one is not too simple.

The quick guidelines are:

- Binaries for UTF-8, which should represent the majority of your usage
- Binaries for UTF-16 and UTF-32, should you use them
- Lists as strings are rarely used in practice, but can be very effective if you want to work at the codepoint level
- Use IoData for everything else, particularly building strings.

One advantage of the binary data types is their ability to create subslices efficiently. So for example, I could have a binary blob with content such as =<<"hello there, Erlang!">>= and if I pattern match a subslice such as =<<Txt:11/binary, _/binary>>=, then =Txt= now refers to =<<"hello there">>= at the same memory location as the original one, but with no way to obtain the parent context programmatically. It's a bounded reference to a subset of the original content. The same would not be true with lists, since they're defined recursively.

On top of that, binaries larger than 64 bytes can be shared across process heaps, so you can cheaply move string content around the virtual machine without paying the same copying cost as you would with other data structure.

#+attr_shortcode: info
#+begin_alert
Binary sharing is often a great way to gain performance in a program. However, there exist some pathological usage patterns where binary sharing can lead to memory leaks. If you want to know more, take a look at [[https://www.erlang-in-anger.com/][Erlang In Anger]]'s chapter on memory leaks, particularly section 7.2
#+end_alert

The real cool thing though comes from the IoData representation where you combine the list approach with binaries. It's how you get really cheap composition of immutable strings:

#+NAME: greetings
#+BEGIN_SRC erlang
Greetings = <<"Good Morning">>,
Name = "James",
[Greetings, ", ", Name, $!]
#+END_SRC

The final data structure here looks like =[<<"Good Morning">>, ", ", "James", 33]= which is a mixed list containing binary subsections, literal codepoints, strings, or other IoData structures. But the VM mechanisms all support handling it as if it were a flat binary string: The IO systems (both network and disk access), and the modules named in the previous section all seamlessly handle this string as =Good Morning, James!= with full Unicode support.


So while you can't mutate strings, you can append and match a bunch of them in constant time, no matter the type they initially had. This has interesting implications if you're writing libraries that do string handling. For example, if I want to replace all instances of =&= by =&amp;=, and I started with =<<"https://example.org/?abc=def&ghi=jkl"/ut8>>=, I might instead just return the following linked list:

#+NAME: url_sublists
#+BEGIN_SRC erlang
% a list
[%% a slice of the original unmutated URL
 <<"https://example.org/?abc=def">>,
 %% a literal list with the replacement content
 "&amp;amp",
 %% the remaining sub-slice
 <<"ghi=jkl">>
]
#+END_SRC

What you have then is a string that is in fact a linked list of 3 elements: a slice of the original string, the replaced subset, the rest of the original string. If you're replacing on a document that's taking 150MB in RAM and you have somewhat sparse replacements, you can build the entire thing and edit it with essentially no overhead. That's pretty great.

So why else are IoData strings kind of cool? Well the unicode representation is one fun thing. As mentioned earlier, grapheme clusters are a crucial aspect of Unicode strings when you want to operate on them as a human would (rather than as binary sequences that only programmers would care about). Whereas most programming languages that use a flat array of bytes to represent strings have no great way to iterate over strings, Erlang's =string= module lets you call =string:to_graphemes(String)= to play with them:


#+NAME: graphemes
#+BEGIN_SRC erlang
erl +pc latin1 # disable unicode interpretation
1> [Grapheme | Rest] = string:next_grapheme(<<"ß↑õ"/utf8>>),
[223 | <<226,134,145,111,204,131>>]
2> string:to_graphemes("ß↑õ"),
[223,8593,[111,771]]
3> string:to_graphemes(<<"ß↑õ"/utf8>>),
[223,8593,[111,771]]
#+END_SRC

This lets you take any unicode string, and turn it into a list that is safe to iterate using calls such as =lists:map/2=, lists comprehensions, or pattern matching. This can only be done through IoData, and this might even be a better format than what you'd get with just default UTF-8 binary strings.

Do note that pattern matching is still risky there. Ideally you'd want to do a round of normalization first, so that characters that can be encoded in more than one way are forced into a uniform representation.

This should hopefully demistify Erlang's strings.

*** Handling Time

Time is something very simple to live, but absurdly difficult to describe. It has taken philosophers and scientists centuries of debate to kind of get to a general agreement, and we software folks decided that counting seconds since January 1st 1970 ought to be good enough. It's harder than that. We won't get into all the details about calendaring rules and conversions, timezones, concepts of leap seconds and so on; that's too general a topic. However, we'll cover some important distinctions between _wall clocks_ and _monotonic time_, and how the Erlang virtual machine can help us deal with this stuff.

**** Background Information on Time

If we want to be very reductionist, there are a few specific use cases for time measurements, and they are often rather distinct:

1. Knowing the duration between two given events, or "how long does something take?", which requires having a single value in a unit such as microseconds, hours, or years
2. Placing an event on the timeline in a way we can pinpoint it and understand when it happened, or "when does something happen?", usually based on a [[https://en.wikipedia.org/wiki/ISO_8601][datetime]].

Essentially those both have to do with time, but are not measured the same way. 

The short answer for Erlang is that you should use [[http://erlang.org/doc/man/erlang.html#monotonic_time-0][=erlang:monotonic_time/0-1=]] to calculate durations, and [[http://erlang.org/doc/man/erlang.html#system_time-0][=erlang:system_time/0-1=]] for the system time (such as a [[https://www.unixtimestamp.com/][UNIX timestamp]]). If you want to understand _why_, then you will want to read the rest of this chapter.

A datetime is usually based on a calendar date (most of readers are likely using the [[https://en.wikipedia.org/wiki/Gregorian_calendar][Gregorian Calendar]]) along with a given hour, minute, and seconds value, along with a timezone and optionally, a higher precision value for milliseconds or microseconds. This value needs to be understandable by humans, and is entirely rooted into a social system that people agree means something for a given period of time: we all know that the year 1000 refers to a specific part of time even if our current Gregorian calendar was introduced in 1582 and technically none of the dates before have happened under that system -- they may have been lived under the Julian calendar or the mayan calendar, but not the gregorian one. The whole concept is eventually attached to astronomical phenomena such as Earth's orbit, or [[https://en.wikipedia.org/wiki/Solar_time#Mean_solar_time][mean solar days]].

On the other hand, a time interval, particularly for computers, is based on some cyclical event which we count. [[https://en.wikipedia.org/wiki/Water_clock][Water clocks]] or hourglasses would have a given rate at which drops or grains of sands would fall, and when it was empty, a given period of time would have gone through. Modern computers use various mechanisms like [[https://en.wikipedia.org/wiki/Clock_signal][clock signals]], [[https://en.wikipedia.org/wiki/Crystal_oscillator][crystal oscillators]], or if you're very fancy, [[https://en.wikipedia.org/wiki/Atomic_clock][atomic clocks]]. By synchronizing these cyclical countable events up with concepts such as solar days, we can adjust the measured cycles to a broader point of reference, and join our two time accounting systems: durations and pinpointing in time can be reconciliated.

We as humans are used to considering these two concepts as two facets of the same "time" value, but when it comes to computers, they're really not that good at doing both at the same time. It really helps a lot if we keep both concepts distinct: durations are not the same thing as absolute points in times, and should be handled differently.

To give an example, many programmers are aware of [[https://en.wikipedia.org/wiki/Unix_time][Unix Time]] (a duration in seconds since January 1st 1970), and many programmers are aware of [[https://en.wikipedia.org/wiki/Coordinated_Universal_Time][UTC]] as a standard. However, few developers are aware that both are actually tricky to convert because UTC handles [[https://en.wikipedia.org/wiki/Leap_second][leap seconds]], but unix timestamps do not, and it can cause all kinds of weird, funny issues. Using them interchangeably can introduce subtle bugs in software.

One particular challenge is that computer clocks are not particularly good at being accurate over long periods of time, a concept known as [[https://en.wikipedia.org/wiki/Clock_drift][clock drift]]. One result of this is that while we might have a very decent resolution over short intervals (a few minutes or hours), over weeks, months, or years, clocks drift _a lot_. The frequency of the computer clock varies here and there, but overall doesn't change too much. All the short-time calculations you'll make will be fine, but they won't be good enough to keep track of most longer spans of time. Instead, protocols such as [[https://en.wikipedia.org/wiki/Network_Time_Protocol][NTP]] are required to re-synchronize computer clocks with far more accurate (and more expensive) ones, over the network.

This means that it is to be expected that the time on your computer might just jump around for fun. Even more so if the operator just plays with things like changing timezones or system time.

**** Handling Time in Erlang

The way your computer handles time is based on the previously mentioned clocks that simply increment by counting microseconds or milliseconds (depending on hardware and operating systems). To represent time in units that makes sense to us humans, a conversion is done from some _epoch_ (an arbitrary starting point) to some time standard (UTC). Because computer clocks drift and shift with time, an _offset_ value is kept that allows to correct the local ever-increasing clock so that it makes sense to people. This is usually all hidden, and unless you know where to look, you won't know it happens.

Erlang's runtime system uses the same kind of mechanisms, but makes them explicit. It exposes two clocks:

1. A _monotonic_ clock, which means a clock that is just a counter that always returns increasing values (or the same number as before, if you call it during the same microsecond). It can have a high precision and is useful to calculate intervals.
2. A _system_ clock, which exposes the time the user usually cares about as a human being. This tends to be done by using the unix POSIX time (seconds since January 1st 1970), which is widely used by computers everywhere, and plenty of conversion libraries exist for all other kinds of time formats. It presents a kind of lowest common denominator for human time.

Overall, all the clocks on your system may end up looking like Figure [[fig:clocks]]:

#+NAME: fig:clocks
[[./static/img/clock-compare.png]]

There is some real perceived time (which we'll assume is rather constant, if we ignore [[https://en.wikipedia.org/wiki/Time_dilation][relativistic effects]]), which the computer's clock more or less matches. Voltage, temperature, humidity, and hardware quality may all impact its reliability. The Erlang VM provides its own monotonic clock, which is synchronized on the hardware clock (if any), and allows some additional control which we'll describe soon.

The system time, for its own part, is always calculated as a given offset from its underlying monotonic clock. The objective is to take the arbitrary number of clock ticks of the hardware clock, and turn them into seconds from 1970, which can then be converted to other formats.

If the offset is a constant 0, then the VM's monotonic and system times will be the same. If the offset is modified positively or negatively, the Erlang system time may be made to match the OS system time while the Erlang monotonic time is left independent. In practice, it is possible for the monotonic clock to be some large negative number, and the system clock to be modified by the offset to represent the positive POSIX timestamp.

This means that in Erlang, you'll want to use the following functions for specific use cases:

- [[http://erlang.org/doc/man/erlang.html#monotonic_time-0][=erlang:monotonic_time/0-1=]] for the Erlang monotonic time. It may return very low negative numbers, but they'll never get more negative. You can use something like =T0=erlang:monotonic_time(millisecond), do_something(), T1=erlang:monotonic_time(millisecond)= and get the total duration of the operation by calculating =T1 - T2=. Note that the time units should be the same across comparisons (see notice).
- [[http://erlang.org/doc/man/erlang.html#system_time-0][=erlang:system_time/0-1=]] for the Erlang system time (after the offset has been applied) when you need a UNIX timestamp
- [[http://erlang.org/doc/man/erlang.html#time_offset-0][=erlang:time_offset/0-1=]] to figure out the difference between the Erlang monotonic and Erlang system clocks
- [[http://erlang.org/doc/man/calendar.html#local_time-0][=calendar:local_time/0=]] to return the system time converted to the operating system's current clock (meaning in the user's current timezone and daylight saving times) in a ={{Year, Month, Day},{Hour, Minute, Second}}= format
- [[http://erlang.org/doc/man/calendar.html#universal_time-0][=calendar:universal_time/0=]] to return the system time converted to the current time in UTC in a ={{Year, Month, Day}, {Hour, Minute, Second}} format.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
The functions handling time in the =erlang= module almost all take a =Unit= argument, which can be one of =second=, =millisecond=, =microsecond=, =nanosecond=, or =native=. By default, the type of timestamp returned is in the native format. The unit is determined at run time, and =erlang:convert_time_unit(Time, FromUnit, ToUnit)= may be used to convert between time units. For example, =erlang:convert_time_unit(1, seconds, native)= returns =1000000000=.
#+end_notice

The [[http://erlang.org/doc/man/calendar.html][=calendar=]] module also contains more utility functions, such as [[http://erlang.org/doc/man/calendar.html#valid_date-1][date validation]], conversion [[http://erlang.org/doc/man/calendar.html#system_time_to_rfc3339-1][to]] and [[http://erlang.org/doc/man/calendar.html#rfc3339_to_system_time-1][from]] RFC3339 datetime strings (=2018-02-01T16:17:58+01:00=), time differences, and conversions to days, weeks, or detecting leap years.

The last tool in the arsenal is a new type of monitor, usable to detect when the time offset jumps. It can be called as =erlang:monitor(time_offset, clock_service)=. It returns a reference and when time drifts, the message received will be ={'CHANGE', MonitorRef, time_offset, clock_service, NewTimeOffset}=.

**** Time Warping

If you use the previous functions in the right context, you'll almost never have a problem handling time. The only thing you have to care about now is how to handle weird cases such as the host computer going to sleep and waking up with a brand new clock, dealing with a system administrator playing with the time, having NTP force a clock forwards and backwards in time, and so on. Not caring for them can make your system behave in very weird ways. 

Fortunately, the Erlang VM lets you pick and choose from pre-established strategies, and as long as you stick with using the right functions at the right time (monotonic clocks for intervals and benchmarks, system time for pinpointing events in time), you can just choose whichever option you feel is more appropriate. Picking the right functions for the right use cases ensures that your code is [[http://erlang.org/doc/apps/erts/time_correction.html#Dos_and_Donts][time warp safe]].

These options can be passed by passing the =+C= (warp mode) and =+c= (time correction) switches to the =erl= executable. The warp mode (=+C=) defines how the offset between monotonic and system time is handled, and the time correction (=+c=) defines how the VM will adjust the monotonic clock it exposes when the system clock changes.

- =+C multi_time_warp +c true=: The time offset can change at any time without any limitations to provide good system time, and the Erlang monotonic clock frequency can be adjusted by the VM to be as accurate as possible. This is what you want to specify on any modern platform, and tends to have better performance, scale better, and behave better.
- =+C no_time_warp +c true=: The time offset is chosen at VM start time, and then is never modified. Instead, the monotonic clock is sped up or slowed down to slowly correct time drift. This is the default mode for backwards compatibility reasons, but you might want to pick a different one that is more in line with proper time usage.
- =+C multi_time_warp +c false=: The time offset can change at any time, but the Erlang monotonic clock frequency may not be reliable. If the OS system time leaps forwards, the monotonic clock will also leap forward. If the OS system time leaps backwards, the Erlang monotonic clock may pause briefly.
- =+C no_time_warp +c false=: The time offset is chosen at VM start time, and then is never modified. The monotonic clock is allowed to stall or jump forwards in large leaps. You generally do not want this mode.
- =+C single_time_warp +c true=: This is a special hybrid mode to be used on embedded hardware when you know Erlang boots before the OS clock is synchronized (for example, you boot your software before NTP synchronization can take place). When the VM boots, the Erlang monotonic clock is kept as stable as possible, but no system time adjustments are made. Once time synchronization is done at the OS level, the user calls =erlang:system_flag(time_offset, finalize)=, the Erlang system time warps once to match the OS system time, and then the clocks become equivalent to those under =no_time_warp=.
- =+C single_time_warp +c true=: This is a special hybrid mode to be used on embedded hardware when you know Erlang boots before the OS clock is synchronized (for example, you boot your software before NTP synchronization can take place). No attempts are made to synchronize the Erlang system time with the OS system time, and any changes in the OS system times may have impacts on the Erlang monotonic clock. Once time synchronization is done at the OS level, the user calls =erlang:system_flag(time_offset, finalize)=, the Erlang system time warps once to match the OS system time, and then the clocks become equivalent to those under =no_time_warp=

You generally want to always have =+c true= as an option (it's the default), and to force =+C multi_time_warp= (which is not default). If you want to emulate old Erlang systems where clock frequency is adjusted, pick =+C no_time_warp=, and if you work in embedded systems where the first clock synchronization can jump really far in time and after that you expect it to be more stable _and_ you don't want =+C multi_time_warp= (you should want it!), then look for =single_time_warp=.

In short, if you can, pick =+C multi_time_warp +c true=. It's the best option for accurate time handling out there.


*** SSL Configurations
**** Background Information on TLS
**** Handling TLS in Erlang

* Production
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/production
:END:

** DONE Index
CLOSED: [2019-08-08 Thu 08:05]
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_FRONT_MATTER_KEY_REPLACE: title>label
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :title "Production"
:EXPORT_HUGO_MENU: :menu main :weight 3001
:END:

#+BEGIN_EXPORT html
<header>
  <h1>Production</h1>
  <h5>
    <strong>August 3, 2019</strong>
  </h5>
</header>
#+END_EXPORT

Erlang/OTP is certainly a unique language and runtime, but it is not as different as even some proponents would have you believe. In this part we will see how to build artifacts for deployment and how to operate the deployment in the same environment you would run any other service. In this part we'll build a deployable artifact (a release), create a docker image of the release and deploy to a Kubernetes cluster.

A common claim heard on forums and comment sections of popular tech news sites is, you have OTP, you don't need Kubernetes. Or the opposite, that having Kubernetes replaces OTP. Erlang does not replace Kubernetes, nor does Kubernetes replace Erlang. If an Erlang system didn't need to be monitored and restarted like any other runtime because it has supervision trees then it wouldn't come with [[http://erlang.org/doc/man/heart.html][heart]]. Similarly, if restarting the entire program with =heart= was adequate there wouldn't be supervision trees.

[[https://kubernetes.io/][Kubernetes]] provides a scheduler for efficiently packing your programs, as containers, on physical or virtual machines. Using containers eases deployment by bundling all dependencies (think OpenSSL in an Erlang release's case) into a single image and isolation that protects against dependency conflicts between services running on a machine. Additionally, deployment and management becomes consistent across the services in your production environment no matter the language or runtime they are built with. When you integrate your Erlang service with common monitoring and tracing services, you will also ensure it's no longer the oddball your coworkers dread having to deal with.

However, containers and Kubernetes are not appropriate in all cases. Kubernetes can be overkill, particularly if using a hosted solution isn't an option, or your product could be an embedded device.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/development/otp_applications">← Prev</a></div>
  <div><a href="/docs/team_building">Next →</a></div>
</div>
#+END_EXPORT

** TODO Releases
:PROPERTIES:
:EXPORT_FILE_NAME: releases
:EXPORT_HUGO_MENU: :menu main :parent production
:END:

In [[/docs/development/otp_high_level/][OTP at a High Level]] we took a bird's-eye view of how applications are combined into a release and in the follow chapters of [[/docs/development/][Development]] we built and tested OTP applications. Now we'll configure and build a release of the [[https://github.com/adoptingerlang/service_discovery][service_discovery]] project.

*** The Nitty Gritty

An Erlang system starts by running instructions found in a [[http://erlang.org/doc/man/script.html][boot script]]. The instructions load modules and start applications. Erlang provides functions for generating a boot script from a list of all required applications, defined in a release resource file with extension ".rel", and the corresponding application resource file, the ".app" file each application has. The application resource file defines the modules the boot script must load and the dependencies of each application so that the boot script will start applications in the correct order. When only the applications used in a release are bundled together with the boot script, to be copied and installed on a target, it is called a *target system*.

In the earlier days of Erlang/OTP, there was only =systools= and its functions for generating boot scripts from release resource files. Back then, release handling was a manual process around which users built their own tooling. Then came =reltool=, a release management tool that ships with Erlang/OTP and was meant to ease the creation of releases—it even has a GUI. While creating and installing target systems has never been provided outside of an example module found in the =sasl= application, =sasl/examples/src/target_system.erl=.

Releases continued to be mysterious and difficult to build to many users. relx was created with the goal of making release creation and management so simple that users no longer felt it was a burden best not undertaken -- this is done in part through requiring minimal configuration to get started and by including tools for runtime management in the generated release. When rebar3 was started, it bundled relx to provide its release building functionality.

Along with building and packaging =relx= comes with a shell script for starting a release and interacting with the running release. While running a release can be as simple as =erl= (which itself runs a boot script built from =start.script= you can find in the =bin/= directory of your Erlang install) the provided script handles setting appropriate arguments to point to configuration files, attaching a remote console to a running node, running functions on a running node and more.

In the following sections we will dissect release building for the [[https://github.com/adoptingerlang/service_discovery][service_discovery]] project. The focus is on real world usage of the tools and not the low level details of constructing and running a release.

*** Building a Development Release

The first thing to look at in [[https://github.com/adoptingerlang/service_discovery][service_discovery]] is the =relx= section in =rebar.config=:

#+NAME: rebar.config
#+BEGIN_SRC erlang
{relx, [{release, {service_discovery, {git, long}},
         [service_discovery_postgres,
          service_discovery,
          service_discovery_http,
          service_discovery_grpc,
          recon]},

        {sys_config_src, "./config/sys.config.src"},
        {vm_args_src, "./config/vm.args.src"},

        {dev_mode, true},
        {include_erts, false},

        {extended_start_script, true},

        {overlay, [{copy, "apps/service_discovery_postgres/priv/migrations/*", "sql/"}]}]}.
#+END_SRC

The =release= tuple in the =relx= configuration list defines a release's name, version and the applications
included in the release. The version here is ={git, long}= which tells =relx= to use the full git sha reference of the current commit as the version of the release. The applications the release will boot includes the Postgres storage backend, the application that is the main interface to the services and the DNS setup, HTTP and grpc frontends and a tool useful for inspecting production nodes, =recon=.

The order the applications are listed is important here. When constructing the boot script a stable sort on all applications based on their dependencies is done to decide the order to start them. This means that while the order is based on sorting the applications based on their runtime dependencies, when no dependency requires moving an application in the list (both the list given in the =relx= config and the lists of applications in each =.app= file) the defined order is kept. Each of =service_discovery_postgres=, =service_discovery_http= and =service_discovery_grpc= depend on =service_discovery= resulting in it being the first of those four to start and the next will be =service_discovery_postgres= because it is listed before the other two. This is important because we need the storage backend available before the HTTP and grpc services are usable.

=rebar3 release= runs =relx= with a configuration based on the =relx= section of =rebar.config= and the rebar3 project structure, allowing =relx= to find the necessary applications for building the release.

#+BEGIN_SRC shell
$ rebar3 release
===> Verifying dependencies...
===> Compiling service_discovery_storage
===> Compiling service_discovery
===> Compiling service_discovery_http
===> Compiling service_discovery_grpc
===> Compiling service_discovery_postgres
===> Starting relx build process ...
===> Resolving OTP Applications from directories:
          /app/src/_build/default/lib
          /app/src/apps
          /root/.cache/erls/otps/OTP-22.0.7/dist/lib/erlang/lib
          /app/src/_build/default/rel
===> Resolved service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70
===> Dev mode enabled, release will be symlinked
===> release successfully created!
#+END_SRC

The first =relx= step seen in the output is "Resolving OTP Applications" followed by a list of directories it will search for built applications. For each application in the =relx= release's configuration, in this case =service_discovery_postgres=, =service_discovery=, =service_discovery_http=, =service_discovery_grpc=, and =recon=, =relx= will find the directory of the built application and then do the same for any application listed in its =.app= file.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
Note that the application =sasl= is not included in the =relx= config's list of applications. By default in the rebar3 template it is in the list. This is because =sasl= is required for certain release operations. The =sasl= application includes =release_handler= which provides functionality for performing release upgrades and downgrades. Since we are focused here on creating containers which are replaced instead of live upgraded =sasl= does not need to be included.
#+end_notice

Because this release is built with ={dev_mode, true}=, symlinks are created in the release's lib directory that point to each application instead of being copied:

#+BEGIN_SRC shell
$ ls -l _build/default/rel/service_discovery/lib
lrwxrwxrwx ... service_discovery-c9e1c80 -> .../_build/default/lib/service_discovery
#+END_SRC

The same is also done for the runtime configuration files =sys.config.src= and =vm.args.src=:

#+BEGIN_SRC shell
$ ls -l _build/default/rel/service_discovery/releases/c9e1c805d57a78d9eb18af1124962960abe38e70
lrwxrwxrwx [...] sys.config.src -> [...]/config/sys.config.src
lrwxrwxrwx [...] vm.args.src -> [...]/config/vm.args.src
#+END_SRC

This allows for a faster feedback loop when running our release for local testing. Simply stopping and starting the release again will pick up any changes to beam files or configuration.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_alert
On Windows the =dev_mode= of relx won't necessary work but it will fallback to copying.
#+end_alert

#+BEGIN_SRC shell
_build/default/rel/service_discovery/
├── bin/
│   ├── install_upgrade.escript
│   ├── nodetool
│   ├── no_dot_erlang.boot
│   ├── service_discovery
│   ├── service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70
│   └── start_clean.boot
├── lib/
│   ├── acceptor_pool-1.0.0 -> /app/src/_build/default/lib/acceptor_pool
│   ├── base32-0.1.0 -> /app/src/_build/default/lib/base32
│   ├── chatterbox-0.9.1 -> /app/src/_build/default/lib/chatterbox
│   ├── dns-0.1.0 -> /app/src/_build/default/lib/dns
│   ├── elli-3.2.0 -> /app/src/_build/default/lib/elli
│   ├── erldns-1.0.0 -> /app/src/_build/default/lib/erldns
│   ├── gproc-0.8.0 -> /app/src/_build/default/lib/gproc
│   ├── grpcbox-0.11.0 -> /app/src/_build/default/lib/grpcbox
│   ├── hpack-0.2.3 -> /app/src/_build/default/lib/hpack
│   ├── iso8601-1.3.1 -> /app/src/_build/default/lib/iso8601
│   ├── jsx-2.10.0 -> /app/src/_build/default/lib/jsx
│   ├── recon-2.4.0 -> /app/src/_build/default/lib/recon
│   ├── service_discovery-c9e1c80 -> /app/src/_build/default/lib/service_discovery
│   ├── service_discovery_grpc-c9e1c80 -> /app/src/_build/default/lib/service_discovery_grpc
│   ├── service_discovery_http-c9e1c80 -> /app/src/_build/default/lib/service_discovery_http
│   └── service_discovery_storage-c9e1c80 -> /app/src/_build/default/lib/service_discovery_storage
└── releases/
    ├── c9e1c805d57a78d9eb18af1124962960abe38e70
    │   ├── no_dot_erlang.boot
    │   ├── service_discovery.boot
    │   ├── service_discovery.rel
    │   ├── service_discovery.script
    │   ├── start_clean.boot
    │   ├── sys.config.src -> /app/src/config/sys.config.src
    │   └── vm.args.src -> /app/src/config/vm.args.src
    ├── RELEASES
    └── start_erl.data
#+END_SRC

The release uses the Postgres storage backend so a database needs to be running and accessible before starting the release. Running =docker-compose up= at the top level of the project will bring up a database and run the migrations:

#+BEGIN_SRC shell
$ docker-compose up
#+END_SRC

To boot the development release to an interactive Erlang shell run the extended start script with command =console=:

#+BEGIN_SRC shell
$ DB_HOST=127.0.0.1 LOGGER_LEVEL=debug SCHEDULERS=1 \
  _build/default/rel/service_discovery/bin/service_discovery console
(service_discovery@localhost)1>
#+END_SRC

With =service_discovery= running =curl= can be used to access the HTTP interface. The following commands create a service =service1=, verify it was created by listing all services, registers an endpoint with the service at IP =127.0.0.3= and  adds a named port =http= on port 8000.

#+BEGIN_SRC shell
$ curl -v -XPUT http://localhost:3000/service \
    -d '{"name": "service1", "attributes": {"attr-1": "value-1"}}'
$ curl -v -XGET http://localhost:3000/services
[{"attributes":{"attr-1":"value-1"},"name":"service1"}]
$ curl -v -XPUT http://localhost:3000/service/service1/register \
    -d '{"ip": "127.0.0.3", "port": 8000, "port_name": "http", "tags": []}'
$ curl -v -XPUT http://localhost:3000/service/service1/ports \
    -d '{"http": {"protocol": "tcp", "port": 8000}}'
#+END_SRC

=service_discovery= DNS server is running on port 8053, use =dig= to see that =service1= is a registered endpoint at the correct IP and that a service (SRV) DNS query returns the port and DNS name for the service.

#+BEGIN_SRC shell
$ dig -p8053 @127.0.0.1 A service1
;; ANSWER SECTION:
service1.		3600	IN	A	127.0.0.3
$ dig -p8053 @127.0.0.1 SRV _http._tcp.service1.svc.cluster.local
;; ANSWER SECTION:
_http._tcp.service1.svc.cluster.local. 3600 IN SRV 1 1 8000 service1.svc.cluster.local.
#+END_SRC


*** Building a Production Release

Preparing a release to be deployed to production requires different options than what is best used during local development. Rebar3 profiles allow us to override and add to the =relx= configuration. This profile is commonly named =prod=:

#+NAME: rebar.config
#+BEGIN_SRC erlang
{profiles, [{prod, [{relx, [{dev_mode, false},
                            {include_erts, true},
                            {include_src, false},
                            {debug_info, strip}]}]
            }]}.
#+END_SRC

We have two overridden configuration values in the =prod= profile. =dev_mode= is set to =false= so all content is copied into the release directory, we can't utilize symlinks to the =_build= directory from another machine and a production release should be an immutable snapshot of the project. =include_erts= copies the Erlang runtime and the Erlang/OTP applications depended on by the release into the release directory and configures the boot script to point to this copy of the runtime.

The entries added to the configuration are setting =include_src= to =false= and =debug_info= to =strip=. Running the release in production doesn't require the source code, so we set =include_src= to false in order to drop it from the final release to save on space. Additional space is saved by stripping debug information from the beam files with =debug_info= set to =strip=. Debug information is used by tools like the debugger, =xref= and =cover= but in a release those tools won't be used and, unless explicitly included, won't even be available.

Building with the production profile enabled results in artifacts being written to the profile directory =_build/prod/=:

#+BEGIN_SRC shell
$ rebar3 as prod release
===> Verifying dependencies...
===> Linking _build/default/lib/uuid to _build/prod/lib/uuid
===> Linking _build/default/lib/pg_types to _build/prod/lib/pg_types
===> Linking _build/default/lib/quickrand to _build/prod/lib/quickrand
===> Compiling service_discovery_storage
===> Compiling service_discovery
===> Compiling service_discovery_http
===> Compiling service_discovery_grpc
===> Compiling service_discovery_postgres
===> Starting relx build process ...
===> Resolving OTP Applications from directories:
          /app/src/_build/prod/lib
          /app/src/apps
          /root/.cache/erls/otps/OTP-22.0.7/dist/lib/erlang/lib
===> Resolved service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70
===> Including Erts from /root/.cache/erls/otps/OTP-22.0.7/dist/lib/erlang
===> release successfully created!
#+END_SRC

Viewing the tree of the new =prod= profile's release directory we see:

#+NAME: prod_rel_structure
#+BEGIN_SRC sh
_build/prod/rel/service_discovery
├── bin
│   ├── install_upgrade.escript
│   ├── nodetool
│   ├── no_dot_erlang.boot
│   ├── service_discovery
│   ├── service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70
│   └── start_clean.boot
├── erts-10.4.4
│   ├── bin
│   ├── doc
│   ├── include
│   ├── lib
│   └── man
├── lib
│   ├── acceptor_pool-1.0.0
│   ├── asn1-5.0.9
│   ├── base32-0.1.0
│   ├── chatterbox-0.9.1
│   ├── crypto-4.5.1
│   ├── dns-0.1.0
│   ├── elli-3.2.0
│   ├── erldns-1.0.0
│   ├── gproc-0.8.0
│   ├── grpcbox-0.11.0
│   ├── hpack-0.2.3
│   ├── inets-7.0.8
│   ├── iso8601-1.3.1
│   ├── jsx-2.10.0
│   ├── kernel-6.4
│   ├── mnesia-4.16
│   ├── public_key-1.6.7
│   ├── recon-2.4.0
│   ├── service_discovery-c9e1c80
│   ├── service_discovery_grpc-c9e1c80
│   ├── service_discovery_http-c9e1c80
│   ├── service_discovery_storage-c9e1c80
│   ├── ssl-9.3.1
│   └── stdlib-3.9.1
├── releases
│   ├── c9e1c805d57a78d9eb18af1124962960abe38e70
│   │   ├── no_dot_erlang.boot
│   │   ├── service_discovery.boot
│   │   ├── service_discovery.rel
│   │   ├── service_discovery.script
│   │   ├── start_clean.boot
│   │   ├── sys.config.src
│   │   └── vm.args.src
│   ├── RELEASES
│   └── start_erl.data
└── sql
    ├── V1__Create_services_endpoints_table.sql
    └── V2__Add_updated_at_trigger.sql
#+END_SRC

There are no symlinks under =lib= and OTP applications like =stdlib-3.8.1= are included. At the top of the tree is =erts-10.4.4= which contains the Erlang runtime.

To build the target system of the release we run the =tar= command in the =prod= profile:

#+BEGIN_SRC shell
$ rebar3 as prod tar
#+END_SRC

Now we have a tarball =_build/prod/rel/service_discovery/service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70.tar.gz= that can be copied to any compatible host, unpacked and run.

*** Runtime Configuration

In the =service_discovery= project we have two files for configuration under the =config/= directory, =vm.args.src= and =sys.config.src=, that are included in the release. These files act as templates to be filled in at runtime based on environment variables. There are two separate files because running a release involves two levels of configuration. First, there is the underlying Erlang virtual machine's settings. These values have to be set before the VM has started, so they cannot be part of a term file like =sys.config= which requires a running VM to read and parse the Erlang term file. Instead, the VM arguments are passed directly to =erl= -- =erl= being the command used to boot our release. To simplify this the =erl= command has an =-args_file= argument to allow command-line arguments to be read from a plain text file. This file is commonly named =vm.args=.

The second level is the configuration for the Erlang applications that make up the release. This is done with a file passed to =erl= through the =-config= argument. The file is a list of 2-tuples where the first element is the name of the application to set the environment of and the second element is a list of key-value pairs to set in the environment.

Of course static files can be pretty limiting and it has become common to want to set configuration through OS environment variables. To offer flexibility and support for environment variable configuration the release start script generated when using =rebar3= can replace variables of the form =${FOO}= with the value found in the current environment. This is done automatically if the files end with extension =.src=.

In the =relx= configuration we use =vm_args_src= and =sys_config_src= to include the files and signal that they are templates -- this is necessary so that the release building does not attempt to verify that =sys.config= is a proper list of Erlang terms, which, for example, ={port, ${PORT}}= is not:

#+BEGIN_SRC erlang
{relx, [...
        {sys_config_src, "config/sys.config.src"},
        {vm_args_src, "config/vm.args.src"},
        ...
       ]}.
#+END_SRC

In the Docker and Kubernetes chapters we will discuss needing to set the number of Erlang schedulers manually, but for now we just care about how it would be done in =vm.args.src=:

#+BEGIN_SRC shell
+S ${SCHEDULERS}
#+END_SRC

In =sys.config.src= we will make the =logger= level a variable as well, so we could, for example, turn on =debug= or =info= level logging to get more details when investigating the deployed service:

#+BEGIN_SRC erlang
{kernel, [{logger_level, ${LOGGER_LEVEL}}]}
#+END_SRC

Now when running the release we must set these variables or the release will fail to start.

#+BEGIN_SRC shell
$ LOGGER_LEVEL=debug SCHEDULERS=1 _build/default/rel/service_discovery/bin/service_discovery console
Erlang/OTP 21 [erts-10.4.4] [source] [64-bit] [smp:1:1] [ds:1:1:10] [async-threads:30] [hipe]
...
#+END_SRC

*** Coming Up

To get a feel for what we will be doing in the next chapters, copy =_build/prod/rel/service_discovery/service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70.tar.gz= to =/tmp/service_discovery=, unpack it and start the node. Here I am assuming that the necessary environment variables are already exported and not repeating them on the line running the bin script's commands.

#+BEGIN_SRC shell
$ mkdir /tmp/service_discovery
$ cp _build/prod/rel/service_discovery/service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70.tar.gz /tmp/service_discovery
$ cd /tmp/service_discovery
$ tar -xvf service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70.tar.gz && rm service_discovery-c9e1c805d57a78d9eb18af1124962960abe38e70.tar.gz
...
$ ls
bin  erts-10.4.4  lib  releases
$ bin/service_discovery console
...
(service_discovery@localhost)1>
#+END_SRC

Running with =console= gives an interactive Erlang shell. To run the release without an interactive shell use =foreground=, which is how we will be running the release in a Docker container in the next chapter. With the release running with =foreground= or =console= open a separate terminal and try the same script with the argument =remote_console=:

#+BEGIN_SRC shell
$ bin/service_discovery remote_console
...
(service_discovery@localhost)1>
#+END_SRC

=remote_console= uses =-remsh= [[http://erlang.org/doc/man/erl.html#flags][erl]] flag for connecting an interactive shell to the running release. The command knows which running Erlang node to connect to based on the same configuration, from =vm.args=, that sets the name and cookie for the node that was run originally. This means any environment variables used to populate =vm.args= when the node is started must be set the same when connecting the remote console.

** TODO Docker
:PROPERTIES:
:EXPORT_FILE_NAME: docker
:EXPORT_HUGO_MENU: :menu main :parent production
:END:

[[https://docker.com][Docker]] helped popularize Linux containers through its ease of use and registry of pre-built images, and became a word often used interchangably with "Linux container".

Docker images contain multiple layers that are merged at runtime to make up the filesystem of the container. Docker creates the layers by running commands found in a =Dockerfile=, each command creates a new layer. Layers are shared between images, saving space, and can be used as a cache for speeding up the building of images. Additional space is saved, compared to other options like a virtual machine (VM), by not including the Linux kernel in the image. The size of the image is little larger than the size of the packaged Erlang release we are deploying.

The small size and ability to run like a regular Linux process makes for quicker start times (a new kernel isn't booted) and less resource consumption than using a traditional VM for isolation. Having little overhead means that the advantages of isolation when packaging and running a program can be standard practice instead of the burden it would be to have to run a VM per program.

Advantages of containers running with filesystem and network isolation are not having to perform operations that are common when programs are not isolated:

- Pre-installing shared libraries
- Updating configuration
- Finding an open port
- Finding a unique name for node name

#+attr_shortcode: note
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
You might notice we will not be using the =latest= tag at all when using Docker. This tag is commonly misunderstood and misused. It is assigned to the last image used without a specific tag, it is not the latest created image. It should not be used, unless you really don't care what version of an image will be used.
#+end_notice

*** Building Images

[[https://hub.docker.com/_/erlang/][Offical Erlang Docker images]] are published for each new OTP release. They include rebar3 and come in [[https://alpinelinux.org/][Alpine]] and [[https://www.debian.org/][Debian]] flavors -- the images are updated for new releases of rebar3 and Alpine/Debian as well.

**** Private Dependencies

If you have private git repos or [[https://hex.pm/docs/rebar3_private][Hex organization packages]] as dependencies they will not be able to be fetched in the Docker container during the build. Often this leads people to not include =_build= in =.dockerignore= and risk polluting the build with local artifacts, possibly not being reproducable elsewhere, so the dependencies could be fetched with rebar3 before running =docker build=. The other option is copying the host SSH credentials and/or Hex apikey into the build container, but this is not recommended because it will be kept in the Docker layer and leaked anywhere you push the image. Instead, in recent Docker releases (18.06 and later) the abilities to mount secrets and SSH agent connections or keys in a secure manner. The data does not leak to the final image or any commands it is not explicitly mounted to.

***** Hex Dependencies

Rebar3 keeps the access keys for private Hex dependencies in a file =~/.config/rebar3/hex.config=. Using the experimental Dockerfile syntax =--mount=type=secret= the config can be mounted into the container for just the compile command. The file is mounted to a separate tmpfs filesystem and excluded from build cache calculations:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental

RUN --mount=type=secret,id=hex.config,target=/root/.config/rebar3/hex.config rebar3 compile
#+END_SRC

To mount the host's =hex.config= when running =docker build= simply pass a secret with a matching =id= and =src= path to the file:

#+BEGIN_SRC shell
$ docker build --secret id=hex.config,src=~/.config/rebar3/hex.config .
#+END_SRC

***** Git Dependencies

You could use the secret mount from the last section for mounting SSH keys, but Docker added a better solution with a mount type specifically for dealing with SSH. A =RUN= command that needs SSH access can use =--mount=type=ssh=:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental

RUN apk add --no-cache openssh-client git && \
    mkdir -p -m 0600 ~/.ssh && \
    ssh-keyscan github.com >> ~/.ssh/known_hosts && \
    git config --global url."git@github.com:".insteadOf "https://github.com/"
WORKDIR /src
COPY rebar.config rebar.lock .
RUN --mount=type=ssh rebar3 compile
#+END_SRC

First, a =RUN= command installs the necessary dependencies, SSH and git. Then, =ssh-keyscan= is used to download the current public key for Github and add it to =known_hosts=. The public key being in =known_hosts= means SSH will not attempt to prompt to ask if you accept the host's public key. Next, the git config setting ensures that even if in the =rebar.config= the git url is using =https= it will instead use SSH. If the private repos are not on Github this url replacement has to be changed for the appropriate location.

Along with adding the previous snippet to the Dockerfiles we'll see later in this chapter you'll also need to add =--ssh default= to the build command when run and set =DOCKER_BUILDKIT=:

#+BEGIN_SRC shell
$ export DOCKER_BUILDKIT=1
$ docker build --ssh default .
#+END_SRC

Additional information and options for the SSH mount type can be found [[https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/experimental.md#run---mounttypessh][in the Moby documentation]] -- Moby is the name of the project that makes up the core functionality of Docker.

**** Efficient Caching

The order of commands in a Dockerfile is very important to the build time and space required of the images it creates. Docker uses the layers each command in the Dockerfile creates to skip a command if nothing has changed. With rebar3 we take advantage of this by creating a layer containing the built dependencies of our project:

#+BEGIN_SRC dockerfile
COPY rebar.config rebar.lock .
RUN rebar3 compile
#+END_SRC

The =COPY= command will only invalidate the cache of the command that runs =rebar3 compile= (and subsequent commands in the file) if =rebar.config= or =rebar.lock= are different from a previously created layer. Since none of the project's code was copied and rebar3 only builds the dependencies, this results in a layer containing only the built dependencies under =_build/default/lib=.

After the dependencies are built and cached we can copy in the rest of the project and compile it:

#+BEGIN_SRC dockerfile
COPY . .
RUN rebar3 compile
#+END_SRC

Because of the order of operations in the Dockerfile each run of =docker build .= only compiles the project's source, assuming there is a change, otherwise an existing layer is used here as well. Any command that doesn't need to be rerun if there are changes to the project need to come before either of the =COPY= commands. For example, installing Alpine packages needed by later steps =RUN apk add --no-cache git=.

We will make use of the =--cache-from= argument. When Docker builds layers, =--cache-from= specifies an image to use as a cache to find the layer already built. If the image isn't found locally it will be pulled from the registry. If it isn't in the registry Docker will ignore it. The argument can be given multiple times, making multiple images potential sources of cached layers.

Now this is all well and good but the layer with the built dependencies that will not be used if =rebar.config= or =rebar.lock= is changed also contains the Hex package cache rebar3 creates under =~/.cache/rebar3/hex=. Any change to those two files will result in all the packages having to be downloaded again.

This issue is resolved as of Docker 18.09 -- when environment variable =DOCKER_BUILDKIT= is set or ="features":{"buildkit": true}= added to =/etc/docker/daemon.json=, enabling the use of Buildkit as the Docker backend -- through a new mount type, =cache=, that can be passed directly to the =RUN= command:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental

COPY rebar.config rebar.lock .
RUN --mount=id=hex-cache,type=cache,target=/root/.cache/rebar3 rebar3 compile
#+END_SRC

Now when =compile= is run there is a cache of =/root/.cache/rebar3= created separately from the image layer. So future runs of =docker build=, even if the config or lock file has changed, will mount this cache and only new packages will be fetched from Hex.

#+attr_shortcode: note
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
There is a security concern to keep in mind when using layer caching. For example, since the =RUN= command only reruns if the text of the command changes, or a previous layer invalidated the cache, any system package installed will remain the same version even if a security fix has been released. For this reason it is good to occasionally run with =--no-cache= which will not reuse any layers when building the image.
#+end_notice

**** Multi-Stage Build

For an Erlang project we are going to need an image with the built release for deploying, but we also need images for running tests and other code analysis. With Docker's multi-stage feature we are able to define how to build individual images for containing the compiled dependencies, the final release and the Dialyzer Persistent Lookup Table (PLT) all in a single =Dockerfile=.

We will step through each stage individually based on the =service_discovery= project's [[https://github.com/adoptingerlang/service_discovery/blob/docker-chapter/Dockerfile][Dockerfile]]. The first stage is named =builder=:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental
FROM erlang:22-alpine as builder

# git for fetching non-hex depenencies
# add any other Alpine libraries needed to compile the project here
RUN apk add --no-cache git

WORKDIR /app/src

# build and cache dependencies as their own layer
COPY rebar.config rebar.lock .
RUN --mount=id=hex-cache,type=cache,target=/root/.cache/rebar3 rebar3 compile
#+END_SRC

The =builder= stage starts with the base image =erlang:22-alpine=. =as builder= names the stage so we can use it as a target to =docker build=:

#+BEGIN_SRC shell
$ CHKSUM=$(cat rebar.config rebar.lock | cksum | awk '{print $1}')
$ docker build --target builder -t ${PROJECT}_builder:${CHKSUM} .
#+END_SRC

Running =docker build= with =--target build= and =-t service_discovery_builder:$CHKSUM= builds the stage and tags with the given name. This stage only fetches and compiles the dependencies of the project, mounting the rebar3 hex cache as discussed in the previous section.

The image with the compiled dependencies is now able to be used as a base for images that run rebar3 commands which would otherwise fetch and compile dependencies.

The next stage, named =releaser=, uses the =builder= image as its base:

#+BEGIN_SRC dockerfile
FROM builder as releaser

# tar for unpacking the target system
RUN apk add --no-cache tar

WORKDIR /app/src

# create the directory to unpack the release to
RUN mkdir -p /opt/rel

# build the release tarball and then unpack
# to be copied into the image built in the next stage
RUN rebar3 as prod tar && \
    tar -zxvf /app/src/_build/prod/rel/*/*.tar.gz -C /opt/rel
#+END_SRC

This stage copies in all of the project and builds a tarball of the release using the =prod= profile:

#+NAME: rebar.config
#+BEGIN_SRC erlang
{profiles, [{prod, [{relx, [{dev_mode, false},
                            {include_erts, true},
                            {include_src, false},
                            {debug_info, strip}]}]
            }]}.
#+END_SRC

The profile having =include_erts= set to =true= means the tarball contains the Erlang runtime and can be run on a target that doesn't have Erlang installed. At the end the tarball is unpacked to =/opt/rel= so the image that will copy the release out of the =releaser= stage does not need to have =tar= installed.

#+attr_shortcode: note
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
Why tar the release at all?

You might notice that a tarball of the release is created only to be untarred immediately. This is done, instead of copying the contents of the release directory, for two reasons. First, it ensures only what is explicitly defined to be in this version of the release is used. This is less important when building in a docker image since no previous release builds will be in the =_build/prod/rel= directory, but still good to do. Second, there are some changes made to the release when tarring that are required to use tools like =release_handler=, for example the boot script is renamed from =RelName.boot= to =start.boot=. For more details see the [[http://erlang.org/doc/man/systools.html#make_tar-1][systools]] documentation.
#+end_notice

Now to build and tag the =release= target using the builder image and, if it exists, a previous build of the image that has the same tag (because it was built for the same git commit) as a cache:

#+BEGIN_SRC shell
$ docker build --cache-from=${PROJECT}_builder:${CHKSUM} --cache-from=${PROJECT}_releaser:${CHKSUM} --target releaser -t ${PROJECT}_releaser:${CHKSUM} .
#+END_SRC

The second image using =builder= as a base is a cache of the project's PLT:

#+BEGIN_SRC dockerfile
FROM builder as plt

RUN --mount=id=hex-cache,type=cache,target=/root/.cache/rebar3 rebar3 dialyzer \
    --plt-location /root/.cache/rebar3 --plt-prefix deps --base-plt-prefix otp

ENTRYPOINT ["rebar3"]

CMD ["dialyzer", "--plt-location", "/root/.cache/rebar3", "--plt-prefix",
    "deps", "--base-plt-prefix", "otp"]
#+END_SRC

Like with the =compile= command the rebar3 cache is mounted and is where all PLT output is stored. Usually rebar3 will store only the PLT of the OTP libraries in the global cache directory and use the profile directory under =_build/= for the PLT which also contains the dependencies. So the argument =--plt-location= is used to set where the PLT will be stored. This is done because when running the container the project must be mounted as a volume to the same directory. Mounting a volume overrides any existing files on the path it is mounted to. Storing the PLT in a separate location ensure it is not lost when the volume is mounted and isn't rebuilt on each run.

Now to build the PLT image using the builder image as a cache (note that the stages =releaser= and =runner= will be skipped since they are not needed by the =plt= stage):

#+BEGIN_SRC shell
$ docker build --cache-from=${PROJECT}_builder:$CHKSUM --target plt -t ${PROJECT}:$CHKSUM .
#+END_SRC

To run dialyzer on the current code use a volume to mount the current directory to =/src=:

#+BEGIN_SRC dockerfile
$ docker run -v $(pwd):/src <image>
#+END_SRC

Finally, the deployable image uses a regular OS image (=alpine:3.9=) as the base instead of a prior stage. Any shared libraries needed to run the release are installed first and then the unpacked release from the build stage we named =releaser= is copied to =/opt/service_discovery=:

#+attr_latex: :options label=Dockerfile
#+BEGIN_SRC dockerfile
FROM alpine:3.9 as runner

# install openssl, needed by the crypto app
RUN apk add --no-cache openssl ncurses

WORKDIR /opt/service_discovery

COPY --from=releaser /opt/rel .

ENV COOKIE service_discovery
# write files generated during startup to /tmp
ENV RELX_OUT_FILE_PATH /tmp

ENTRYPOINT ["/opt/service_discovery/bin/service_discovery"]

CMD ["foreground"]
#+END_SRC

=/opt/service_discovery= is owned by root and it is recommended to not run the container as root. When the release is run =sys.config= and =vm.args= need to be generated from their respective =.src= files. By default these are placed in the same directory as the original =.src= files. If =RELX_OUT_FILE_PATH= is set, its location will be used instead. Here, the =ENV= command is used to ensure the environment variable =RELX_OUT_FILE_PATH= is set to =/tmp= when the container is run.

#+BEGIN_SRC shell
$ docker build --cache-from=${PROJECT}_releaser:${CHKSUM} --cache-from=${PROJECT}_builder:${CHKSUM} --target runner -t ${PROJECT}:${CHKSUM} .
#+END_SRC

*** Running a Container

Now that we have the image =docker run= can be used to run the release for local verification and testing. The =CMD= passed to the entrypoint, =foreground=, can be overridden with the =console= command to get an interactive shell when the container is run:

#+BEGIN_SRC shell
$ docker run -ti adoptingerlang.org/service_discovery console
[...]
(service_discovery@960409ea0bc0)1>
#+END_SRC

The =-ti= options tell =docker= we want an interactive shell, while `console` tells the same to the Erlang release.

A running node can also be attached to with =docker exec=, the container id (use =docker ps= to find this id) and =remote_console=:

#+BEGIN_SRC shell
$ docker exec -ti 960409ea0bc0 bin/service_discovery remote_console
[...]
(service_discovery@960409ea0bc0)1>
#+END_SRC

*** Building and Publishing Images in CI

Since it would be tedious to manually build and publish images images to the registry each release, it is common to include image building as part of the Continuous Integration process.  Usually this is restricted to only occur on a merge to master or a new tag being created, but it can sometimes be useful to also build branch images for testing purposes. In this section we will cover a couple options for automating this process, but whatever CI tool you're already using should be capable of something similar.

**** Google Cloud Build



*** Next Steps

In this chapter we built images for our service and finished off by creating a CI pipeline for continually building and publishing those images when changes are made to the repository. In the next chapter we will cover how to build a deployment to Kubernetes from these images. After we are running in Kubernetes the following chapter covers observability, such as connecting to a running node, well structured logs, reporting metrics and distributed traces.

** TODO Kubernetes
:PROPERTIES:
:EXPORT_FILE_NAME: kubernetes
:EXPORT_HUGO_MENU: :menu main :parent production
:END:

Kubernetes is a container orchestration system. When our backend contains many distinct services that need to be kept running, cross communicating and scaling an orchestration system becomes essential. And with the growing popularity of containers, using Kubernetes for orchestration has grown as well.

With containers and Kubernetes we have a shared method of deployment, discovery, scaling and monitoring across the various languages and runtimes we might have running and interacting in our system. So in this chapter we will go over the core components of Kubernetes and how to use them to deploy and manage the =service_discovery= service we built in the previous chapters.

*** Running Kubernetes

In order to develop and test the Kubernetes deploy, we will need to run Kubernetes locally for testing purposes, and then briefly discuss options for production deployments.

**** Locally

- [[https://github.com/kubernetes/minikube][minikube]]: The oldest and most flexible option, this is now an official part of the Kubernetes project. `minikube` offers support for various hypervisors and has an option to run without creating a new virtual machine, but it still suggests doing so within a Linux VM.
- [[https://docs.docker.com/docker-for-mac/#kubernetes][Docker for Mac Kubernetes]]: The easiest to get going with when running on MacOS.
- [[https://microk8s.io/][microk8s]]: An offering from Ubuntu, but runs on any [[https://docs.snapcraft.io/installing-snapd/6735][Linux distro that supports]] [[https://snapcraft.io/][snaps]]. microk8s is simple to install and get started with, and it runs locally, not within a VM like minikube, so is less of a resource hog.

**** Production

All the big cloud providers offer managed Kubernetes clusters: [[https://cloud.google.com/kubernetes-engine/][Google Kubernetes Engine]], [[https://www.digitalocean.com/products/kubernetes/][Digital Ocean Kubernetes]], [[https://aws.amazon.com/eks/][AWS Elastic Container Service for Kubernetes]] and [[https://azure.microsoft.com/en-us/services/kubernetes-service/][Azure Kubernetes Service]].

There are [[https://kubernetes.io/docs/setup/pick-right-solution/#table-of-solutions][many more options]] for deploying to the cloud or on-premise. Many factors go into play when choosing a solution, like in the case of an existing company, where are your services currently being hosted. Luckily with Kubernetes your deployment will not be locked in to any one provider.

*** Deployment

In Kubernetes, containers are part of a =Pod=. Each =Pod= has 1 or more containers, optionally including =init-containers= which run once before the other containers are started. For an application a higher level abstraction, called a =Deployment=, is used so individual =Pods= don't have to be manually created for deploying or scaling. A =Deployment= is a declarative way to create and update how many =Pods= of our application are to be run and how they are to be deployed.

Each Kubernetes resource is defined in a =yaml= file containing the =kind= of resource, =metadata=, such as a name, and the resource's specification:

#+BEGIN_SRC yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: service-discovery
spec:
#+END_SRC

The =Deployment= spec entries we will cover here are =selector=, =replicas= and =template=. The =selector= is a specification for which =Pods= belong to a =Deployment=. =matchLabels= in this case means that =Pods= with the label =app= with value =service-discovery= will be considered part of the =Deployment=. =replicas= declares how many instances of the =Pod= should be running.

#+BEGIN_SRC yaml
spec:
  selector:
    matchLabels:
      app: service-discovery
  replicas: 1
  template:
#+END_SRC

The =template= section is a =Pod= template and defines the specification of the =Pods= to be run by the =Deployment=:

#+BEGIN_SRC yaml
  template:
    metadata:
      labels:
        app: service-discovery
    spec:
      containers:
      - name: service-discovery
        image: tsloughter/service_discovery:06f522015c0d4c9ddcba73fdd632cf667cdb482c
        ports:
        - containerPort: 8053
          protocol: UDP
#+END_SRC

First, the =Pod= metadata sets the label to match with the =selector= from the =Deployment= spec. Then, the =Pod= spec has a list of containers. In this case there is one container that exposes port =8053= for UDP.

**** Resources

Each container spec in the =Pod= spec can include resource requests and limits for memory and CPU. Requests are used to schedule the pod. Scheduling involves choosing a node that the requested CPU and memory is available (not already requested by other Pods on the node).

#+BEGIN_SRC yaml
    resources:
      requests:
        memory: "250Mi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "2000m"
#+END_SRC

Additionally, CPU requests are translated to the cgroup property =cpu.shares=. Each CPU is considered 1024 slices and a CPU request tells the kernel how many of those slices to try to give to the process. But there is no upper bound to how much a process can ultimately take when only setting the shares. For throttling a process that is using too much CPU time we need the Kubernetes resource limits.

The limits are translated to CPU bandwidth controls for the Linux kernel scheduler to enforce on the process. Bandwidth control has a period, which is some number of microseconds, and a quota, the maximum number of microseconds a process can use within a period. The period is always 100000 microseconds, so in the case of the example above with CPU limit set to =2000m= the cgroup quota set will be =200000=, meaning 2 CPUs can be used every 100000 microseconds.

If the limit is exceeded during a period, the kernel will throttle the process by not allowing it to run again until the next period. This is why it is important to correctly set the number of Erlang VM schedulers that are used and to limit the amount of busy waiting done by the VM.

A busy wait is a tight loop an Erlang scheduler will enter waiting for more work to do before eventually going to sleep. This tight loop burns CPU just waiting to do actual work and can lead to much worse performance because your Erlang program will be likely to get throttled by the kernel scheduler. Then when there is actual work to be done, it may happen in a period the Erlang VM gets no CPU slices at all. This will be even worse if the VM is running more schedulers than CPUs it is allocated. The CPU limit of =2000m=, which we think of as meaning 2 CPU cores, does not actually restrict the process to 2 cores. If 8 schedulers are being used and there are the same number of cores on the node, those 8 will still spread across all the cores and run in parallel. But the quota is still =200000= and more likely to be exceeded when 8 schedulers are taking time on 8 cores. Even without the busy wait, a scheduler must do work of its own and can be unnecessary overhead when trying to stay within some CPU usage constraints.

In order to disable the scheduler busy waiting and to set the number of schedulers the VM spawns we set the VM arguments =+sbwt= and =+S= in =vm.args.src= as shown here:

#+BEGIN_SRC shell
+sbwt none

+S ${SCHEDULERS}
#+END_SRC

In the next section we will see how using an environment variable =${SCHEDULERS}= makes it easy to adjust the number of schedulers when we want to change the CPU limits in the Kubernetes resource.

**** Container Environments and ConfigMaps

As we've seen in the Releases chapter, runtime configuration is done through environment variable substitution in =vm.args.src= and =sys.config.src=. We therefore have to insert those variable to the environment of the container. Each container in a Kubernetes Pod can have a field =env= declaring a set of environment variables:

#+BEGIN_SRC yaml
env:
- name: LOGGER_LEVEL
  value: error
- name: PORT
  value: 8053
- name: SCHEDULERS
  value: 2
#+END_SRC

#+BEGIN_SRC yaml
env:
- name: NODE_IP
  valueFrom:
    fieldRef:
      fieldPath: status.podIP
#+END_SRC

#+BEGIN_SRC yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: configmap
data:
  LOGGER_LEVEL: error
  PORT: 8053
  SCHEDULERS: 2
#+END_SRC

#+BEGIN_SRC yaml
env:
- name: LOGGER_LEVEL
  valueFrom:
    configMapKeyRef:
      name: configmap
      key: LOGGER_LEVEL
- name: PORT
  valueFrom:
    configMapKeyRef:
      name: configmap
      key: PORT
- name: SCHEDULERS
  valueFrom:
    configMapKeyRef:
      name: configmap
      key: SCHEDULERS
#+END_SRC

A shortcut for bringing in all the variables defined in a ConfigMap as environment variables for the container can be done with =envFrom=:

#+BEGIN_SRC yaml
envFrom:
- configMapRef:
    name: configmap
#+END_SRC

Now all the variables defined in the ConfigMap will be added to the container without having to individually specify each one. For more on defining ConfigMaps see the upcoming section [Using Kustomize to Simplify Deployment].

#+attr_shortcode: note
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
<EXPLAIN THIS BETTER, maybe shouldn't be a note either but its own section in here>

Rolling updates: Do not modify existing ConfigMap. Instead, create a new ConfigMap with the necessary changes and modify the ConfigMap referenced by the deployment. The old ConfigMaps will eventually be garbage collected by kubernetes since they are not referenced anywhere.
#+end_notice

*** Service

Now that our application is able to run in Kubernetes through a =Deployment= we need a way to communicate with the =Pods= on their exposed port, =8053=. A =Service= defines a policy for accessing a set of =Pods= and provides environmental variables and DNS (technically an optional cluster addon) for finding them.

#+BEGIN_SRC yaml
kind: Service
apiVersion: v1
metadata:
  name: service-discovery
spec:
  selector:
    app: service-discovery
  ports:
  - protocol: UDP
    port: 8053
    targetPort: 8053
#+END_SRC

#+BEGIN_SRC shell
$ dig service-discovery.default

#+END_SRC

*** Using Kustomize to Simplify Deployment

[[https://kustomize.io/][Kustomize]] is a tool builtin to =kubectl= providing a template-free way to customize Kubernetes yaml resources. We will use it to create different configurations for different environments, starting with =dev=.

Our setup will be a base configuration with overlays for different environments that can add additional resources and make modifications to the resources from the base layer. The directory layout for the base configuration and a dev overlay is:

#+BEGIN_SRC shell
$ tree deployment
deployment
├── base
│   ├── application.properties
│   ├── default.env
│   ├── deployment.yaml
│   ├── kustomization.yaml
│   ├── namespace.yaml
│   └── service.yaml
└── overlays
    └── dev
        ├── flyway-deployment.yaml
        ├── kustomization.yaml
        ├── pgdata-persistentvolumeclaim.yaml
        ├── postgres-deployment.yaml
        └── postgres-service.yaml
#+END_SRC

The base =kustomization.yaml= includes the main resources of the service discovery project, a namespace, deployment and service:

#+BEGIN_SRC yaml
namespace: service-discovery
commonLabels:
  app: service-discovery
resources:
- namespace.yaml
- deployment.yaml
- service.yaml
configMapGenerator:
- name: configmap
  env: default.env
#+END_SRC

The labels under =commonLabels= will be added to each resource and simplifies the Deployment configuration from the earlier section by being able to remove both the =labels= entry and the =selector=:

#+BEGIN_SRC yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: service-discovery
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: service-discovery
        image: tsloughter/service_discovery
        ports:
        - containerPort: 8053
          protocol: UDP
#+END_SRC

Kustomize will insert the labels as well as the same labels under the =selector= field =matchLabels= automatically. To see what Kustomize creates run =kubectl kustomize= on the base and it will output the generated resources to the screen:

#+BEGIN_SRC shell
$ kubectl kustomize deployment/base
...
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: service-discovery
  name: service-discovery
  namespace: service-discovery
spec:
  replicas: 1
  selector:
    matchLabels:
      app: service-discovery
  template:
    metadata:
      labels:
        app: service-discovery
...
#+END_SRC

Another feature for improving creation of Deployments is generation of ConfigMaps. In the previous section on environment variables and ConfigMaps we ended with a Deployment that included environment variables from the data in a ConfigMap:

#+BEGIN_SRC yaml
envFrom:
- configMapRef:
    name: configmap
#+END_SRC

With Kustomize's =configMapGenerator= field we can declare that the ConfigMap be generated from any file with lines like =VarName=VarValue=:

#+BEGIN_SRC yaml
configMapGenerator:
- name: configmap
  env: default.env
#+END_SRC

The content of =default.env= is:

#+BEGIN_SRC shell
LOGGER_LEVEL=debug
#+END_SRC

The resulting ConfigMap seen in the output for =kubectl kustomize deployment/base= is:

#+BEGIN_SRC yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: service-discovery
  name: configmap-gdb24h2h47
  namespace: service-discovery
data:
  LOGGER_LEVEL: debug
#+END_SRC

Note that the name is no longer simply =configmap= but instead =configmap-gdb24h2h47=. Kustomize will create a new ConfigMap with a different name if the content changes and updates any reference to the ConfigMap by the name given to the generator. So in the Deployment we will also have:

#+BEGIN_SRC yaml
- envFrom:
  - configMapRef:
      name: configmap-gdb24h2h47
#+END_SRC

To apply the resources generated by Kustomize in one step the =-k= option can be passed to =kubectl apply=:

#+BEGIN_SRC shell
$ kubectl apply -k deployment/overlays/dev
#+END_SRC

This command will generate the resources based on the =dev= overlay and apply them to the Kubernetes cluster.

*** Tilt for Local Development

#+BEGIN_SRC shell
$ microk8s.enable registry
$ microk8s.enable dns
#+END_SRC

=/etc/docker/daemon.json=

#+BEGIN_SRC json
{
  ...
  "insecure-registries" : ["localhost:32000"]
  ...
}
#+END_SRC

*** Database Migrations
**** Jobs
**** Init Containers
*** StatefulSet

** TODO Operations
:PROPERTIES:
:EXPORT_FILE_NAME: operations
:EXPORT_HUGO_MENU: :menu main :parent production
:END:
*** Remote access
*** Metrics
**** VM
**** Libraries
**** Custom
*** Logging
*** Distributed tracing
* Team Building
:PROPERTIES:
:EXPORT_HUGO_SECTION: docs/team_building
:END:

** DONE Index
CLOSED: [2019-08-08 Thu 08:06]
:PROPERTIES:
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_FRONT_MATTER_KEY_REPLACE: title>label
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :title "Team Building"
:EXPORT_HUGO_MENU: :menu main :weight 4001
:END:

#+BEGIN_EXPORT html
<header>
  <h1>Team Building</h1>
  <h5>
    <strong>August 3, 2019</strong>
  </h5>
</header>
#+END_EXPORT

No business works only with code; it is way more frequent to hear about projects that failed due to bad communications and dysfunctional teams than it is to hear about projects that failed purely due to bad technological choices. This part of the book is dedicated to team-building, to figure out how to bootstrap a team of Erlang developers when you're starting without any in-house expertise.

#+BEGIN_EXPORT html
<div class="pagination">
  <div><a href="/docs/production">← Prev</a></div>
</div>
#+END_EXPORT

** TODO Who to Put on The Team
:PROPERTIES:
:EXPORT_FILE_NAME: on_the_team
:EXPORT_HUGO_MENU: :menu main :parent team-building
:END:

*** Building Around an Expert
*** Building Without an Expert
*** To Remote or Not To Remote
** TODO Repository Structures
:PROPERTIES:
:EXPORT_FILE_NAME: repo_structures
:EXPORT_HUGO_MENU: :menu main :parent team-building
:END:

** TODO Processes
:PROPERTIES:
:EXPORT_FILE_NAME: processes
:EXPORT_HUGO_MENU: :menu main :parent team-building
:END:

*** Code Reviews
*** Common Architecture Decisions
*** Prototype and Throw Away
*** Internal Training
** TODO How To Hire
:PROPERTIES:
:EXPORT_FILE_NAME: how_to_hire
:EXPORT_HUGO_MENU: :menu main :parent team-building
:END:

*** It Takes One to Know One
**** Hiring for Mentorship
*** It is Easier to Train than Hire

* DONE Appendix 1: Erlang/OTP Cheat Sheets
CLOSED: [2019-08-08 Thu 08:06]
:PROPERTIES:
:EXPORT_FILE_NAME: cheat_sheets
:EXPORT_HUGO_MENU: :menu main :weight 5001
:END:

This section contains various reminders to jog your memory if you're not too fresh on basic Erlang data, types, or syntax.

*** Data Types

| Name  | Description  | Dialyzer | Example Syntax |
|-------+--------------+----------+----------------|
| integer | number without decimals | =integer()=, =pos_integer()=, =non_neg_integer()= | =1=, =2=, =3=, =-213=, =16#01FF=, =2#101011= |
| float   | number with decimals | =float()= | =1.0=, =-1.0=, =123.12=, =1.0e232= |
| number | either floats or integers | =number()= | =1.0=, =1= |
| atom | literals, constants with their own name for value | =atom()= | =abc=, ='abc'=, =some_atom@erlang=, ='atom with spaces'= |
| boolean | atoms =true= or =false= | =boolean()= | =true=, =false= |
| reference | unique opaque value | =reference()= | =make_ref()= |
| fun | anonymous function | =fun()=, =fun((ArgType) -> RetType)= | <code>fun(X) -> X end, fun F(0) -> []; F(N) -> [1 \vert F(N-1)] end</code> |
| port | opaque type for a file descriptor | =port()= | N/A |
| pid  | process identifier | =pid()= | =<0.213.0>= |
| tuple | group a known set of elements | =tuple()=, ={A, B, C}= | ={celcius, 42=}, ={a, b, c}=, ={ok, {X, Y}}= |
| map  | a dictionary of terms | =map()=, ~#{KType => VType}~, ~#{specific_key := VType}~ | ~#{a => b, c => d}~, ~Existing#{key := Updated}~ |
| nil  | an empty list | =[]= | =[]= |
| list | recursive structure for a list of terms | =list()=, =[Type]= | =[a, b, c]=, <code>[a \vert [b \vert [c \vert []]]]</code>, ="a string is a list"= |
| binary | a flat byte sequence | =binary()= | =<<1,2,3,4>>=, =<<"a string can be a binary">>=, =<<X:Size/type, _Rest/binary>>= |

Term ordering: =number < atom < reference < fun < port < pid < tuple < map < nil < list < binary=

*** Modules and Syntax

#+NAME: all_syntax_mod
#+BEGIN_SRC erlang
%%% This is a module-level comment
%%% @doc This tag includes officiel EDoc documentation.
%%% It can be useful for people to consule
%%% @end
%%% Generate documentation with rebar3 edoc

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Let's start with Module Attributes %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is an attribute or function-specific comment
%% attributes start with a `-', functions with letters.
%% This file should be saved as `sample.erl'
-module(sample).

%% Functions are described in the form Name/Arity, and must
%% be exported through an `-export([...]).' module attribute
-export([f/0, f/1]).
-export([x/0]).         % multiple export attributes can exist

%% You can "import" functions from another module, but
%% for clarity's sake (and because there's no namespaces)
%% nobody really does that
-include(module, [y/0]).

%% .hrl files contain headers, and are imported directly
%% within the module.
%% The following includes a private header file from src/
%% or a public header file from include/ in the current app
-include("some_file.hrl").
%% The following includes a public header file from the
%% include/ file of another application
-include_lib("appname/include/some_file.hrl").

%% specify an interface you implement:
-behaviour(gen_server).

%% Define a record (a tuple that compilers handles in a
%% special way)
-record(struct, {key = default :: term(),
                 other_key     :: undefined | integer()}).

%% Just C-style macros
-define(VALUE, 42).        % ?VALUE in this module becomes `42'
-define(SQUARE(X), (X*X)). % function macro
-define(DBG(Call),         % a fancy debug macro: ?DBG(2 + 2)
        io:format("DBG: ~s (~p): ~p~n",
                  [??Call, {?MODULE, ?LINE}, Call])).

%% Conditionals
-ifdef(MACRO_NAME).        % opposite: -ifndef(MACRO_NAME).
-define(OTHER_MACRO, ok).
-else.                     % other option: -elif(NAME).
-define(MACRO_NAME, ok).
-endif.

%% Type definitions
-type my_type() :: number() | boolean().
-type my_container(T) :: {[T], [T], my_type(), mod:type()}
-export_type([my_type/0, my_container/1]).

%% you can also define custom attributes:
-my_attribute(hello_there).
-author("Duke Erlington").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% And now modules for code and functions %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% @doc A function with 0 arguments returning an atom
-spec f() -> term(). % optional spec
f() -> ok.

-spec f(number()) -> float().
f(N) -> N + 1.0.

%% Pattern matching with clauses
x([]) -> [];  % base recursive clause for a list
x([_H|T] -> [x | T]. % replace list element with `x' atom

%% @private variable binding rules
same_list(X = [_|_], X) -> true;
same_list([], []) -> true;
same_list(_, _) -> false.

%% Operators in the language
operators(X, Y) ->
    +X, -Y, % unary
    X + Y, X - Y, X * Y, X / Y,   % any numbers
    X div Y, X rem Y,             % integers-only
    X band Y, X bor Y, X bxor Y,  % binary operators
    X bsl Y, X bsr L,             % bit shifting
    not X,                        % boolean not
    X andalso Y, X orelse Y,      % shortcircuit boolean operators
    X < Y, X > Y, X >= Y, X =< Y, % comparison
    X == Y, X /= Y,               % equality (float == int)
    X =:= Y, X =/= Y,             % strict equality (float =/= int)
    X ++ Y, X -- Y,               % append Y to X, delete Y from X
    X ! Y.                        % send message Y to process X

%% Using guards. Valid guard expressions at:
%% erlang.org/doc/reference_manual/expressions.html#guard-sequences
comfortable({celsius, X}) when X >= 18, X =< 26 -> % AND clauses
    true;
comfortable({celsius, _}) ->
    false.

incomfortable({celsius, X}) when X =< 18; X >= 26 -> % OR clauses
    true;
incomfortable({celsius, _}) ->
    false.

%% difference with 'andalso' and 'orelse'
conds(X) when (is_number(X) orelse is_integer(X))
               andalso X < 9 ->
    %% equivalent (A AND B) OR C
    true;
conds(X) when is_number(X); is_integer(X), X < 9 ->
    %% - parentheses impossible with , or ;
    %% - equivalent to A OR (B AND C)
    true;
conds(T) when element(1, T) == celsius; is_integer(T) ->
    %% element/2 extracts an element from a tuple. If `T' is
    %% not a tuple, the call fails and `is_integer/1' is tried
    %% instead
    true;
conds(T) when element(1, T) == celsius orelse is_integer(T) ->
    %% this can never work: if element/2 fails, the whole
    %% `orlese' expressoin fails and `is_integer/1' is skipped
    true.

%% Conditionals
conditional('if', Light) ->
    if Light == red -> stop;
       Light == green; Light == yellow -> go_fast;
       true -> burnout % else clause!
    end;
conditional('case', {Light, IsLate}) ->
    case Light of
        green -> go;
        yellow when IsLate -> go_fast;
        _ -> stop
    end;
conditional(pattern, green) -> go;
conditional(pattern, yellow) -> slow;
conditional(pattern, red) -> stop.

%% List and binary comprehensions
comp(ListA, ListB) ->
    [X*X || X <- ListA, X rem 2 == 0], % square even numbers
    [{X,Y} || X <- ListA, Y <- ListB], % all possible pairs
    << <<X:8>> || X <- ListA >>.       % turn list into bytes
comp(BinA, BinB) -> % now with binaries
    << <<X*X:32>> || <<X:8>> <= Bin, X rem 2 == 0 >>,
    [{X,Y} || <<X:32>> <= BinA, <<Y:8>> <= BinB],
    [X || <<X:8>> <= BinA].

%% Anonymous and higher order functions
higher_order() ->
    If = fun(Light) -> conditional('if', Light) end,
    Case = fun(Light) -> conditional('case', {Light, true}) end,
    lists:map(If, [green, yellow, red]),
    lists:map(Case, [green, yellow, red]),
    If(red), % can be called literally
    lists:map(fun(X) -> X*X end, [1,2,3,4,5]).

try_catch() ->
    try
        some_call(),     % exceptions in this call are caught as well
        {ok, val},       % common good return value to pattern match
        {error, reason}, % common bad return value to pattern match
        % any of these expression aborts the execution flow
        throw(reason1), % non-local returns, internal exceptions
        error(reason2), % unfixable error
        exit(reason3)   % the process should terminate
    of  % this section is optional: exceptions here are not caught
        {ok, V} ->
            do_something(V),
            try_catch(); % safely recurse without blowing stack
        {error, R} ->
            {error, R} % just return
    catch % this section is optional: various patterns
        throw:reason1 -> handled;
        reason2 -> oops; % never matches, `throw' is implicit type
        error:reason2 -> handled;
        exit:reason3 -> handled;
        throw:_ -> wildcard_throws;
        E:R when is_error(E) -> any_error;
        _:_:S -> {stacktrace, S}; % extract stacktrace
    after -> % this is an optional 'finally' block
        finally
    end.
#+END_SRC


*** Processes and Signals

#+NAME: concurrency_constructs
#+BEGIN_SRC erlang
%% Start a new process
Pid = spawn(fun() -> some_loop(Arg) end)
Pid = spawn('name@remote.host', fun() -> some_loop(Arg) end)
Pid = spawn(some_module, some_loop, [Arg])
Pid = spawn('name@remote.host', some_module, some_loop, [Arg])
%% Spawn a linked process
Pid = spawn_link(...) % 1-4 arguments as with spawn/1-4
%% Spawn a monitored process atomically
{Pid, Ref} = spawn_monitor(fun() -> some_loop(Arg) end)
{Pid, Ref} = spawn_monitor(some_module, some_loop, [Arg])
%% Spawn with fancy options
spawn_opt(Fun, Opts)
spawn_opt(Node, Fun, Opts)
spawn_opt(Mod, Fun, Args, Opts)
spawn_opt(Node, Mod, Fun, Args, Opts)
%% Options must respect the following spec; many are advanced
[link | monitor |
 {priority, low | normal | high | max} |    % don't touch
 {fullsweep_after, integer() >= 0} |        % full GC
 {min_heap_size, Words :: integer() >= 0} | % perf tuning
 {min_bin_heap_size, Words} |
 {max_heap_size,                    % heap size after which
   Words |                          % the process may be killed. Use
   #{size => integer() >= 0,        % to indirectly set max queue sizes
     kill => boolean(),
     error_logger => boolean()}}

%% send an exit signal to a process
exit(Pid, Reason)

%% Receive a message
receive
    Pattern1 when OptionalGuard1 ->
        Expression1;
    Pattern2 when OptionalGuard2 ->
        Expression2
after Milliseconds -> % optional
    Expression
end

%% Naming processes
true = register(atom_name, Pid)
true = unregister(atom_name)
Pid | undefined = whereis(atom_name)

%% Monitor
Ref = erlang:monitor(process, Pid)
true = erlang:demonitor(Ref)
true | false = erlang:demonitor(Ref, [flush | info])

%% Links
link(Pid)
unlink(Pid)
process_info(trap_exit, true | false)
#+END_SRC

And the semantics for links and monitors, in diagram forms:

#+CAPTION: Monitors are unidirectional informational signals, and they stack
#+NAME: fig:sig_mon
[[./static/img/sig_mon_sm.png]]

#+CAPTION: Untrapped links are bidirectional and kill the other process, except if the reason is 'normal'
#+NAME: fig:sig_linked_notrap
[[./static/img/sig_linked_notrap_sm.png]]

#+CAPTION: Trapped links are converted to messages, except for the untrappable 'kill' reason
#+NAME: fig:sig_linked_trap
[[./static/img/sig_linked_trap_sm.png]]

OTP processes do have slightly different semantics due to supervision shenanigans:

#+CAPTION: Untrapped links work the same for OTP
#+NAME: fig:sig_otp_notrap
[[./static/img/sig_otp_notrap_sm.png]]

#+CAPTION: Trapped links behave in a special way when the parent of a process is the one that dies
#+NAME: fig:sig_otp_trap
[[./static/img/sig_otp_trap_sm.png]]

#+CAPTION: Supervisors log things differently based on the termination reason
#+NAME: fig:sig_otp_own
[[./static/img/sig_otp_own_sm.png]]

*** Behaviours

Not all OTP behaviours are listed here, only thee most frequently-used ones.

**** Applications

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =application:start/1-2= | client or booting VM | =start(Type, Args)= | <code>{ok, pid()} \vert {ok, pid(), State}</code> | should start the root supervisor |
| ={start_phases, [{Phase, Args}]}= in app file | =kernel= booting the app | =start_phase(Phase, Type, Args)= | <code>ok \vert {error, Reason}</code> | Optional. Allows to isolate specific steps of initialization |
| =application:stop/1= | app shutting down | =prop_stop(State)= | =State= | Optional. Called before the supervision tree is shut down |
| =application:stop/1= | app shutting down | =stop(State)= | =term()= | called once the app is done running to clean things up |
| Hot code update | SASL's release handler | =config_change(Changed::[{K,V}], New::[{K,V}], Removed::[K])= | =ok= | Called after a hot code update using the VM's relup functionality, if the configuration values changed |

**** Supervisors

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =supervisor:start_link/2-3= | parent process | =init(Arg)= | <code>ignore \vert {ok, {SupFlag, [Child]}}</code> | Specifies a supervisor. Refer to official documentation |

**** gen_server

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =gen_server:start_link/3-4= | supervisor | =init(Arg)= | <code>{ok, State [, Option]} \vert ignore \vert {stop, Reason}</code> | Set up the initial state of the process |
| =gen_server:call/2-3= | client | =handle_call(Msg, From, State)= | <code>{Type::reply \vert noreply, State [, Option]} \vert {stop, Reason [, Reply], State}code> | Request/response pattern. A message is received and expects an answer |
| =gen_server:cast/2= | client | =handle_cast(Msg, State)= | <code>{noreply, State [, Option]} \vert {stop, Reason, State}</code> | Information sent to the process; fire and forget |
| =Pid ! Msg= | client | =handle_info(Msg, State)= | same as =handle_cast/2= | Out-of-band messages, including monitor signals and ='EXIT'= messages when trappig exit |
| Setting an =Option= value to ={continue, Val}= | the server itself | =handle_continue(Val, State)= | same as =handle_cast/2= | Allows to break longer operations into triggerable internal events |
| =gen_server:stop/1,3= | client or supervisor | =terminate(Reason, State)= | =term()= | Called when the process is shutting down willingly or through errors. If the process does not trap exits, this callback may be omitted |
| =sys:get_status/2-3=, crash logs | client, the server itself | <code>format_status(normal \vert terminate, [PDict, State])</code> | =[{data, [{"State", Term}]}]= | Allows to add or remove information that would make it to debugging calls or error logs |
| N/A | supervisor | =code_change(OldVsn, State, Extra)= | ={ok, NewState}= | called to update a stateful process if the proper instructions are given during a hot code upgrade with releases |

**** gen_statem

***** Process management

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =gen_statem:start_link/3-4= | supervisor | =init(Arg)= | <code>{ok, State, Data [, Actions]} \vert ignore \vert {stop, Reason}</code> | Sets the initial state and data for the state machine |
| N/A | internal | =callback_mode()= | <code>[state_functions \vert handle_event_function [, state_enter]]</code> | Defines the type of FSM and whether entering a state triggers a special internal event |
| =gen_statem:stop/1,3= | client or supervisor | =terminate(Reason, State, Data)= | =term()= | Called when the process is shutting down willingly or through errors. If the process does not trap exits, this callback may be omitted |
| =sys:get_status/2-3=, crash logs | client, the server itself | <code>format_status(normal \vert terminate, [PDict, State, Data])</code> | =[{data, [{"State", Term}]}]= | Allows to add or remove information that would make it to debugging calls or error logs |
| N/A | supervisor | =code_change(OldVsn, State, Data, Extra)= | ={ok, NewState, NewData}= | called to update a stateful process if the proper instructions are given during a hot code upgrade with releases |

***** State handling and transitions

Handled by either =handle_event/4= or =StateName/3= functions, based on the value of =callback_mode()=. The function signatures are either:

- =handle_event(EventType, EventDetails, State, Data)=
- =State(EventType, EventDetails, Data)=

If the value of =State= is not a list, even though =callback_mode()= defined =state_functions=, then =handle_event/4= will be called. All possible return values for either functions are one of:

- ={next_state, State, Data}=
- ={next_state, State, Data, [Actions, ...]}=
- ={stop, Reason, Data}=
- ={stop, Reason, Data, [Actions, ...]}=

Various short forms exist, such as =keep_state_and_data=, ={keep_state, Data}=, ={repeat_state, Data}=, and many more. Refer to the documentation for their content.

The =Actions= value is any combination of the following list (non-inclusive): =postpone=, ={next_event, EventType, EventDetails}=, =hibernate=, ={timeout, Delay, EventDetails}=, ={state_timeout, Delay, EventDetails}=, ={reply, From, Reply}=, =hibernate=. Consult the documentation for more options.


| Trigger | Called By | Event Type | Event Details | Description |
|---------+-----------+------------+---------------+-------------|
| =gen_statem:call/2-3= | client | ={call, From}= | =term()= | Request/response pattern. A message is received and is expected to receive an answer |
| =gen_statem:cast/2= | client | =cast= | =term()= | Information must be sent to the process; fire and forget |
| Pid ! Msg | client | =info= | =Msg= | Out-of-band messages, including monitor messages and ='EXIT'= signals that are trapped |
| ={timeout, T, Msg}= | =Action= return value | =timeout= | =Msg= | A specific timeout that can be set and received internally when the state machine has not received a new event in =T= milliseconds |
| ={state_timeout, T, Msg}= | =Action= return value | =state_timeout= | =Msg= | A specific timeout that can be set and received internally when the state machine has not transitioned to a new different state in =T= milliseconds |
| ={next_event, internal, Msg}= | =Action= return value | =internal= | =Msg= | Internal messages that can be generated by a state machine wanting to trigger itself without looking like external calls |

* TODO Appendix 2: Systemd
:PROPERTIES:
:EXPORT_FILE_NAME: systemd
:EXPORT_FILE_NAME: cheat_sheets
:EXPORT_HUGO_MENU: :menu main :weight 6001
:END:

*** Systemd Unit

#+BEGIN_src shell
[Unit]
Description=Service Discovery Runner
After=network.target

[Service]
WorkingDirectory=/opt/service_discovery
EnvironmentFile=/etc/default/service_discovery.env
ExecStart=/opt/service_discovery/bin/service_discovery foreground
Restart=on-failure
Environment=RELX_OUT_FILE_PATH=/tmp/
Environment=COOKIE=service_discovery_cookie

[Install]
WantedBy=multi-user.target
#+END_src

As of OTP 19.3 a =SIGTERM= signal causes the OTP VM to gracefully shutdown.

#+BEGIN_src shell
journalctl service_discovery
#+END_src
* TODO Appendix 3: The Boot Script

The boot file has variables that must be set properly in order to find libraries and the runtime, the bundled script takes care of making sure these are set properly and passed to =erl=.

=-boot_var ERTS_LIB_DIR "$ERTS_LIB_DIR"=
