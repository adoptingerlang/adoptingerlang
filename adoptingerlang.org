#+TITLE:     Adopting Erlang
#+AUTHOR:    Fred Hebert, Tristan Sloughter
#+DRAWERS: HIDDEN HINT SOLUTION
#+EMAIL:     t@crashfast.com
#+DATE:      \today
#+DESCRIPTION: Adopting Erlang.
#+KEYWORDS: erlang

# \setcounter{secnumdepth}{-1}

#+LATEX_CLASS: book
#+LATEX_CLASS_OPTIONS: [oneside,11pt]
#+ATTR_LATEX: :width 4in
#+OPTIONS: H:6
#+LATEX_HEADER: \usepackage[Bjornstrup]{fncychap}
#+LATEX_HEADER: \usepackage[svgnames]{xcolor}
#+LATEX_HEADER: \usepackage[tikz]{bclogo}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{minted}
#+latex_header: \usepackage{xcolor}
#+latex_header: \usemintedstyle{monokai}    %% sets default for all source-code blocks
#+latex_header: \definecolor{friendlybg}{HTML}{f0f0f0}
#+latex_header: \definecolor{dark}{HTML}{272822}   %% custom colour for background
#+latex_header: \setminted{style=friendly, bgcolor=friendlybg, frame=lines, breaklines, breakanywhere}
#+LATEX_HEADER: \newenvironment{alert}{\begin{bclogo}}{\end{bclogo}}
#+LATEX_HEADER: \newenvironment{notice}{\begin{bclogo}}{\end{bclogo}}
#+OPTIONS: ^:{}
#+HUGO_BASE_DIR: .
#+HUGO_SECTION: docs
#+HUGO_PAIRED_SHORTCODES: %alert
#+HUGO_PAIRED_SHORTCODES: %notice

* Introduction
:PROPERTIES:
:EXPORT_FILE_NAME: introduction
:END:

There's a ton of Erlang books available out there, and a bunch more websites that can help you get started. The Erlang community has collectively spent years writing introductory content, and a lot of it is still really good. So what's the hope for yet another book?

Frankly, most of the material out there is really solid to teach you the Erlang basics, and we have no pretension of replacing them, nor a desire to re-explain the same content they contain once more. Instead, we the authors felt like while they are rock solid in a lot of areas, they still have a bunch of weaknesses.

For example, here are a bunch of interesting books:

- [[https://www.goodreads.com/book/show/808814.Programming_Erlang][Programming Erlang]], by Joe Armstrong is great to get into the philosophy behind Erlang
- [[https://www.goodreads.com/book/show/4826120-erlang-programming][Erlang Programming]], by Cesarini & Thompson is a very well-rounded practical approach to learning the language and bits of OTP
- [[https://www.goodreads.com/book/show/7438968-erlang-and-otp-in-action][Erlang and OTP in Action]], by Logan, Merritt & Carlsson is the first Erlang book that really tries to teach you OTP-first and hints at broader system design
- [[https://learnyousomeerlang.com/][Learn You Some Erlang]], by Fred Hebert, is possibly the friendliest introduction to both Erlang and OTP that tries to cover everything from basic Erlang to the design principles underpinning OTP, releases, and the whole ordeal
- [[https://www.goodreads.com/book/show/17984681-tudes-for-erlang][Études for Erlang]] by J. David Eisenberg is a fantastic companion exercise book that works with a bunch of other Erlang books, as a kind of practical complement
- [[https://www.goodreads.com/book/show/808815.Concurrent_Programming_ERLANG][Concurrent Programming ERLANG]] by Williams & Armstrong is a great piece of history from the 90s, showing earlier iterations of Erlang and how it could be applied to real world problems
- [[https://www.goodreads.com/book/show/15811999-introducing-erlang][Introducing Erlang]] by Simon St. Laurent is the most concise taste of Erlang you can get in book form
- [[https://www.erlang-in-anger.com/][Erlang in Anger]] by Fred Hebert is the only book that really contains a complete guide to debugging your Erlang systems in production
- [[https://www.goodreads.com/book/show/18324312-designing-for-scalability-with-erlang-otp][Designing for Scalability with Erlang/OTP]] by Cesarini & Vinoski is likely the most modern approach to Erlang/OTP systems with a real-world slant to it.
- [[https://blog.stenmans.org/theBeamBook/][The BEAM Book]] by Erik Stenman (and a lot of community contributors) is the most advanced resource on the virtual machine internals
- [[https://propertesting.com/][Property-Based Testing with PropEr, Erlang, and Elixir]] by Fred Hebert is the one book that teaches Property-based testing for Erlang

And there are some more too.

We intend to replace none of these. One huge omission in most (if not all) of these books, is that they tend to focus on Erlang/OTP on its own. In fact, many of these were written before massive shifts in how the community works. For example, _Learn You Some Erlang_, while very complete, was being written before _any_ community-driven build tool would see massive adoption, and before concepts such as OTP Releases would see widespread use. None of them have really been written under the new age of containerized platforms currently in place. And pretty much none of them mention how you should structure your projects to fit well within the open source Erlang ecosystem.

So this is what _Adopting Erlang_ is all about. This book (and website!) is all about filling in the niche that other books and manuals have not yet managed to properly cover. What you will learn in these pages will contain actually super useful stuff like:

- How to set yourself up to use multiple Erlang versions, because in the real world, you end up having to run multiple Erlang versions for the multiple projects your workplace or group of friends will end up using.
- We also cover how to set up editors and other tools, because chances are you may not have a good Erlang setup going even if you've already seen the basics
- How to approach OTP systems from the top. Most resources out there take a bottom-up approach, but we want you to be able to have the right project structure from day one, and then fill in the gaps with other resources as you need them
- What's needed for a good project, including dependency handling, some testing practices, handling configuration and documentation, and so on
- How to set up a good _Continuous Integration_ (CI) pipeline on common open platforms so that code reviews and automated testing can get the best support they can
- How to handle a bunch of difficult stuff nobody really teaches properly, like dealing with strings, specifically Unicode, time and proper SSL/TLS configuration
- How to deploy your Erlang systems as a self-executable bundle of files
- How to properly package your Erlang systems as Docker images, and showing how to manage their lifecycle with Kubernetes
- How to plan on setting up operations and get metrics going _outside_ of what the VM provides; think of things like logging and distributed tracing, platforms to get metrics dashboards going, and so on
- How to build a team that will start using Erlang in commercial projects
- How to interview your first Erlang experts or developers
- How to structure your practices for things such as code reviews, experience sharing, and so on.

By opposition, we will _not_ cover things like basic Erlang, core OTP behaviours, and so on. They have been covered multiple times in other resources in the past, many of which are freely available. We still have put together an appendix of cheat sheets you can refer to if you need a refresher.

Essentially, we hope for _Adopting Erlang_ to be the missing link between all the various starter books with their various approaches, and the material like _Erlang in Anger_ that lets you debug stuff in production. We want this book to teach you how to go from "Okay, I think I got the basics" to "let's get this project going, and let's do it right." After reading this book, you should be able to know exactly what the best practices are to fit right in with the rest of the Erlang community.

** About the Authors

*** Tristan Sloughter

Tristan is a long time Erlang hacker, having gotten into it in college and then professionally for various companies, eCDMarket, Orbitz Worldwide, Heroku, SpaceTime Insight, and currently as a senior software engineer at Postmates, Inc. Tristan is also one of the maintainers of the release tool Relx and build tool Rebar3.

*** Fred Hebert

Fred is the author of _Learn You Some Erlang_, _Erlang in Anger_, and more recently, _Property-Based Testing with PropEr, Erlang, and Elixir_. He is a maintainer of Rebar3, and of libraries such as recon, pobox, vmstats, and backoff.

He is a Systems Architect at Genetec, a company offering video systems, access control, case management, and IoT integration systems. Previously, he was a principal member of technical staff on the Heroku platform, worked in real-time bidding, and provided Erlang training.

* Development
:PROPERTIES:
:EXPORT_FILE_NAME: development
:END:
#+latex_header: \usepackage[utf8]{inputenc}
#+latex_header: \usepackage{pmboxdraw} % for directory listings
#+latex_header: \usepackage{textalpha} % for greek a
#+latex_header: \usepackage[T2A]{fontenc} % cyrilic a
#+latex_header: \DeclareUnicodeCharacter{0430}{\cyra} % cyrilic a
#+latex_header: \DeclareUnicodeCharacter{03A9}{Ω} % omega vs. ohm
#+latex_header: \DeclareUnicodeCharacter{267B}{\includegraphics[height=\fontcharht\font`\B]{./static/img/recycling.png}}
#+latex_header: \DeclareUnicodeCharacter{FDFD}{\includegraphics[height=\fontcharht\font`\B]{./static/img/bismillah.png}}
#+latex_header: \DeclareUnicodeCharacter{1F469}{\includegraphics[height=\fontcharht\font`\B]{./static/img/woman.png}}
#+latex_header: \DeclareUnicodeCharacter{1F466}{\includegraphics[height=\fontcharht\font`\B]{./static/img/boy.png}}
#+latex_header: \DeclareUnicodeCharacter{1F914}{\includegraphics[height=\fontcharht\font`\B]{./static/img/thinking.png}}
#+latex_header: \DeclareUnicodeCharacter{200D}{\hspace{0pt}}

The first section of this book is dedicated to getting a working installation working, and understanding the actual structure of a project. This section will also cover how to import dependencies in your project, how to build projects that contain multiple OTP applications, write tests for your projects, and also a few other interesting topics.

** Setup

In this chapter, you will go through the basic steps required to install Erlang/OTP on most major platforms. The instructions will aim for a basic set-up, and in some more popular platforms, will also target running multiple Erlang/OTP versions at once, as a team with growing projects is likely to have to test multiple deploy scenarios.

You will also see how to install Rebar3, the official build tool for the Erlang community, and base configurations for various text editors.

*** Installing Erlang/OTP

The first step is to get a proper install of Erlang/OTP in place. This is not going to be a uniform experience on all platforms, but we'll at least make sure everyone following these steps has a fully functioning setup for any work environment.

**** Choosing a Version

Erlang/OTP is released on a fairly stable and predictable schedule, with well-defined criteria for backwards-incompatible changes.

Erlang versions are numbered according to a =<Major>.<Minor>.<Patch>= scheme, as described in the [[http://erlang.org/doc/system_principles/versions.html#version_scheme][Erlang/OTP system principles]]. In some rare circumstances, other digits are bolted on as "branched" versions, which you likely won't have to care about.

Here are some example possible versions:

- 22.0-rc1
- 21.3
- 21.2.3
- 21.1
- 19.3
- 17.0
- R16B03 (this is a legacy version format that hasn't been used since 2014)

As you can see, the =Patch= version is not mentioned when no patch is required. The release schedule for Erlang goes a bit like this:

1. Once per year, around February or March, a release candidate for the next major version is announced (with a suffix such as =-rc1=, or =-rc2=). This release candidate is made available for users who want to build from source, in order to test that their applications and system will work well with it
2. A few months later (April to June), the major release is cut and made public. Major releases contain large new features that require bigger virtual machine changes, and are also allowed to introduce backwards-incompatible changes
3. At a frequency of every three or four months, a minor release is made public, which usually includes stability fixes and minor feature additions in individual libraries
4. If a critical bug has been found in some circumstances, either for security or stability reasons, a patch release may be announced.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_alert
Backwards incompatible changes are usually going through a cycle of deprecation before being removed, which tends to leave ample time to adapt. The policy is described in the [[http://erlang.org/doc/system_principles/misc.html][Support, Compatibility, Deprecations, and Removal]] document published by the OTP team at Ericsson.
#+end_alert

In some rare scenarios, hard-and-fast deprecations do happen, and it may take a few weeks for the community to come up with workarounds.

A team that adopts Erlang will therefore likely want to adopt a maintenance schedule that fits the main releases if they want to avoid falling too far behind. While it is possible to only upgrade occasionally, you will find that it is often easier to do a bit of maintenance somewhat often than a lot of maintenance at once.

Do note that patch-level releases are often only announced on the [[http://erlang.org/mailman/listinfo/erlang-questions][mailing lists]] and tagged on [[https://github.com/erlang/otp][the main git repository on GitHub]], but are otherwise not packaged on the main website.

**** Windows

If you are a Windows user, it is recommended that you use Windows 10 for any Erlang development. Prior versions can work, but community tools such as Rebar3 are only tested on Windows 10, for example.

Building on Windows from source has been notoriously difficult, and it is therefore recommended that you stick to the pre-built copies distributed on [[https://www.erlang.org/downloads][www.erlang.org/downloads]], or alternatively those built by [[https://www.erlang-solutions.com/resources/download.html][Erlang Solutions Ltd.]].

The installer for these versions comes with a wizard that will take you through all the required steps.

Do not forget to add Erlang/OTP to your =PATH= variable to contain your Erlang/OTP installation, since this will let you call it from the command-line:


1. In the start menu, search for "system environment variables" and select the "Edit the System and Environment Variables (Control Panel)" option
2. At the bottom of the "System Properties" window that has just open, press the "Environment Variables..." button
3. Select the =Path= variable (or create it if it does not exist) and click the "Edit" button
4. Add an entry for Erlang/OTP that matches the installation path, usually something like =C:\Program Files\erl10.2\bin=. The entries put earlier in the list will be loaded first.
5. Save the options
6. Close and restart any terminal you were running.

If you do development in the long term, you will be able to install multiple versions that way. You can control which one is used by changing and modifying the =PATH= variable's priorities in paths.

If you are a purist when it comes to Windows development, you may be quite comfortable in an environment such as Visual Studio, where pretty much everything can be done from within the IDE. Erlang comes from a different environment, and a lot of the instructions we'll use in this book are focused on using the command line to build everything.

If you are looking for a terminal to run the command line on Windows, various options are available:

- Use PowerShell as a terminal. Most commands in this book should work fine with it, but some edge cases may exist.
- Download and install [[https://git-scm.com/download/win][git for Windows]], which will come with a =git-bash= shell that will work well with all tooling and most commands in this book
- Try [[https://www.fosshub.com/ConEmu.htm][ConEmu]] as a nicer terminal emulator to work with
- Use [[https://cmder.net/][Cmder]] which is a Windows console emulator that packages most of the above options rather well
- Use [[https://www.cygwin.com][Cygwin]] at your own risk; you will need to rebuild your software from source to work well with it, and tools like Rebar3 dynamically figure out they're on Windows, which historically has caused a few path problems when interacting with Cygwin

You can then use the editor or IDE of your choosing to work with Erlang components.

**** OSX

While OSX makes it possible to use [[https://brew.sh/][Homebrew]] or [[https://www.erlang-solutions.com/resources/download.html][Erlang Solutions Ltd. packages]] to install pre-built versions of Erlang/OTP, you should only do so if you're trying things out the first time around. If you're planning on doing actual development for the longer haul, you'll instead want to be able to handle multiple versions at once.

The most commonly supported tool for this is [[https://github.com/kerl/kerl][kerl]]. Kerl is a wrapper around downloading, compiling, and loading various Erlang/OTP versions on a single system, and will abstract away most annoying operations.

You can install Kerl from homebrew by calling =$ brew install kerl=, or by following the instructions in its [[https://github.com/kerl/kerl#downloading][README file]].

Before installing Erlang, we will need to install and update a few dependencies, the main ones being to make sure you have [[https://developer.apple.com/xcode/][XCode]] installed and to then install OpenSSL (since OSX has terribly outdated copies of SSL by default):

#+NAME: openssl_osx
#+BEGIN_SRC sh
$ brew install openssl
...
$ ls /usr/local/Cellar/openssl/
1.0.2q
#+END_SRC

Note the full path this gives you for the local openssl install, here being =/usr/local/Cellar/openssl/1.0.2q/=

You can set the following options in your environment:

#+NAME: kerlcfg_osx
#+BEGIN_SRC sh
SSL_PATH=/usr/local/Cellar/openssl/1.0.2q/
export KERL_BUILD_BACKEND="git"
export KERL_CONFIGURE_OPTIONS="--without-javac \
                               --with-ssl=${SSL_PATH}"
#+END_SRC

And ensure it's active (for example, call =source ~/.bashrc=). These options specify what is accepted or expected from the build tool. The one here disables Java bindings, and uses the new SSL install we've made. You can look at the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#configuring-1][Build Instructions]] for more configuration options.

If you want to add more content, such as =Wx= (which lets you use and build GUIs), the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#os-x-darwin][Build instructions for OSX]] contain further details to guide you.

From that point on, you can download and install your own Erlang/OTP versions:

#+NAME: kerl_osx
#+BEGIN_SRC sh
$ kerl update releases
...
# kerl build <release> <build name>
$ kerl build 21.3 21.3
...
# kerl install <build name> <target path>
$ kerl install 21.3 ~/bin/erls/21.3/
...
# make that version active
$ . ~/bin/erls/21.3/activate
# or alternatively
$ source ~/bin/erls/21.3/activate
#+END_SRC

Any installed version can then be activated on-demand. If you want to set a default version, you can put the activation command in your =.bashrc= configuration file (or any shell profile you might have).

**** Linux

Linux distributions pretty much all have package managers that let you install pre-built copies of Erlang, or you can still use [[https://www.erlang-solutions.com/resources/download.html][Erlang Solutions Ltd. packages]]. Much like with OSX though, you should only do so if you're trying things out the first time around. If you're planning on doing actual development for the longer haul, you'll instead want to be able to handle multiple versions at once.

The most commonly supported tool for this is [[https://github.com/kerl/kerl][kerl]]. Kerl is a wrapper around downloading, compiling, and loading various Erlang/OTP versions on a single system, and will abstract away most annoying operations.

You can install kerl by calling:

#+NAME: linux_kerl
#+BEGIN_SRC sh
$ curl -O https://raw.githubusercontent.com/kerl/kerl/master/kerl
$ chmod a+x kerl
#+END_SRC

And then moving kerl to your path. Kerl will automatically check and warn you about missing dependencies you might be needing when building libraries, so you can just go ahead and run the following commands, and listen to its directions as you go.

First, you can set options as follows in your environment:

#+NAME: kerlcfg_linux
#+BEGIN_SRC sh
export KERL_BUILD_BACKEND="git"
export KERL_CONFIGURE_OPTIONS="--without-javac"
#+END_SRC

And ensure it's active (for example, call =source ~/.bashrc=). These options specify what is accepted or expected from the build tool. The one here disables Java bindings, but they would be skipped automatically anyway. You can look at the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#configuring-1][Build Instructions]] for more configuration options.

If you want to add more content, such as =Wx= (which lets you use and build GUIs), the [[https://github.com/erlang/otp/blob/master/HOWTO/INSTALL.md#building-with-wxerlang][Build instructions for Wx]] contain further details to guide you.

From that point on, you can download and install your own Erlang/OTP versions:

#+NAME: kerl_linux
#+BEGIN_SRC sh
$ kerl update releases
...
# kerl build <release> <build name>
$ kerl build 21.3 21.3
...
# kerl install <build name> <target path>
$ kerl install 21.3 ~/bin/erls/21.3/
...
# make that version active
$ . ~/bin/erls/21.3/activate
# or alternatively
$ source ~/bin/erls/21.3/activate
#+END_SRC

Any installed version can then be activated on-demand. If you want to set a default version, you can put the activation command in your =.bashrc= configuration file (or any shell profile you might have).

**** FreeBSD

On FreeBSD, some patches are required to make things work as smoothly as on other platforms. The good news is that if you use either the BSD [[https://www.freebsd.org/doc/en/books/handbook/ports-using.html][ports]] or [[https://www.freebsd.org/doc/en/books/handbook/pkgng-intro.html][packages]], it will all work fine out of the box.

This is the easiest way forwards, but makes switching across versions a bit trickier since you don't get an Erlang version manager for free. However, BSD ports and packages do let you build any version supported at your liking.

For example you can call any of the following:

#+NAME: bsd_install
#+BEGIN_SRC sh
# pkg install erlang # default copy
# pkg install erlang-runtime20  # OTP-20.x
# ls /usr/ports/lang/erlang* # source install: pick the version directory
erlang/
...
erlang-runtime20/
erlang-runtime21/
erlang-wx/
# cd /usr/ports/lang/erlang-runtime21/
# make config-recursive     # configure all the deps
# make install
#+END_SRC

FreeBSD maintainers are generally good about ensuring things keep working fine on the main supported architectures, so if you're sticking to x86 and avoid ARM, you should have no major issues.

**** Making things Nice

Before you're done, you should go to your shell or terminal profile, and add a few environment variables. Specifically, you can use =ERL_AFLAGS= or =ERL_ZFLAGS= to add configuration switches to the =erl= executable at all times.

We'll use =ERL_AFLAGS= to turn on two neat features: outputting strings with Unicode support by default, and enabling shell history so that the Erlang shell remembers your commands between invocations. Add the following to your environment:

#+NAME: erl_aflags
#+BEGIN_SRC sh
export ERL_AFLAGS="+pc unicode -kernel shell_history enabled"
#+END_SRC

Things will feel a bit more modern that way.

*** Installing Rebar3

Rebar3 is the standard build tool within the Erlang community. It essentially bundles all of the other tools shipping with Erlang along with a few open-source ones, and makes them all work under a unified project structure.

There are a few ways to install Rebar3: from a pre-built binary, or from source, and then a last variant for a faster-running local install. Do note that in all cases, you need Erlang to have been installed already.

**** Pre-Built Binaries

Pre-built binaries can be found at [[https://www.rebar3.org/][www.rebar3.org]]. There's a big "Download" button with the latest stable version, but if you like to live more dangerously, you can grab [[https://s3.amazonaws.com/rebar3-nightly/rebar3][the latest _nightly_ build]] as well.

It is common to create a directory =~/bin/= to place commands line utilities like =rebar3=, which is where you might want to put the version you just downloaded. Call =chmod +x rebar3= on it to make sure it can run, and add it to your path with =export PATH=~/bin/:$PATH= in your =~/.bashrc=, =~/.zshrc= or equivalent.

Windows users who want to use the code from PowerShell or cmd.exe (rather than a terminal emulator) must ensure that a =rebar3.cmd= file is added:

#+NAME: rebar.cmd
#+BEGIN_SRC sh
@echo off
setlocal
set rebarscript=%~f0
escript.exe "%rebarscript:.cmd=%" %*
#+END_SRC

**** Building From Source

First make sure that you have git installed, and checkout the repository to build it:

#+NAME: rebar_bootstrap
#+BEGIN_SRC sh
$ git clone https://github.com/erlang/rebar3.git
$ cd rebar3
$ ./bootstrap
#+END_SRC

This will create a =rebar3= script file (along with a =rebar3.cmd= file on Windows).

**** Local Install

The local install form will let you take any of the previously built rebar3 versions, and unpack them to a local directory from which the tool will be able to self-update at a later time:

#+NAME: rebar_local
#+BEGIN_SRC sh
$ ./rebar3 local install  # starting from a rebar3 not in PATH
===> Extracting rebar3 libs to ~/.cache/rebar3/lib...
===> Writing rebar3 run script ~/.cache/rebar3/bin/rebar3...
===> Add to $PATH for use: export PATH=$PATH:~/.cache/rebar3/bin
$ export PATH=$PATH:~/.cache/rebar3/bin
$ rebar3 local upgrade # this can be used to update to the latest stable copy
...
#+END_SRC


*** Configuring Editors

**** Visual Studio Code

Although there exists a [[https://github.com/erlang/sourcer][language server]] with its own [[https://github.com/vladdu/vscode-erlang-lsp][extension]], they are at the time of this writing only at an experimental stage. Instead, the [[https://marketplace.visualstudio.com/items?itemName=pgourlain.erlang][Erlang extension]] by Pierrick Gourlain is recommended.

To configure the extension, go to the =Preferences= and then =Settings= menu. Within the VS Code window, unroll the =Extensions= menu until the =erlang configuration= section. Make sure that all the values are right, particularly the Erlang path and the Rebar3 path. With this in place, you can mix and match all the other extensions you'd like and things should be ready to go.

The code formatter may feel a bit janky; it respects the official Erlang repository's old rules of mixing tabs and spaces, and expects each tab is 8 spaces wide. This is not really use anywhere else, and if your Visual Studio Code is not configured that way (using 4 spaces for example), it will just look off.

Otherwise, that extension covers all the major features: jumping around code definitions, build tool support (although only =compile=, =eunit=, and =dialyzer= are supported in the command palette, you can still call =rebar3= directly from the terminal), intellisense, warnings as you type, and CodeLens features. If you look at the extension's documentation, you'll also find debugger support instructions.

All you've got to do then is configure themes and more general extensions to your liking.

**** Emacs

TODO

**** Vim

Although absolutely fancy support for Erlang is possible in Vim—as the [[https://github.com/vim-erlang][vim-erlang group on Github]] allows—the authors of this book who use it tends to stick with the most minimal configuration possible.

Simply stick with the default syntax highlighting in your =.vimrc= file, and make sure it's used in all the right file types:

#+BEGIN_SRC vim
"also erlang
autocmd BufRead,BufNewFile *.erl,*.es.*.hrl,*.xrl,*.config setlocal expandtab noautoindent
au BufNewFile,BufRead *.erl,*.es,*.hrl,*.xrl,*.config setf erlang
#+END_SRC

This is the very basic stuff, obviously. Fancier integration is possible, but the one author who uses vim mostly uses only this, and relies on Rebar3 in a terminal to deal with the rest of the language.

** OTP at a High Level

*** The Erlang Run-Time System

Erlang/OTP is different from most programming environments out there, even those that also use a virtual machine. You may have heard people comparing Erlang to an operating system and that is an apt comparison. It's not that Erlang provides low-level primitives and drivers that let you run without an operating system--you'll still need that. Rather, it is that Erlang has a strong opinion about how your applications should be structured, the level of isolation they should have, and a separation between what Erlang's VM can do, and what your softwafe can do.

The foundational block for everything is the Erlang virtual machine itself, called BEAM. BEAM is technically a single implementation of the Erlang virtual machine, as there could be others. For example, Erllvm is an implementation over LLVM (using some custom patches to make everything possible), and an older implementation in the 90s was called JAM. The Erlang VM is implemented in C, and contains a lot of fancy stuff: schedulers to run processes, garbage collection, memory allocators, a timer wheel for events, a bunch of smart switches to abstract over operating system features and provide unified interfaces (such as over time management, file-handling drivers, and so on), a few built-in functions that go faster than what Erlang can do on its own (BIFs) and an interface for functions implemented natively in other languages (NIFs) along with special schedulures for them. There's obviously a lot more, but you can think of all that stuff the way you would with the kernel in BSD or Linux: low level stuff that you need in order to build fancier stuff.

If all you have is the virtual machine with nothing else, you can't run Erlang code. You don't have a standard library, you don't have libraries to even load code. There's some odd bootstrapping going on that we don't need to understand. Just know that there's a limited set of pre-loaded Erlang modules that ship with the virtual machine, and those can be used to set up networking and file-handling stuff that allows to further load and run modules. If you're interested in knowing more though, please consult [[https://happi.github.io/theBeamBook/][The BEAM Book]] or [[http://beam-wisdoms.clau.se/en/latest/][BEAM Wisdoms]].

If you take the virtual machine and the pre-loaded stuff, along with all the little utilities that make code-loading possible, you have what is essentially called the _Erlang Run-Time System_ (ERTS). The Run-Time System, when starting, follows the values of a thing called a _boot script_ (which nobody writes by hand) that specifies what to start. Erlang, by default, provides boot scripts that load code described in the next section as part of its boot sequence.

With this basic stuff in place, we fall into Erlang's space, something akin to userspace if we want to keep the comparison operating systems.

*** Erlang/OTP

If what we have right now is equivalent to the kernel, we need the foundational blocks for the userspace components. In Erlang, this is essentially what OTP is about. OTP specifies how "components" that run on the virtual machine should be structured. From the first start, there is more than just "processes and messages", there's one way to structure your code.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_alert
OTP stands for _Open Telecom Platform_, which is literally a meaningless name that was used to get the stuff open-sourced back in the old days of Erlang at Ericsson.
#+end_alert

This is done through the use of components named _OTP Applications_. Every Erlang install that you use ships with a few of them, because it would be way too much trouble not to. There are basically two variants of OTP applications: _Library Applications_, which are just collections of modules, and regular _OTP Applications_, which contain a collection of modules, but also specify a stateful process structure stored under a supervision tree. For the sake of clarity, we're going to use the following terminology for OTP Applications for this entire book:

- _Library Applications_: stateless collections of modules
- _Runnable Applications_: OTP applications that start stateful supervision tree structures with processes running in them
- _OTP Applications_: either _Library_ or _Runnable Applications_, interchangeably

By default, the two OTP applications everyone includes are called =stdlib=, which is a library application that contains the core standard library modules such as =list= or =maps=, and =kernel=, which is a runnable application and sets up the core structure for an Erlang system that relies on OTP applications to work.

The way things go is that the modules from all required OTP applications are loaded in memory. Then =kernel= is started. Kernel manages the lifecycle of the system from this point on. All other OTP applications and their configuration are handled through it, and so are unique features like distribution and hot code updates. If we go back to the operating system comparison, you can think of the =kernel= OTP application a bit like you could think of =systemd= for the Linux kernel (or =init= if you hate =systemd= or use a BSD -- Windows users can think of it as the service that runs other services)

In fact, kernel and stdlib are the only two applications you need for a basic working Erlang shell. When you type in =erl= (or start =werl= on Windows), this boots up the VM, along with kernel, with =stdlib= pre-loaded. Everything else is optional and can be loaded at a later time.

The standard Erlang distribution contains applications such as:

- kernel
- stdlib
- crypto (cryptographic primitives)
- ssl (TLS termination library)
- inets (network services such as FTP or HTTP clients)
- ct (Common Test framework)
- wx (graphic toolkit)
- observer (a control panel to manage your Erlang node, building on =wx=)
- compiler (the Erlang compiler to build your own project)
- and so on

All of these are put together into what is called an Erlang _release_. A release is a collection of OTP applications, possibly bundled together with a full virtual machine. As such, when you download and install Erlang, you just get a release whose name is something like _Erlang/OTP-21.3.4_. You're free to build your own releases, which will take some of the OTP applications in the standard distribution, and then bundle them with some of your own apps.

So if we to write an app named =proxy= that relies on =ssh= and =ssl= (which themselves depend on =public_key=, =crypto=, =stdlib=, and =kernel=), we make a release with all of these components in it:

- ERTS
- kernel
- stdlib
- crypto
- public_key
- ssl
- ssh
- proxy

A visual representation of this can be seen in Figure [[fig:proxy_release]].

#+CAPTION: Visual representation of building the =proxy= release
#+NAME:   fig:proxy_release
[[./static/img/proxy_release_draft.png]]

Essentially, building an Erlang system is re-bundling the VM, along with some standard applications provided with the default distribution, together with your own apps and libraries.

*** Living in Erlang/OTP

Standard tools developed and used by the community such as rebar3 basically operate on the idea that what you write and publish are OTP applications, and contains all the functionality required to deal with them. That's a big shift from a lot of programming languages that only ask of you to have a function named =main()= somewhere in one of your files. This is why the programming language is often called =Erlang/OTP= rather than just 'Erlang': it's not just a programming language, it's a general development framework that mandates some basic structure for everything you do.

And everyone follows it, whether they are writing embedded software, blockchain systems, or distributed databases. It's OTP or nothing. Whereas other languages usually mandate nothing specific to get started, but then add some requirements later on (such as when integrating with a package manager), Erlang--and its entire community--expects you to just write OTP applications, which the rest of the tools can handle.

So the key to getting started fast in Erlang is to know the framework, which is often kept as more advanced material. Here we're going to do things upside down and start from a fully functional release, and then dig down into its structure. The next chapters will be dedicated to understanding how to work within these requirements.


** OTP Applications

Since every component to be shipped in an Erlang/OTP release needs to be an OTP Application, it will do you a great good to understand what they are and how they work. In this chapter, we'll go over the basic structure of an OTP application, and what that means for your project.

*** Project Structure

We'll start by using the rebar3 templates, since they will allow us to create brand new projects that properly respect the directory structures expected by Erlang/OTP. Let's see which templates are available:

#+NAME: rebar3_new
#+BEGIN_SRC sh
$ rebar3 new
app (built-in): Complete OTP Application structure.
cmake (built-in): Standalone Makefile for building C/C++ in c_src
escript (built-in): Complete escriptized application structure
lib (built-in): Complete OTP Library application (no processes) structure
plugin (built-in): Rebar3 plugin project structure
release (built-in): OTP Release structure for executable programs
umbrella (built-in): OTP structure for executable programs
                     (alias of 'release' template)
#+END_SRC

Here's a table showing when they might be used:

| Type of Project                    | Template to use | Comments                                                            |
|------------------------------------+-----------------+---------------------------------------------------------------------|
| script or command line tool        | escript         | Requires Erlang to be installed by the user                         |
| a library (collection of modules)  | lib             | Can be used as a dependency                                         |
| a library (stateful processes)     | app             | Can be used as a dependency                                         |
| full executable program            | umbrella or app | Can be turned into a full release, the recommended deploy mechanism |
| a collection of multiple libraries | umbrella        | Cannot be used as a git dependency but each individual app could be published to hex |
| rebar3 extension                   | plugin          |                                                                     |
| compiling C code                   | cmake           | Also see the "pc" plugin for a portable way to compile C/C++        |

You can see the details of a given template by calling =rebar3 new help <template>=. See for example:

#+NAME: rebar3_new_lib
#+BEGIN_SRC sh
$ rebar3 new help lib
lib:
  built-in template
  Description: Complete OTP Library application (no processes) structure
  Variables:
    name="mylib" (Name of the OTP library application)
    desc="An OTP library" (Short description of the app)
    date="2019-03-15"
    datetime="2019-03-15T19:52:31+00:00"
    author_name="Fred Hebert"
    author_email="mononcqc@ferd.ca"
    copyright_year="2019"
    apps_dir="apps" (Directory where applications will be created if needed)
#+END_SRC

The values can be modified as desired on the command line, but those are the default variables. Let's see what we get by writing our own:

#+NAME: rebar3_new_mylib
#+BEGIN_SRC sh
$ rebar3 new lib mylib desc="Checking out OTP libs"
===> Writing mylib/src/mylib.erl
===> Writing mylib/src/mylib.app.src
===> Writing mylib/rebar.config
===> Writing mylib/.gitignore
===> Writing mylib/LICENSE
===> Writing mylib/README.md
#+END_SRC

Go to the =mylib= directory, and call =rebar3 compile= right away:

#+NAME: rebar3_mylib_compile
#+BEGIN_SRC sh
$ rebar3 compile
===> Verifying dependencies...
===> Compiling mylib
#+END_SRC

If you look at your directory structure, you should now have something like this in your project:


#+NAME: lib_structure
#+BEGIN_SRC sh
mylib/
├─ _build/
│  └─ default/
│     └─ lib/
│        └─ mylib/
│           ├─ ebin/
│           │  ├─ mylib.app
│           │  └─ mylib.beam
│           ├─ include/
│           ├─ priv/
│           └─ src/
│              └─ ...
├─ .gitignore
├─ LICENSE
├─ README.md
├─ rebar.config
├─ rebar.lock
└─ src/
   ├─ mylib.app.src
   └─ mylib.erl
#+END_SRC

The =_build/= directory is the build tool's playground, where it can stash all the artifacts it needs. You should never have to touch what is in there by hand. This directory is nonetheless interesting because it shows how rebar3 structures things.

Everything in =_build/= is split by [[https://www.rebar3.org/docs/profiles][profile]], which lets rebar3 build things differently (with different sets of dependencies and compiler options) whether they are built in the =default=, =test=, or =prod= profile—in fact, you can define as many profiles as you want, and compose them together. The rebar3 documentation explains how this works.

Within each profile, the =lib/= directory contains all the OTP applications that your project may use, outside of the standard distribution's libraries. You can see our =mylib= library replicated right there, but its directory structure is a bit different from what's directly at the project root:

- compiled =.erl= files are moved to the =ebin/= directory and now have the =.beam= extension
- there is a =mylib.app= file created, whereas the source application had =mylib.app.src=
- two symlinks have been added to =include/= and =priv/=. These will refer to matching directories at the root of the project, if they exist. The =include/= directory is meant for [[http://erlang.org/doc/reference_manual/macros.html#file-inclusion][header files]] (=.hrl=), and the =priv/= directory for any file that must be copied over and made available in production
- All other files at the root of the project have been discarded

If we had any dependencies (see [[Dependencies][the Dependencies chapter]]), they would also be placed in the =_build/<profile>/lib/= directory.

In general, you will want to ignore the =_build/= directory entirely and avoid tracking it in your source control: if you look at the =.gitignore= file, you will see that it automatically ignores =_build/= for you.

Rebar3 chooses a license for you by default (because you should always choose a license if you plan on doing open soruce work), going for the [[https://en.wikipedia.org/wiki/Apache_License#Version_2.0][Apache 2.0]] license that Erlang ships with. Feel free to replace it as required. Rebar3 also sets up a =README= file that you might want to fix up and update with all the relevant contents. Don't be a jerk, write documentation!

Then we get to two interesting files, =rebar.config= and =rebar.lock=. The lock file is used by rebar3 to track which versions of any dependencies you were using, and should be checked into source control. The [[Dependencies][Dependencies chapter]] contains more details.

The =rebar.config= file is a complete declarative configuration file that exposes options for all the Erlang tools that rebar3 integrates with. [[https://www.rebar3.org/docs/configuration][The official documentation]] explains all the values possible, but by default it is quite empty. In fact, if you only want default values with no dependencies, you can just delete the file. As long as your project is structured like an OTP application, rebar3 will figure out what needs to be done.

Let's see what the standards are for that to happen.

*** What Makes a Lib an App

You've possibly guessed it, but the directory structure is one of the basic requirements of a framework like OTP. As long as your library has an =ebin/= directory once compiled with an =<appname>.app= file in it, the Erlang runtime system will be able to load your modules and run your code.

This basic requirement guides the project structure of the entire Erlang ecosystem. Let's look at what a built =.app= file looks like:

#+NAME: mylib.app
#+BEGIN_SRC erlang
$ cat _build/default/lib/mylib/ebin/mylib.app
{application, mylib, [
  {description, "Checking out OTP libs"},
  {vsn, "0.1.0"},     % version number (string)
  {registered, []},   % name of registered processes, if any
  {applications, [    % List of OTP application names on which
    kernel, stdlib    % yours depends at run-time. kernel and
  ]},                 % stdlib are ALWAYS needed
  {env, []},          % default configuration values ({Key, Val} pairs)
  {modules, [mylib]}, % list of all the modules in the application
  %% content below is optional, and for package publication only
  {licenses, ["Apache 2.0"]},
  {links, []}         % relevant URLs
]}.
#+END_SRC

This is essentially a metadata file that describes everything about the application. We've taken the time to annotate it for you, so check it out. A lot of the content in there is annoying to write by hand so if you look at the source file (=src/mylib.app.src=), you'll see that the fields are mostly pre-populated. You may also notice that =modules= is empty. That's on purpose: rebar3 will populate the list for you.

By far, the most critical field to keep up to date in there is the =applications= tuple. It lets Erlang libraries know the order in which OTP applications must be started to work, and also allows build tools to build a dependency graph between all available OTP applications to know which to keep and which to remove from the distribution when building a release.

A more subtle thing to notice is that even if what we have here is a _library_, and it therefore has no processes to run, we still have the ability to define some configuration values (see the [[Configuration][Configuration Chapter]]), and dependencies must be respected. It is possible, for example, that our library is stateless, but uses a stateful HTTP client: the Erlang VM will then need to know when your code may or may not be safe to call.

For now, let's focus on what exactly is the difference between a stateless and a stateful application.

*** What Makes an App an App

To make a stateful application, we're going to use the "app" template in rebar3, and see what are the differences with a stateless application.

So let's grab your command line tool and run the following:

#+NAME: rebar3_new_myapp
#+BEGIN_SRC sh
$ rebar3 new app myapp
===> Writing myapp/src/myapp_app.erl
===> Writing myapp/src/myapp_sup.erl
===> Writing myapp/src/myapp.app.src
===> Writing myapp/rebar.config
===> Writing myapp/.gitignore
===> Writing myapp/LICENSE
===> Writing myapp/README.md
$ cd myapp
#+END_SRC

If you're careful, you'll see that we now have two new modules instead of =<appname>.erl=: we have =<appname>_app.erl= and =<appname>_sup.erl=. We'll study them real soon, but first, let's focus on the top-level metadata file for the application, the =myapp.app.src= file:

#+NAME: myapp.app.src
#+BEGIN_SRC erlang
$ cat src/myapp.app.src
{application, myapp,
 [{description, "An OTP application"},
  {vsn, "0.1.0"},
  {registered, []},
  {mod, {myapp_app, []}},               % this is new!
  {applications, [kernel, stdlib]},
  {env,[]},
  {modules, []},

  {licenses, ["Apache 2.0"]},
  {links, []}
 ]}.
#+END_SRC

The only new line here is the ={mod, {<appname>_app, []}}= tuple. This tuple specifies a special module that can be called (=<appname>_app=) with some specific arguments (=[]=). When called, it is expected that this module will return the _process identifier_ (the _pid_) of a [[Supervision Trees][supervision tree]].

If you go visit the =myapp_app= module, you will see what these callbacks are:

#+NAME: myapp_app.erl
#+BEGIN_SRC erlang
%%%-------------------------------------------------------------------
%% @doc myapp public API
%% @end
%%%-------------------------------------------------------------------

-module(myapp_app).
-behaviour(application).
%% Application callbacks
-export([start/2, stop/1]).

%%====================================================================
%% API
%%====================================================================

start(_StartType, _StartArgs) ->
    myapp_sup:start_link().

stop(_State) ->
    ok.
#+END_SRC

The =start/2= callback is called when the application is booted by the Erlang runtime system, at which point all of its dependencies—as defined in the =applications= tuple in the .app file—have already been started. This is where you can do one-time bits of initialization. In the template application, the only thing done is starting the root supervisor for the application.

The =stop/1= callback is called _after_ the whole supervision tree has been taken down once someone, somewhere, has decided to shut down the OTP application.

But all in all, this little additional =mod= line in the app file and the presence of a supervision structure are what differentiates a runnable application from a library application.

You now understand most of the weird stuff about Erlang/OTP's project structure and everything that has to do with these mysterious "OTP Applications". Starting with next chapter, we'll start digging a bit in supervision trees, so that you know how to set things up in a stateful runnable application.

ALSO

** Supervision Trees
*** Basics
*** Structuring Supervision Trees
*** Further resources
** Dependencies
** External Dependencies
** Projects with Multiple Applications
** Rebar3 Shell
** Configuration
** Documentation
** Testing
*** Common Test
*** Coverage
*** Dialyzer
*** XRef
*** Continuous Integration
**** CircleCI
***** surefire ct output
***** Microsoft's visual studio output
 https://github.com/ferd/trx


** Things Hard to Get Right

You probably have a fairly decent understanding of how an Erlang project should be structured by now. Along with any guide about the language basics, you should be mostly good to get started. However, there are a few complex topics that are currently not covered well in any of the Erlang documentation out there. In this chapter, we'll go through the task of providing guidance around handling Unicode, time, and SSL/TLS configurations.

Do note that those are three complex topics on their own. While we're going to provide some background information on each of them, you are not going to be an expert at handling them right away—it just helps to know how much complexity exists to avoid huge mistakes.

*** Handling Unicode

Erlang's got quite a bad reputation for string handling. A lot of this comes from not having a dedicated string type, and for years, not having decent unicode support outside of community libraries. While the former has not changed, there are some strengths to that approach, and the latter has finally been addressed in recent Erlang releases.

**** Background Information on Unicode

Unicode, in a nutshell, is a set of standards about how text should be handled in computers, regardless of the user's language (real languages, not programming languages). It has become a huge specification with a lot of exceedingly complex considerations about all kinds of details, and developers are often reasonably getting lost in it.

Even without knowing all about Unicode, you can know _enough_ to be effective and avoiding all of the most glaring mistakes. To get started, we'll introduce a bit of terminology:

- _character_: the word "character" is defined kind of vaguely in Unicode. Everytime you see the word "character", imagine that the person talking to you is using a very abstract term that can mean anything from a letter in a given alphabet, some drawings (like emojis), accents or letter modifiers (like =¸= and =c=, which becomes =ç=), control sequences (like "backspace"), and so on. It's mostly a common but inaccurate way to refer to bits of text, and you must not attach too much meaning to it. Unicode has better and exact definitions of its own.
- _code point_: the Unicode standard defines all the possible basic fundamental "characters" you can have in a big list (and then some), each of which has a unique identifier. That identifier is the _code point_, often denoted =U+<hexadecimal number>=. For example, "M" has the code point =U+004D=, and ♻ has the code point =U+267B=. You can see [[https://unicode-table.com][the Unicode Table]] for the full list.
- _encoding_: While code points are just integers that represent an index by which you can look up, this is not sufficient to represent text in programming languages. Historically, a lot of systems and programming languages used bytes (=0..255=) to represent all valid characters in a language. If you needed more characters, you had to switch languages. To be compatible with all kinds of systems, Unicode defines _encodings_, which allows people to represent sequences of code points under various schemes. _UTF-8_ is the most common one, using bytes for everything. Its representation shares the same basic structure as [[https://en.wikipedia.org/wiki/ASCII][ASCII]] or [[https://en.wikipedia.org/wiki/ISO/IEC_8859-1][Latin-1]] did, and so it became extremely popular in Latin and Germanic languages. _UTF-16_ and _UTF-32_ are two alternatives that represent on wider sequences (16 or 32 bits).
- _code unit_: A code unit specifies the way a given code point is encoded in a given encoding. Each code point takes from 1 to 4 code units for UTF-8. For example, =F= takes only =46= as a code unit in UTF-8, =0046= in UTF-16, and =00000046= in UTF-32. By comparison, =©= has the code point =U+00A9=, but is representable as _two_ code units in UTF-8 (=C2= and =A9=), and one code unit in UTF-16 and UTF-32 (=00A9= and =000000A9= respectively).
- _glyph_: the graphic representation of a character. For example, =U+2126= is "Ohm sign", represented as =Ω=, and =U+03A9= is "Greek Capital Letter Omega", also represented by a similar-looking =Ω=. In some [[https://en.wikipedia.org/wiki/Typeface][Typefaces]] they will be the same, in some not. Similarly, the letter "a" is possibly representable by glyphs looking like "а" or "α".  Some code points have no associated glyphs ("backspace", for example), and some glyphs can be used for _ligatures_ representing multiple codepoints at once (such as =æ= for =ae=).
- _grapheme cluster_: all of the terms mentioned so far have to do with very abstract concepts. Unicode has funky stuff like _combining marks_ and ways to join multiple code points into one "character". This can become super confusing because what a user considers a character and what a programmer considers a character are not the same thing. A _grapheme cluster_ is a term meaning "a unit of text the user perceives as being a single character". For example, the letter "ï" is composed of two code-points: the latin small letter =i= (=U+0069=), and a =combining= [[https://en.wikipedia.org/wiki/Diaeresis_(diacritic)][diaeresis]] (=¨= as =U+0308=). So for a programmer, this will look like two  code points, encoded with 3 code units in UTF-8. For a user though, they will expect that pressing "backspace" will remove both the diaeresis _and_ the letter "i".

That's a lot of stuff, but those are important to know about. There is no direct relationship between how a programmer writes a character and how it ends up displayed to a user.

One particularly fun example is the _ARABIC LIGATURE BISMILLAH AR-RAHMAN AR-RAHEEM_, which is a single code point (=U+FDFD=), but represented graphically as "﷽". This is currently the widest "character" in the Unicode standard. This represents an entire arabic sentence, and was added to the standard because it turns out to be a legal requirement in multiple Urdu documents, without their keyboard layouts having the ability to type arabic. It's a great bit of unicode to mess with UI folks.

Most languages have problems with the fact that graphical (and logical) representations are not equal to the underlying codes creating the final character. Those exist for all kinds of possible ligatures and assemblies of "character parts" in various languages, but for Emojis, you can also make a family by combining individual people: 👩‍👩‍👦‍👦 is a family composed of 4 components with combining marks: 👩 + 👩 + 👦 + 👦, where =+= is a special combining mark (a [[https://www.fileformat.info/info/unicode/char/200d/index.htm][zero width joiner]]) between two women and two boys (if you are viewing this document on an older browser, with an older font, or are checking out the PDF version of this book, then you might just see four people instead of a family.) If you were to go and consume that sequence byte by byte or codepoint by codepoint, you would break the family apart and change the semantic meaning of the text.

If you edit the text in a text editor that traditionally has good support for locales and all kinds of per-language rules, such as Microsoft Word (one of the few we know to do a great job of automatically handling half-width spaces and non-breakable spaces when languages ask for it), pressing backspace on 👩‍👩‍👦‍👦 will remove the whole family as one unit. If you do it in FireFox or Chrome, deleting that one 'character' will take you 7 backstrokes: one for each 'person' and one for each zero-width joining character. Slack will consider them to be a single character and visual studio code behaves like the browsers (even if both are electron apps), and notepad.exe or many terminal emulators will instead expand them as 4 people and implicitly drop the zero-width joining marks.

This means that no matter which programming language you are using, if strings look like arrays where you can grab "characters" by position or through some index, you are likely to have serious problems.

Worse than this, some "characters" have more than one acceptable encoding in Unicode. The character =é= can be created by encoding a single code point (=U+00E9=), or as the letter =e= (=U+0065=) followed by =´= (=U+0301=). This will logically be the same letter =é= in French, but two strings using the two different forms will not compare equal. Unicode therefore introduces concepts such as [[http://unicode.org/reports/tr15/][Normalization]], which allows to standardize the representation of strings according to four possible standards: NFC, NFD, NFKC, and NFKD (if you don't know which one to use, stick to NFC).

Sorting strings also introduces concepts such as [[http://unicode.org/reports/tr10/][Collations]], which require knowing the current language being used when sorting.

In short, to support Unicode well in your programs, no matter in which programming language you work, you must treat strings as a kind of opaque data type that you manipulate exclusively through Unicode-aware libraries. Anything else and you are manipulating _byte sequences_ or _code point sequences_ and may end up breaking things unexpectedly at the human-readable level.


**** Handling Strings in Erlang

Erlang's support for strings initially looks a bit funky: there is no dedicated string type. When considering all the complexity of Unicode though, it's not actually all that bad. It's usually as tricky to work with just _one_ string type as it would be to work with _no_ string types at all, because of all the possible alternative representations.

Folks using programming languages with variable string types that reflect multiple encodings may feel good about themselves right now, but you'll see that Erlang has pretty decent Unicode support all things considered—only collations appear to be missing.

***** Data Types

In Erlang, you have to be aware of the following possible encodings for strings:

- ="abcdef"=: a string, which is directly made up of Unicode code points in a list. This means that if you write =[16#1f914]= in your Erlang shell, you'll quite literally get ="🤔"= as a string, with no regards to encoding. This is a singly linked-list.
- =<<"abcdef">>= as a binary string, which is shorthand for =<<$a, $b, $c, $d, $e, $f>>=. This is an old standard list of Latin1 integers transformed as a binary. By default this literal format does _not_ support Unicode encodings, and if you put a value that is too large in there (such as =16#1f914=) by declaring a binary like =<<"🤔">>= in your source file, you will instead find yourself with an overflow, and the final binary =<<20>>=. This is implemented with an Erlang binary (what is essentially an immutable byte array), and is meant to handle any kind of binary data content, even if it's not text.
- =<<"abcdef"/utf8>>= as a binary Unicode string that is encoded as UTF-8. This one would work to support emojis. It is still implemented as an Erlang binary, but the =/utf8= constructor ensures proper Unicode encoding. =<<"🤔"/utf8>>= returns =<<240,159,164,148>>=, which is the proper sequence to represent the thinking emoji in UTF-8.
- =<<"abcdef"/utf16>>= as a binary string that is Unicode encoded as UTF-16. =<<"🤔"/utf16>>= returns =<<216,62,221,20>>=
- =<<"abcdef"/utf32>>= as a binary string that is Unicode encoded as UTF-32. =<<"🤔"/utf32>>= returns =<<0,1,249,20>>=
- =["abcdef", <<"abcdef"/utf8>>]=: This is a special list dubbed "IoData" that can support multiple string formats. Your list can be codepoints as usual, but you'll want all the binaries to all be the same encoding (ideally UTF-8) to prevent issues where encodings get mixed.

If you want to work with Unicode content, you will want to use the various string-related modules in Erlang.

The first one is [[http://erlang.org/doc/man/string.html][string]], which contains functions such as =equal/2-4= to handle string comparison while dealing with case sensitivity and normalization, =find/2-3= to look for substrings, =length/1= to get the number of grapheme clusters, =lexemes/2= to split a string on some pattern, =next_codepoint/1= and =next_grapheme/1= to consume bits of a string, =replace/3-4= for substitutions, =to_graphemes/1= to turn a string into lists of graphemes, and finally functions like =lowercase/1=, =uppercase/1=, and =titlecase/1= to play with casing. The module contains more content still, but that should be representative.

You will also want to use the [[http://erlang.org/doc/man/unicode.html][unicode]] module to handle all kinds of conversions across string formats, encodings, and normalization forms. The regular expression module [[http://erlang.org/doc/man/re.html][re]] handles unicode fine (just pass in the =unicode= atom to its options lists), and lets you use [[http://erlang.org/doc/man/re.html#generic_character_types][Generic Character Types]] if you pass in the =ucp= option. Finally, the =file= and =io= modules all support specific options to make unicode work fine.

All of these modules work on any form of string: binaries, lists of integers, or mixed representations. As long as you stick with these modules for string handling, you'll be in a good position.

The one tricky thing you have to remember is that the encoding of a string is implicit. You have to know what it is when a string enters your system: an HTTP request often specifies it in headers, and so does XML. JSON and YAML mandate using UTF-8, for example. When dealing with SQL databases, each table may specify its own encoding, but so does the connection to the database itself! If any one of them disagrees, you're going to corrupt data.

So you will want to know and identify your encoding very early on, and track it well. It's not just a question of which data type in your language exists, it's a question of how you design your entire system and handle exchanging data over the network.

There's one more thing we can cover about strings: how to transform them effectively.

***** IoData

So which string type should you use? There are plenty of options, but picking one is not too simple.

The quick guidelines are:

- Binaries for UTF-8, which should represent the majority of your usage
- Binaries for UTF-16 and UTF-32, should you use them
- Lists as strings are rarely used in practice, but can be very effective if you want to work at the codepoint level
- Use IoData for everything else, particularly building strings.

One advantage of the binary data types is their ability to create subslices efficiently. So for example, I could have a binary blob with content such as =<<"hello there, Erlang!">>= and if I pattern match a subslice such as =<<Txt:11/binary, _/binary>>=, then =Txt= now refers to =<<"hello there">>= at the same memory location as the original one, but with no way to obtain the parent context programmatically. It's a bounded reference to a subset of the original content. The same would not be true with lists, since they're defined recursively.

On top of that, binaries larger than 64 bytes can be shared across process heaps, so you can cheaply move string content around the virtual machine without paying the same copying cost as you would with other data structure.

#+attr_shortcode: info
#+begin_alert
Binary sharing is often a great way to gain performance in a program. However, there exist some pathological usage patterns where binary sharing can lead to memory leaks. If you want to know more, take a look at [[https://www.erlang-in-anger.com/][Erlang In Anger]]'s chapter on memory leaks, particularly section 7.2
#+end_alert

The real cool thing though comes from the IoData representation where you combine the list approach with binaries. It's how you get really cheap composition of immutable strings:

#+NAME: greetings
#+BEGIN_SRC erlang
Greetings = <<"Good Morning">>,
Name = "James",
[Greetings, ", ", Name, $!]
#+END_SRC

The final data structure here looks like =[<<"Good Morning">>, ", ", "James", 33]= which is a mixed list containing binary subsections, literal codepoints, strings, or other IoData structures. But the VM mechanisms all support handling it as if it were a flat binary string: The IO systems (both network and disk access), and the modules named in the previous section all seamlessly handle this string as =Good Morning, James!= with full Unicode support.


So while you can't mutate strings, you can append and match a bunch of them in constant time, no matter the type they initially had. This has interesting implications if you're writing libraries that do string handling. For example, if I want to replace all instances of =&= by =&amp;=, and I started with =<<"https://example.org/?abc=def&ghi=jkl"/ut8>>=, I might instead just return the following linked list:

#+NAME: url_sublists
#+BEGIN_SRC erlang
% a list
[%% a slice of the original unmutated URL
 <<"https://example.org/?abc=def">>,
 %% a literal list with the replacement content
 "&amp;amp",
 %% the remaining sub-slice
 <<"ghi=jkl">>
]
#+END_SRC

What you have then is a string that is in fact a linked list of 3 elements: a slice of the original string, the replaced subset, the rest of the original string. If you're replacing on a document that's taking 150MB in RAM and you have somewhat sparse replacements, you can build the entire thing and edit it with essentially no overhead. That's pretty great.

So why else are IoData strings kind of cool? Well the unicode representation is one fun thing. As mentioned earlier, grapheme clusters are a crucial aspect of Unicode strings when you want to operate on them as a human would (rather than as binary sequences that only programmers would care about). Whereas most programming languages that use a flat array of bytes to represent strings have no great way to iterate over strings, Erlang's =string= module lets you call =string:to_graphemes(String)= to play with them:


#+NAME: graphemes
#+BEGIN_SRC erlang
erl +pc latin1 # disable unicode interpretation
1> [Grapheme | Rest] = string:next_grapheme(<<"ß↑õ"/utf8>>),
[223 | <<226,134,145,111,204,131>>]
2> string:to_graphemes("ß↑õ"),
[223,8593,[111,771]]
3> string:to_graphemes(<<"ß↑õ"/utf8>>),
[223,8593,[111,771]]
#+END_SRC

This lets you take any unicode string, and turn it into a list that is safe to iterate using calls such as =lists:map/2=, lists comprehensions, or pattern matching. This can only be done through IoData, and this might even be a better format than what you'd get with just default UTF-8 binary strings.

Do note that pattern matching is still risky there. Ideally you'd want to do a round of normalization first, so that characters that can be encoded in more than one way are forced into a uniform representation.

This should hopefully demistify Erlang's strings.

*** Handling Time
**** Background Information on Time
**** Handling Time in Erlang
*** SSL Configurations
**** Background Information on TLS
**** Handling TLS in Erlang

* Production
:PROPERTIES:
:EXPORT_FILE_NAME: production
:END:

Erlang/OTP is certainly a unique language and runtime, but it is not as different as even some proponents would have you believe. In this part we will see how to build artifacts for deployment and how to operate the deployment in the same environment you would run any other service. In this part we'll build a deployable artifact (a release), create a docker image of the release and deploy to a Kubernetes cluster.

A common claim heard on forums and comment sections of popular tech news sites is, you have OTP, you don't need Kubernetes. Or the opposite, that having Kubernetes replaces OTP. Erlang does not replace Kubernetes, nor does Kubernetes replace Erlang. If an Erlang system didn't need to be monitored and restarted like any other runtime because it has supervision trees then it wouldn't come with [[http://erlang.org/doc/man/heart.html][heart]]. Similarly, if restarting the entire program with =heart= was adequate there wouldn't be supervision trees.

[[https://kubernetes.io/][Kubernetes]] provides a scheduler for efficiently packing your programs, as containers, on physical or virtual machines. Using containers eases deployment by bundling all dependencies (think OpenSSL in an Erlang release's case) into a single image and isolation that protects against dependency conflicts between services running on a machine. Additionally, deployment and management becomes consistent across the services in your production environment no matter the language or runtime they are built with. When you integrate your Erlang service with common monitoring and tracing services, you will also ensure it's no longer the oddball your coworkers dread having to deal with.

However, containers and Kubernetes are not appropriate in all cases. Kubernetes can be overkill, particularly if using a hosted solution isn't an option, or your product could be an embedded device.


** Releases
In OTP at a High Level we took a bird's-eye view of how applications are combined into a release and in Development we built and tested OTP applications. Now we'll configure and build a release of the =service_discovery= project.

*** The Nitty Gritty

An Erlang system starts by running instructions found in a boot script. The instructions load modules and start applications. Erlang provides functions for generating a boot script from a list of all required applications, defined in a release resource file with extension ".rel", and their corresponding application resource file, the ".app" file each application has. The application resource file defines the modules the boot script must load and the dependencies of each application so that the boot script will start applications in the correct order. When only the applications used in a release are bundled together with the boot script, to be copied and installed on a target, it is called a *target system*.

In the earlier days of Erlang/OTP, there was only =systools= and its functions for generating boot scripts from release resource files. Back then, release handling was a manual process around which users built their own tooling. Then came =reltool=, a release management tool that ships with Erlang/OTP and was meant to ease the creation of releases—it even has a GUI. While creating and installing target systems has never been provided outside of an example module found in the =sasl= application, =sasl/examples/src/target_system.erl=.

Releases continued to be mysterious and difficult to build to many users. relx was created with the goal of making release creation and management so simple that users no longer felt it was a burden best not undertaken -- this is done in part through requiring minimal configuration to get started and by including tools for runtime management in the generated release. When rebar3 was started, it bundled relx to provide its release building functionality.

*** Building a Development Release

The first thing we need is a =relx= section in =rebar.config=:

#+NAME: rebar.config
#+BEGIN_SRC erlang
{relx, [{release, {service_discovery, "0.1.0"},
         [service_discovery]},

        {sys_config_src, "./config/sys.config.src"},
        {vm_args_src, "./config/vm.args.src"},

        {dev_mode, true},
        {include_erts, false},

        {extended_start_script, true}]}.
#+END_SRC

The first tuple in the =relx= configuration list defines a release's name, version and the applications
included in the release.

=rebar3 release= runs relx with configuration based on the =relx= section of =rebar.config= and the rebar3 project structure so relx can find the necessary applications for building the release.

#+BEGIN_SRC shell
$ rebar3 release
===> Verifying dependencies...
===> Compiling service_discovery
===> Starting relx build process ...
===> Resolving OTP Applications from directories:
          /src/service_discovery/_build/default/lib
          /src/service_discovery/apps
          /root/.cache/erls/otps/OTP-21.3.4/dist/lib/erlang/lib
          /src/service_discovery/_build/default/rel
===> Resolved service_discovery-0.1.0
===> Dev mode enabled, release will be symlinked
===> release successfully created!
#+END_SRC

The first relx step seen in the output is "Resolving OTP Applications" followed by a list of directories it will check, this means to find the name, version and path to all applications that make up the release being built. In the =relx= config only =service_discovery= is listed as applications to include in the release. relx takes those two applications and based on their =.app= files finds the applications they depend on, does the same for those found and so on until all dependencies have been discovered.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
Note that the application =sasl= is not included in the =relx= config's list of applications. By default in the rebar3 template it is in the list. This is because =sasl= is required for certain release operations. The application includes =release_handler= which provides functionality for performing release upgrades and downgrades. Since we are focused here on creating containers which are replaced instead of live upgraded =sasl= does not need to be included.
#+end_notice

Since this is built with ={dev_mode, true}= symlinks are created in the release's lib directory that point to each application:

#+BEGIN_SRC shell
$ ls -l _build/default/rel/service_discovery/lib
lrwxrwxrwx ... service_discovery-0.1.0 -> .../_build/default/lib/service_discovery
#+END_SRC

The same is also done for the runtime configuration files =sys.config.src= and =vm.args.src=:

#+BEGIN_SRC shell
$ ls -l _build/default/rel/service_discovery/releases/0.1.0
lrwxrwxrwx [...] sys.config.src -> [...]/config/sys.config.src
lrwxrwxrwx [...] vm.args.src -> [...]/config/vm.args.src
#+END_SRC

This allows for a faster feedback loop when running our release for local testing. Simply stopping and starting the release again will pick up any changes to beam files or configuration.

#+attr_shortcode: info
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_alert
On Windows the =dev_mode= of relx won't necessary work but it will fallback to copying.
#+end_alert

#+BEGIN_SRC shell
_build/default/rel/service_discovery/
├── bin/
│   ├── install_upgrade.escript
│   ├── nodetool
│   ├── no_dot_erlang.boot
│   ├── service_discovery
│   ├── service_discovery-0.1.0
│   └── start_clean.boot
├── lib/
│   ├── base32-0.1 -> /src/_build/default/lib/base32
│   ├── bear-0.8.7 -> /src/_build/default/lib/bear
│   ├── dns-0.1.0 -> /src/_build/default/lib/dns
│   ├── erldns-1.0.0 -> /src/_build/default/lib/erldns
│   ├── folsom-0.8.7 -> /src/_build/default/lib/folsom
│   ├── iso8601-1.3.1 -> /src/_build/default/lib/iso8601
│   ├── jsx-2.9.0 -> /src/_build/default/lib/jsx
│   └── service_discovery-0.1.0 -> /src/_build/default/lib/service_discovery
└── releases/
    ├── 0.1.0
    │   ├── no_dot_erlang.boot
    │   ├── service_discovery.boot
    │   ├── service_discovery.rel
    │   ├── service_discovery.script
    │   ├── start_clean.boot
    │   ├── sys.config.src -> /src/config/sys.config.src
    │   └── vm.args.src -> /src/config/vm.args.src
    ├── RELEASES
    └── start_erl.data
#+END_SRC

*** Building a Production Release

Preparing a release to be deployed to production benefits from having different options than what is best during local development. Rebar3 profiles allow us to override and add to the relx configuration:

#+NAME: rebar.config
#+BEGIN_SRC erlang
{profiles, [{prod, [{relx, [{dev_mode, false},
                            {include_erts, true},
                            {include_src, false},
                            %%{include_hrl, false}, undecided?
                            {debug_info, strip}]}]
            }]}.
#+END_SRC

We have two overridden configuration values here. =dev_mode= is set to =false= so all content is copied into the release directory, we can't utilize symlinks to the =_build= directory from another machine and a production release should be an immutable snapshot of the project. =include_erts= copies the Erlang runtime and the Erlang/OTP applications depended on by the release into the release directory and configures the boot script to point to this copy of the runtime.

The entries added to the configuration are setting =include_src= to =false= and and =debug_info= to =strip=. Since running the release in production doesn't require the source code we can drop it from the final release to save on space. Additional space is saved by stripping debug information from the beam files. Tools used during development like the debugger, =xref= and =cover= require debug information but in a release those won't be used and, unless explicitly included, won't be available.

Building with the production profile enabled results in artifacts being written to the profile directory =_build/prod/= and can be enabled with =as prod=:

#+BEGIN_SRC shell
$ rebar3 as prod release
===> Verifying dependencies...
===> Compiling service_discovery
===> Starting relx build process ...
===> Resolving OTP Applications from directories:
          /src/service_discovery/_build/prod/lib
          /src/service_discovery/apps
          /root/.cache/erls/otps/OTP-21.3.4/dist/lib/erlang/lib
          /src/service_discovery/_build/prod/rel
===> Resolved service_discovery-0.1.0
===> Including Erts from /root/.cache/erls/otps/OTP-21.3.4/dist/lib/erlang
===> release successfully created!
#+END_SRC

Viewing the tree of the new =prod= profile's release directory we see:

#+NAME: prod_rel_structure
#+BEGIN_SRC sh
_build/prod/rel/service_discovery/
├─ bin/
│   ├─ install_upgrade.escript
│   ├─ nodetool
│   ├─ no_dot_erlang.boot
│   ├─ service_discovery
│   ├─ service_discovery-0.1.0
│   └─ start_clean.boot
├─ erts-10.3.3/
│   ├─ bin
│   ├─ doc
│   ├─ include
│   ├─ lib
│   ├─ man
│   └─ src
├─ lib/
│   ├─ asn1-5.0.8
│   ├─ base32-0.1
│   ├─ bear-0.8.7
│   ├─ crypto-4.4.2
│   ├─ dns-0.1.0
│   ├─ erldns-1.0.0
│   ├─ folsom-0.8.7
│   ├─ inets-7.0.6
│   ├─ iso8601-1.3.1
│   ├─ jsx-2.9.0
│   ├─ kernel-6.3.1
│   ├─ mnesia-4.15.6
│   ├─ public_key-1.6.5
│   ├─ service_discovery-0.1.0
│   ├─ ssl-9.2.1
│   └─ stdlib-3.8.1
└─ releases/
    ├─ 0.1.0/
    │   ├─ no_dot_erlang.boot
    │   ├─ service_discovery.boot
    │   ├─ service_discovery.rel
    │   ├─ service_discovery.script
    │   ├─ start_clean.boot
    │   ├─ sys.config.src
    │   └─ vm.args.src
    ├─ RELEASES
    └─ start_erl.data
#+END_SRC

There are no symlinks under =lib= and OTP applications like =stdlib-3.8.1= are included. And at the top of the tree is =erts-10.3.3= which contains the Erlang runtime.

To build the target system of the release we run the =tar= command in the =prod= profile:

#+BEGIN_SRC shell
$ rebar3 as prod tar
#+END_SRC

Now we have a tarball =_build/prod/rel/service_discovery/service_discovery-0.1.0.tar.gz= that can be copied to a target and run.

** Docker

[[https://docker.com][Docker]] helped popularize Linux containers through its ease of use and registry of pre-built images, and became a word often used interchangably with "Linux container".

Docker images contain multiple layers that are merged at runtime to make up the filesystem of the container. Docker creates the layers by running commands found in a =Dockerfile=, each command creates a new layer. Layers are shared between images, saving space, and can be used as a cache for speeding up the building of images. Additional space is saved, compared to other options like a virtual machine (VM), by not including the Linux kernel in the image. The size of the image is little larger than the size of the packaged Erlang release we are deploying.

The small size and ability to run like a regular Linux process makes for quicker start times (a new kernel isn't booted) and less resource consumption than using a traditional VM for isolation. Having little overhead means that the advantages of isolation when packaging and running a program can be standard practice instead of the burden it would be to have to run a VM per program.

Advantages of containers running with filesystem and network isolation are not having to perform operations that are common when programs are not isolated:

- Pre-installing shared libraries
- Updating configuration
- Finding an open port
- Finding a unique name for node name

#+attr_shortcode: note
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
You might notice we will not be using the =latest= tag at all when using Docker. This tag is commonly misunderstood and misused. It is assigned to the last image used without a specific tag, it is not the latest created image. It should not be used, unless you really don't care what version of an image will be used.
#+end_notice

*** Building Images

[[https://hub.docker.com/_/erlang/][Offical Erlang Docker images]] are published for each new OTP release. They include rebar3 and come in [[https://alpinelinux.org/][Alpine]] and [[https://www.debian.org/][Debian]] flavors -- the images are updated for new releases of rebar3 and Alpine/Debian as well.

#+attr_shortcode: tip
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
If you have private git repos as dependencies they will not be able to be fetched in the Docker container during the build. Often this leads people to not include =_build= in =.dockerignore= and risk polluting the build with local artifacts, possibly not being reproducable elsewhere, so the dependencies could be fetched with rebar3 before running =docker build=. The other option is copying the host SSH credentials into the build container, but this is not recommended because it will be kept in the Docker layer and leaked anywhere you push the image.

To resolve this, Docker added a new feature, as of Docker 18.09, allowing for secure mounting of SSH credentials. A =RUN= command that needs SSH access can use =--mount=type=ssh=:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental

RUN apk add --no-cache openssh-client git && \
    mkdir -p -m 0600 ~/.ssh && \
    ssh-keyscan github.com >> ~/.ssh/known_hosts && \
    git config --global url."git@github.com:".insteadOf "https://github.com/"

COPY rebar.config rebar.lock /src/app/
RUN --mount=type=ssh rebar3 compile
#+END_SRC

The git config setting set in the first =RUN= ensures that even if in the =rebar.config= the git url is using =https= it will instead use SSH. If the private repos are not on Github this url replacement has to be changed for the appropriate location.

Along with adding the previous snippet to the Dockerfiles we'll see later in this chapter you'll also need to add =--ssh default= to the build command when run and set =DOCKER_BUILDKIT=:

#+BEGIN_SRC shell
$ export DOCKER_BUILDKIT=1
$ docker build --ssh default .
#+END_SRC

Additional information and options for the SSH mount type can be found [[https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/experimental.md#run---mounttypessh][in the Moby documentation]] -- Moby is the name of the project that makes up the core functionality of Docker.

#+end_notice

**** Efficient Caching

The order of commands in a Dockerfile is very important to the build time and space required of the images it creates. Docker uses the layers each command in the Dockerfile creates to skip a command if nothing has changed. With rebar3 we take advantage of this by creating a layer containing the built dependencies of our project:

#+BEGIN_SRC dockerfile
COPY rebar.config rebar.lock /src/
RUN rebar3 compile
#+END_SRC

The =COPY= command will only invalidate the cache of the command that runs =rebar3 compile= (and subsequent commands in the file) if =rebar.config= or =rebar.lock= are different from a previously created layer. Since none of the project's code was copied and rebar3 only builds the dependencies, this results in a layer containing only the built dependencies under =_build/default/lib=.

After the dependencies are built and cached we can copy in the rest of the project and compile it:

#+BEGIN_SRC dockerfile
COPY . /src/
RUN rebar3 compile
#+END_SRC

Because of the order of operations in the Dockerfile each run of =docker build .= only compiles the project's source, assuming there is a change, otherwise an existing layer is used here as well. Any command that doesn't need to be rerun if there are changes to the project need to come before either of the =COPY= commands. For example, installing Alpine packages needed by later steps =RUN apk add --no-cache git=.

Now this is all well and good but the layer with the built dependencies that will not be used if =rebar.config= or =rebar.lock= is changed also contains the Hex package cache rebar3 creates under =~/.cache/rebar3/hex=. Any change to those two files will result in all the packages having to be downloaded again.

This issue is resolved as of Docker 18.09 -- when environment variable =DOCKER_BUILDKIT= is set, enabling the use of Buildkit as the Docker backend -- through a new mount type, =cache=, that can be passed directly to the =RUN= command:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental

COPY rebar.config rebar.lock /src/
RUN --mount=type=cache,target=/root/.cache/rebar3 rebar3 compile
#+END_SRC

Now when =compile= is run there is a cache of =/root/.cache/rebar3= created separately from the image layer. So future runs of =docker build=, even if the config or lock file has changed, will mount this cache and only new packages will be fetched from Hex.

**** Multi-Stage Build

For developing and running an Erlang project we are going to need an image with the built release along with ERTS. With Docker's multi-stage feature we are able define how to build individual images for containing the compiled dependencies, the final release and the Dialyzer Persistent Lookup Table (PLT) all in a single =Dockerfile=.

We will step through each stage individually based on the =service_discovery= project's [[https://github.com/adoptingerlang/service_discovery/blob/master/Dockerfile][Dockerfile]]. The first stage is named =builder=:

#+BEGIN_SRC dockerfile
# syntax = docker/dockerfile:experimental
FROM erlang:21-alpine as builder

# git for fetching non-hex depenencies
# add any other Alpine libraries needed to compile the project here
RUN apk add --no-cache git

WORKDIR /src

# build and cache dependencies as their own layer
COPY rebar.config rebar.lock /src/
RUN --mount=type=cache,target=/root/.cache/rebar3 rebar3 compile
#+END_SRC

The =builder= stage starts with the base image =erlang:21-alpine=. =as builder= names the stage so we can use it as a target to =docker build=:

#+BEGIN_SRC shell
$ CHKSUM=$(cat rebar.config rebar.lock | cksum | awk '{print $1}')
$ docker build --target builder -t ${PROJECT}_builder:${CHKSUM} .
#+END_SRC

Running =docker build= with =--target build= and =-t service_discovery_builder:$CHKSUM= builds the stage and tags with the given name. This stage only fetches and compiles the dependencies of the project, mounting the rebar3 hex cache as discussed in the previous section.

The image with the compiled dependencies is now able to be used as a base for images that run rebar3 commands which would otherwise fetch and compile dependencies.

The next stage uses the =builder= image as its base:

#+BEGIN_SRC dockerfile
FROM builder as releaser

# tar for unpacking the target system
RUN apk add --no-cache tar

# copy in the source and build the release tarball
COPY . /src
RUN rebar3 as prod tar

# unpack tarball to be copied into the image built next
RUN mkdir -p /opt/rel
RUN tar -zxvf /src/_build/prod/rel/*/*.tar.gz -C /opt/rel
#+END_SRC

This stage copies in all of the project and builds a tarball of the release using the =prod= profile:

#+NAME: rebar.config
#+BEGIN_SRC erlang
{profiles, [{prod, [{relx, [{dev_mode, false},
                            {include_erts, true},
                            {include_src, false},
                            %%{include_hrl, false}, undecided?
                            {debug_info, strip}]}]
            }]}.
#+END_SRC

The profile having =include_erts= set to =true= means the tarball contains the Erlang runtime and can be copied to a target without Erlang and be run. At the end the tarball is unpacked to =/opt/rel= so the image that will copy the release out of the =releaser= does not need to have =tar= installed.

#+attr_shortcode: note
#+attr_latex: :environment bclogo :options [logo=\bcinfo, couleurBarre=orange, noborder=true, couleur=white]{Information}
#+begin_notice
Why tar the release at all?
#+end_notice

Now to build and tag the =release= target:

#+BEGIN_SRC shell
$ docker build --cache_from=${PROJECT}_builder:${CHKSUM} --target releaser -t ${PROJECT}_releaser:${CHKSUM} .
#+END_SRC

The second image using =builder= as a base is a cache of the project's PLT:

#+BEGIN_SRC dockerfile
FROM builder as plt

RUN --mount=type=cache,target=/root/.cache/rebar3 rebar3 dialyzer \
    --plt-location /root/.cache/rebar3 --plt-prefix deps --base-plt-prefix otp

ENTRYPOINT ["rebar3"]

CMD ["dialyzer", "--plt-location", "$/root/.cache/rebar3", "--plt-prefix",
    "deps", "--base-plt-prefix", "otp"]
#+END_SRC

Like with the =compile= command the rebar3 cache is mounted and is where all PLT output is stored. Usually rebar3 will store only the PLT of the OTP libraries in the global cache directory and use the profile directory under =_build/= for the PLT which also contains the dependencies. So the argument =--plt-location= is used to set where the PLT will be stored. This is done because when running the container the project must be mounted as a volume to the same directory. Mounting a volume overrides any existing files on the path it is mounted to. Storing the PLT in a separate location ensure it is not lost when the volume is mounted and isn't rebuilt on each run.

#+BEGIN_SRC shell
$ docker build --cache_from=${PROJECT}_builder:$CHKSUM --target plt -t ${PROJECT}:$CHKSUM .
#+END_SRC

#+BEGIN_SRC dockerfile
$ docker run -v $(pwd):/src <image>
#+END_SRC

The deployable image uses just a base OS image. In this case =alpine:3.9= is used as the base image. Any shared libraries needed to run the release are installed first and then the unpacked release from the build stage we named =releaser= is copied to =/opt/service_discovery=:

#+attr_latex: :options label=Dockerfile
#+BEGIN_SRC dockerfile
FROM alpine:3.9 as runner

# install openssl, needed by the crypto app
RUN apk add --no-cache openssl ncurses

WORKDIR /opt/service_discovery

COPY --from=releaser /opt/rel /opt/service_discovery

ENV COOKIE service_discovery
# write files generated during startup to /tmp
ENV RELX_OUT_FILE_PATH /tmp
ENV HOME /opt/service_discovery/bin

ENTRYPOINT ["/opt/service_discovery/bin/service_discovery"]

CMD ["foreground"]
#+END_SRC

=/opt/service_discovery= is owned by root and it is recommended to not run the container as root. When the release is run =sys.config= and =vm.args= need to be generated from their respective =.src= files. By default these are placed in the same directory as the original =.src= files. If =RELX_OUT_FILE_PATH= is set, its location will be used instead. Here, the =ENV= command is used to ensure the environment variable =RELX_OUT_FILE_PATH= is set to =/tmp= when the container is run.

#+BEGIN_SRC shell
$ docker build --cache_from=${PROJECT}_releaser:${CHKSUM} --cache_from=${PROJECT}_builder:${CHKSUM} --target runner -t ${PROJECT}:${CHKSUM} .
#+END_SRC

*** Running a Container

Now that we have the image =docker run= can be used to run the release. The =CMD= passed to the entrypoint can be overridden with the =console= command to get an interactive shell:

#+BEGIN_SRC shell
$ docker run -ti --user 1000 adoptingerlang.org/service_discovery console
[...]
(service_discovery@960409ea0bc0)1>
#+END_SRC

A running node can also be attached to with =docker exec= and =remote_console=:

#+BEGIN_SRC shell
$ docker exec -ti --user 1000 960409ea0bc0 bin/service_discovery remote_console
[...]
(service_discovery@960409ea0bc0)1>
#+END_SRC

** Kubernetes
*** Deployment
*** Service
*** StatefulSet
*** Resources
**** CPUs
***** Active Schedulers
***** +sbwt none
*** Testing Locally
**** Minikube, Microk8s, Docker for Machine
**** Tilt
** Operations
*** Remote access
*** Metrics
**** VM
**** Libraries
**** Custom
*** Logging
*** Distributed tracing
* Team Building
:PROPERTIES:
:EXPORT_FILE_NAME: team_building
:END:
** Who to Put on The Team
*** Building Around an Expert
*** Building Without an Expert
*** To Remote or Not To Remote
** Repository Structures
** Processes
*** Code Reviews
*** Common Architecture Decisions
*** Prototype and Throw Away
*** Internal Training
** How To Hire
*** It Takes One to Know One
*** It is Easier to Train than Hire

* Appendix
:PROPERTIES:
:EXPORT_FILE_NAME: appendix
:END:
** Erlang/OTP Cheat Sheets

This section contains various reminders to jog your memory if you're not too fresh on basic Erlang data, types, or syntax.

*** Data Types

TODO: format this in a table or more compact manner

| Name  | Description  | Dialyzer | Example Syntax |
|-------+--------------+----------+----------------|
| integer | number without decimals | =integer()=, =pos_integer()=, =non_neg_integer()= | =1=, =2=, =3=, =-213=, =16#01FF=, =2#101011= |
| float   | number with decimals | =float()= | =1.0=, =-1.0=, =123.12=, =1.0e232= |
| number | either floats or integers | =number()= | =1.0=, =1= |
| atom | literals, constants with their own name for value | =atom()= | =abc=, ='abc'=, =some_atom@erlang=, ='atom with spaces'= |
| boolean | atoms =true= or =false= | =boolean()= | =true=, =false= |
| reference | unique opaque value | =reference()= | =make_ref()= |
| fun | anonymous function | =fun()=, =fun((ArgType) -> RetType)= | <code>fun(X) -> X end, fun F(0) -> []; F(N) -> [1 \vert F(N-1)] end</code> |
| port | opaque type for a file descriptor | =port()= | N/A |
| pid  | process identifier | =pid()= | =<0.213.0>= |
| tuple | group a known set of elements | =tuple()=, ={A, B, C}= | ={celcius, 42=}, ={a, b, c}=, ={ok, {X, Y}}= |
| map  | a dictionary of terms | =map()=, ~#{KType => VType}~, ~#{specific_key := VType}~ | ~#{a => b, c => d}~, ~Existing#{key := Updated}~ |
| nil  | an empty list | =[]= | =[]= |
| list | recursive structure for a list of terms | =list()=, =[Type]= | =[a, b, c]=, <code>[a \vert [b \vert [c \vert []]]]</code>, ="a string is a list"= |
| binary | a flat byte sequence | =binary()= | =<<1,2,3,4>>=, =<<"a string can be a binary">>=, =<<X:Size/type, _Rest/binary>>= |

Term ordering: =number < atom < reference < fun < port < pid < tuple < map < nil < list < binary=

*** Modules and Syntax

#+NAME: all_syntax_mod
#+BEGIN_SRC erlang
%%% This is a module-level comment
%%% @doc This tag includes officiel EDoc documentation.
%%% It can be useful for people to consule
%%% @end
%%% Generate documentation with rebar3 edoc

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Let's start with Module Attributes %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is an attribute or function-specific comment
%% attributes start with a `-', functions with letters.
%% This file should be saved as `sample.erl'
-module(sample).

%% Functions are described in the form Name/Arity, and must
%% be exported through an `-export([...]).' module attribute
-export([f/0, f/1]).
-export([x/0]).         % multiple export attributes can exist

%% You can "import" functions from another module, but
%% for clarity's sake (and because there's no namespaces)
%% nobody really does that
-include(module, [y/0]).

%% .hrl files contain headers, and are imported directly
%% within the module.
%% The following includes a private header file from src/
%% or a public header file from include/ in the current app
-include("some_file.hrl").
%% The following includes a public header file from the
%% include/ file of another application
-include_lib("appname/include/some_file.hrl").

%% specify an interface you implement:
-behaviour(gen_server).

%% Define a record (a tuple that compilers handles in a
%% special way)
-record(struct, {key = default :: term(),
                 other_key     :: undefined | integer()}).

%% Just C-style macros
-define(VALUE, 42).        % ?VALUE in this module becomes `42'
-define(SQUARE(X), (X*X)). % function macro
-define(DBG(Call),         % a fancy debug macro: ?DBG(2 + 2)
        io:format("DBG: ~s (~p): ~p~n",
                  [??Call, {?MODULE, ?LINE}, Call])).

%% Conditionals
-ifdef(MACRO_NAME).        % opposite: -ifndef(MACRO_NAME).
-define(OTHER_MACRO, ok).
-else.                     % other option: -elif(NAME).
-define(MACRO_NAME, ok).
-endif.

%% Type definitions
-type my_type() :: number() | boolean().
-type my_container(T) :: {[T], [T], my_type(), mod:type()}
-export_type([my_type/0, my_container/1]).

%% you can also define custom attributes:
-my_attribute(hello_there).
-author("Duke Erlington").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% And now modules for code and functions %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% @doc A function with 0 arguments returning an atom
-spec f() -> term(). % optional spec
f() -> ok.

-spec f(number()) -> float().
f(N) -> N + 1.0.

%% Pattern matching with clauses
x([]) -> [];  % base recursive clause for a list
x([_H|T] -> [x | T]. % replace list element with `x' atom

%% @private variable binding rules
same_list(X = [_|_], X) -> true;
same_list([], []) -> true;
same_list(_, _) -> false.

%% Operators in the language
operators(X, Y) ->
    +X, -Y, % unary
    X + Y, X - Y, X * Y, X / Y,   % any numbers
    X div Y, X rem Y,             % integers-only
    X band Y, X bor Y, X bxor Y,  % binary operators
    X bsl Y, X bsr L,             % bit shifting
    not X,                        % boolean not
    X andalso Y, X orelse Y,      % shortcircuit boolean operators
    X < Y, X > Y, X >= Y, X =< Y, % comparison
    X == Y, X /= Y,               % equality (float == int)
    X =:= Y, X =/= Y,             % strict equality (float =/= int)
    X ++ Y, X -- Y,               % append Y to X, delete Y from X
    X ! Y.                        % send message Y to process X

%% Using guards. Valid guard expressions at:
%% erlang.org/doc/reference_manual/expressions.html#guard-sequences
comfortable({celsius, X}) when X >= 18, X =< 26 -> % AND clauses
    true;
comfortable({celsius, _}) ->
    false.

incomfortable({celsius, X}) when X =< 18; X >= 26 -> % OR clauses
    true;
incomfortable({celsius, _}) ->
    false.

%% difference with 'andalso' and 'orelse'
conds(X) when (is_number(X) orelse is_integer(X))
               andalso X < 9 ->
    %% equivalent (A AND B) OR C
    true;
conds(X) when is_number(X); is_integer(X), X < 9 ->
    %% - parentheses impossible with , or ;
    %% - equivalent to A OR (B AND C)
    true;
conds(T) when element(1, T) == celsius; is_integer(T) ->
    %% element/2 extracts an element from a tuple. If `T' is
    %% not a tuple, the call fails and `is_integer/1' is tried
    %% instead
    true;
conds(T) when element(1, T) == celsius orelse is_integer(T) ->
    %% this can never work: if element/2 fails, the whole
    %% `orlese' expressoin fails and `is_integer/1' is skipped
    true.

%% Conditionals
conditional('if', Light) ->
    if Light == red -> stop;
       Light == green; Light == yellow -> go_fast;
       true -> burnout % else clause!
    end;
conditional('case', {Light, IsLate}) ->
    case Light of
        green -> go;
        yellow when IsLate -> go_fast;
        _ -> stop
    end;
conditional(pattern, green) -> go;
conditional(pattern, yellow) -> slow;
conditional(pattern, red) -> stop.

%% List and binary comprehensions
comp(ListA, ListB) ->
    [X*X || X <- ListA, X rem 2 == 0], % square even numbers
    [{X,Y} || X <- ListA, Y <- ListB], % all possible pairs
    << <<X:8>> || X <- ListA >>.       % turn list into bytes
comp(BinA, BinB) -> % now with binaries
    << <<X*X:32>> || <<X:8>> <= Bin, X rem 2 == 0 >>,
    [{X,Y} || <<X:32>> <= BinA, <<Y:8>> <= BinB],
    [X || <<X:8>> <= BinA].

%% Anonymous and higher order functions
higher_order() ->
    If = fun(Light) -> conditional('if', Light) end,
    Case = fun(Light) -> conditional('case', {Light, true}) end,
    lists:map(If, [green, yellow, red]),
    lists:map(Case, [green, yellow, red]),
    If(red), % can be called literally
    lists:map(fun(X) -> X*X end, [1,2,3,4,5]).

try_catch() ->
    try
        some_call(),     % exceptions in this call are caught as well
        {ok, val},       % common good return value to pattern match
        {error, reason}, % common bad return value to pattern match
        % any of these expression aborts the execution flow
        throw(reason1), % non-local returns, internal exceptions
        error(reason2), % unfixable error
        exit(reason3)   % the process should terminate
    of  % this section is optional: exceptions here are not caught
        {ok, V} ->
            do_something(V),
            try_catch(); % safely recurse without blowing stack
        {error, R} ->
            {error, R} % just return
    catch % this section is optional: various patterns
        throw:reason1 -> handled;
        reason2 -> oops; % never matches, `throw' is implicit type
        error:reason2 -> handled;
        exit:reason3 -> handled;
        throw:_ -> wildcard_throws;
        E:R when is_error(E) -> any_error;
        _:_:S -> {stacktrace, S}; % extract stacktrace
    after -> % this is an optional 'finally' block
        finally
    end.
#+END_SRC


*** Processes and Signals

#+NAME: concurrency_constructs
#+BEGIN_SRC erlang
%% Start a new process
Pid = spawn(fun() -> some_loop(Arg) end)
Pid = spawn('name@remote.host', fun() -> some_loop(Arg) end)
Pid = spawn(some_module, some_loop, [Arg])
Pid = spawn('name@remote.host', some_module, some_loop, [Arg])
%% Spawn a linked process
Pid = spawn_link(...) % 1-4 arguments as with spawn/1-4
%% Spawn a monitored process atomically
{Pid, Ref} = spawn_monitor(fun() -> some_loop(Arg) end)
{Pid, Ref} = spawn_monitor(some_module, some_loop, [Arg])
%% Spawn with fancy options
spawn_opt(Fun, Opts)
spawn_opt(Node, Fun, Opts)
spawn_opt(Mod, Fun, Args, Opts)
spawn_opt(Node, Mod, Fun, Args, Opts)
%% Options must respect the following spec; many are advanced
[link | monitor |
 {priority, low | normal | high | max} |    % don't touch
 {fullsweep_after, integer() >= 0} |        % full GC
 {min_heap_size, Words :: integer() >= 0} | % perf tuning
 {min_bin_heap_size, Words} |
 {max_heap_size,                    % heap size after which
   Words |                          % the process may be killed. Use
   #{size => integer() >= 0,        % to indirectly set max queue sizes
     kill => boolean(),
     error_logger => boolean()}}

%% send an exit signal to a process
exit(Pid, Reason)

%% Receive a message
receive
    Pattern1 when OptionalGuard1 ->
        Expression1;
    Pattern2 when OptionalGuard2 ->
        Expression2
after Milliseconds -> % optional
    Expression
end

%% Naming processes
true = register(atom_name, Pid)
true = unregister(atom_name)
Pid | undefined = whereis(atom_name)

%% Monitor
Ref = erlang:monitor(process, Pid)
true = erlang:demonitor(Ref)
true | false = erlang:demonitor(Ref, [flush | info])

%% Links
link(Pid)
unlink(Pid)
process_info(trap_exit, true | false)
#+END_SRC

And the semantics for links and monitors, in diagram forms:

#+CAPTION: Monitors are unidirectional informational signals, and they stack
#+NAME: fig:sig_mon
[[./static/img/sig_mon.png]]

#+CAPTION: Untrapped links are bidirectional and kill the other process, except if the reason is 'normal'
#+NAME: fig:sig_linked_notrap
[[./static/img/sig_linked_notrap.png]]

#+CAPTION: Trapped links are converted to messages, except for the untrappable 'kill' reason
#+NAME: fig:sig_linked_trap
[[./static/img/sig_linked_trap.png]]

OTP processes do have slightly different semantics due to supervision shenanigans:

#+CAPTION: Untrapped links work the same for OTP
#+NAME: fig:sig_otp_notrap
[[./static/img/sig_otp_notrap.png]]

#+CAPTION: Trapped links behave in a special way when the parent of a process is the one that dies
#+NAME: fig:sig_otp_trap
[[./static/img/sig_otp_trap.png]]

#+CAPTION: Supervisors log things differently based on the termination reason
#+NAME: fig:sig_otp_own
[[./static/img/sig_otp_own.png]]

*** Behaviours

Not all OTP behaviours are listed here, only thee most frequently-used ones.

**** Applications

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =application:start/1-2= | client or booting VM | =start(Type, Args)= | <code>{ok, pid()} \vert {ok, pid(), State}</code> | should start the root supervisor |
| ={start_phases, [{Phase, Args}]}= in app file | =kernel= booting the app | =start_phase(Phase, Type, Args)= | <code>ok \vert {error, Reason}</code> | Optional. Allows to isolate specific steps of initialization |
| =application:stop/1= | app shutting down | =prop_stop(State)= | =State= | Optional. Called before the supervision tree is shut down |
| =application:stop/1= | app shutting down | =stop(State)= | =term()= | called once the app is done running to clean things up |
| Hot code update | SASL's release handler | =config_change(Changed::[{K,V}], New::[{K,V}], Removed::[K])= | =ok= | Called after a hot code update using the VM's relup functionality, if the configuration values changed |

**** Supervisors

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =supervisor:start_link/2-3= | parent process | =init(Arg)= | <code>ignore \vert {ok, {SupFlag, [Child]}}</code> | Specifies a supervisor. Refer to official documentation |

**** gen_server

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =gen_server:start_link/3-4= | supervisor | =init(Arg)= | <code>{ok, State [, Option]} \vert ignore \vert {stop, Reason}</code> | Set up the initial state of the process |
| =gen_server:call/2-3= | client | =handle_call(Msg, From, State)= | <code>{Type::reply \vert noreply, State [, Option]} \vert {stop, Reason [, Reply], State}code> | Request/response pattern. A message is received and expects an answer |
| =gen_server:cast/2= | client | =handle_cast(Msg, State)= | <code>{noreply, State [, Option]} \vert {stop, Reason, State}</code> | Information sent to the process; fire and forget |
| =Pid ! Msg= | client | =handle_info(Msg, State)= | same as =handle_cast/2= | Out-of-band messages, including monitor signals and ='EXIT'= messages when trappig exit |
| Setting an =Option= value to ={continue, Val}= | the server itself | =handle_continue(Val, State)= | same as =handle_cast/2= | Allows to break longer operations into triggerable internal events |
| =gen_server:stop/1,3= | client or supervisor | =terminate(Reason, State)= | =term()= | Called when the process is shutting down willingly or through errors. If the process does not trap exits, this callback may be omitted |
| =sys:get_status/2-3=, crash logs | client, the server itself | <code>format_status(normal \vert terminate, [PDict, State])</code> | =[{data, [{"State", Term}]}]= | Allows to add or remove information that would make it to debugging calls or error logs |
| N/A | supervisor | =code_change(OldVsn, State, Extra)= | ={ok, NewState}= | called to update a stateful process if the proper instructions are given during a hot code upgrade with releases |

**** gen_statem

***** Process management

| Trigger | Called By | Handled By | Return | Description |
|---------+-----------+------------+--------+-------------|
| =gen_statem:start_link/3-4= | supervisor | =init(Arg)= | <code>{ok, State, Data [, Actions]} \vert ignore \vert {stop, Reason}</code> | Sets the initial state and data for the state machine |
| N/A | internal | =callback_mode()= | <code>[state_functions \vert handle_event_function [, state_enter]]</code> | Defines the type of FSM and whether entering a state triggers a special internal event |
| =gen_statem:stop/1,3= | client or supervisor | =terminate(Reason, State, Data)= | =term()= | Called when the process is shutting down willingly or through errors. If the process does not trap exits, this callback may be omitted |
| =sys:get_status/2-3=, crash logs | client, the server itself | <code>format_status(normal \vert terminate, [PDict, State, Data])</code> | =[{data, [{"State", Term}]}]= | Allows to add or remove information that would make it to debugging calls or error logs |
| N/A | supervisor | =code_change(OldVsn, State, Data, Extra)= | ={ok, NewState, NewData}= | called to update a stateful process if the proper instructions are given during a hot code upgrade with releases |

***** State handling and transitions

Handled by either =handle_event/4= or =StateName/3= functions, based on the value of =callback_mode()=. The function signatures are either:

- =handle_event(EventType, EventDetails, State, Data)=
- =State(EventType, EventDetails, Data)=

If the value of =State= is not a list, even though =callback_mode()= defined =state_functions=, then =handle_event/4= will be called. All possible return values for either functions are one of:

- ={next_state, State, Data}=
- ={next_state, State, Data, [Actions, ...]}=
- ={stop, Reason, Data}=
- ={stop, Reason, Data, [Actions, ...]}=

Various short forms exist, such as =keep_state_and_data=, ={keep_state, Data}=, ={repeat_state, Data}=, and many more. Refer to the documentation for their content.

The =Actions= value is any combination of the following list (non-inclusive): =postpone=, ={next_event, EventType, EventDetails}=, =hibernate=, ={timeout, Delay, EventDetails}=, ={state_timeout, Delay, EventDetails}=, ={reply, From, Reply}=, =hibernate=. Consult the documentation for more options.


| Trigger | Called By | Event Type | Event Details | Description |
|---------+-----------+------------+---------------+-------------|
| =gen_statem:call/2-3= | client | ={call, From}= | =term()= | Request/response pattern. A message is received and is expected to receive an answer |
| =gen_statem:cast/2= | client | =cast= | =term()= | Information must be sent to the process; fire and forget |
| Pid ! Msg | client | =info= | =Msg= | Out-of-band messages, including monitor messages and ='EXIT'= signals that are trapped |
| ={timeout, T, Msg}= | =Action= return value | =timeout= | =Msg= | A specific timeout that can be set and received internally when the state machine has not received a new event in =T= milliseconds |
| ={state_timeout, T, Msg}= | =Action= return value | =state_timeout= | =Msg= | A specific timeout that can be set and received internally when the state machine has not transitioned to a new different state in =T= milliseconds |
| ={next_event, internal, Msg}= | =Action= return value | =internal= | =Msg= | Internal messages that can be generated by a state machine wanting to trigger itself without looking like external calls |


** Systemd
:PROPERTIES:
:EXPORT_FILE_NAME: systemd
:END:

*** Systemd Unit

#+BEGIN_src shell
[Unit]
Description=Service Discovery Runner
After=network.target

[Service]
WorkingDirectory=/opt/service_discovery
EnvironmentFile=/etc/default/service_discovery.env
ExecStart=/opt/service_discovery/bin/service_discovery foreground
Restart=on-failure
Environment=RELX_OUT_FILE_PATH=/tmp/
Environment=COOKIE=service_discovery_cookie

[Install]
WantedBy=multi-user.target
#+END_src

As of OTP 19.3 a =SIGTERM= signal causes the OTP VM to gracefully shutdown.

#+BEGIN_src shell
journalctl service_discovery
#+END_src
